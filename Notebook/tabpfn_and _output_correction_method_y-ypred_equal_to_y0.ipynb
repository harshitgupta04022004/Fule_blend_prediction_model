{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error, make_scorer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn import linear_model \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor,RegressorChain\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_solution = pd.read_csv(\"133e814757ed11f0/dataset/sample_solution.csv\", index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BlendProperty1', 'BlendProperty2', 'BlendProperty3', 'BlendProperty4',\n",
       "       'BlendProperty5', 'BlendProperty6', 'BlendProperty7', 'BlendProperty8',\n",
       "       'BlendProperty9', 'BlendProperty10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_solution.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlendProperty1</th>\n",
       "      <th>BlendProperty2</th>\n",
       "      <th>BlendProperty3</th>\n",
       "      <th>BlendProperty4</th>\n",
       "      <th>BlendProperty5</th>\n",
       "      <th>BlendProperty6</th>\n",
       "      <th>BlendProperty7</th>\n",
       "      <th>BlendProperty8</th>\n",
       "      <th>BlendProperty9</th>\n",
       "      <th>BlendProperty10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.117370</td>\n",
       "      <td>0.348090</td>\n",
       "      <td>0.473673</td>\n",
       "      <td>0.079501</td>\n",
       "      <td>-0.411504</td>\n",
       "      <td>0.015352</td>\n",
       "      <td>0.454957</td>\n",
       "      <td>0.065651</td>\n",
       "      <td>-0.146684</td>\n",
       "      <td>-0.140500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.503910</td>\n",
       "      <td>-0.250186</td>\n",
       "      <td>-1.412727</td>\n",
       "      <td>-0.523577</td>\n",
       "      <td>-0.577571</td>\n",
       "      <td>-0.294264</td>\n",
       "      <td>-1.396187</td>\n",
       "      <td>-0.856044</td>\n",
       "      <td>-0.003241</td>\n",
       "      <td>-0.246948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.484172</td>\n",
       "      <td>1.272972</td>\n",
       "      <td>1.188539</td>\n",
       "      <td>1.321349</td>\n",
       "      <td>1.472491</td>\n",
       "      <td>1.237584</td>\n",
       "      <td>1.192748</td>\n",
       "      <td>1.575889</td>\n",
       "      <td>0.773926</td>\n",
       "      <td>1.917254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.841616</td>\n",
       "      <td>0.457436</td>\n",
       "      <td>0.534375</td>\n",
       "      <td>0.376650</td>\n",
       "      <td>1.593406</td>\n",
       "      <td>0.157950</td>\n",
       "      <td>0.516430</td>\n",
       "      <td>0.632370</td>\n",
       "      <td>0.376289</td>\n",
       "      <td>-0.446052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.024147</td>\n",
       "      <td>0.136198</td>\n",
       "      <td>1.174866</td>\n",
       "      <td>-0.197264</td>\n",
       "      <td>2.463520</td>\n",
       "      <td>0.418315</td>\n",
       "      <td>1.185596</td>\n",
       "      <td>0.509797</td>\n",
       "      <td>-0.434762</td>\n",
       "      <td>0.807128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.022706</td>\n",
       "      <td>-0.047897</td>\n",
       "      <td>0.474691</td>\n",
       "      <td>-0.016551</td>\n",
       "      <td>-0.431127</td>\n",
       "      <td>-0.081999</td>\n",
       "      <td>0.462777</td>\n",
       "      <td>0.089287</td>\n",
       "      <td>-0.608682</td>\n",
       "      <td>0.516307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-1.475840</td>\n",
       "      <td>-1.294104</td>\n",
       "      <td>-1.230311</td>\n",
       "      <td>-1.231267</td>\n",
       "      <td>-0.303306</td>\n",
       "      <td>-0.977209</td>\n",
       "      <td>-1.217209</td>\n",
       "      <td>-1.553847</td>\n",
       "      <td>-1.126938</td>\n",
       "      <td>-1.407277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1.002035</td>\n",
       "      <td>0.870014</td>\n",
       "      <td>0.037003</td>\n",
       "      <td>0.963333</td>\n",
       "      <td>-0.261270</td>\n",
       "      <td>0.620495</td>\n",
       "      <td>0.029488</td>\n",
       "      <td>0.414339</td>\n",
       "      <td>0.726121</td>\n",
       "      <td>-0.088445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.330749</td>\n",
       "      <td>0.305096</td>\n",
       "      <td>0.692611</td>\n",
       "      <td>0.211861</td>\n",
       "      <td>-0.629404</td>\n",
       "      <td>0.222873</td>\n",
       "      <td>0.679603</td>\n",
       "      <td>0.295588</td>\n",
       "      <td>-0.061082</td>\n",
       "      <td>0.818857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-1.477784</td>\n",
       "      <td>-1.536384</td>\n",
       "      <td>-1.974211</td>\n",
       "      <td>-1.430588</td>\n",
       "      <td>-0.478197</td>\n",
       "      <td>-1.539213</td>\n",
       "      <td>-1.947190</td>\n",
       "      <td>-1.503319</td>\n",
       "      <td>-1.813341</td>\n",
       "      <td>-0.509822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BlendProperty1  BlendProperty2  BlendProperty3  BlendProperty4  \\\n",
       "ID                                                                    \n",
       "1         -0.117370        0.348090        0.473673        0.079501   \n",
       "2         -0.503910       -0.250186       -1.412727       -0.523577   \n",
       "3          1.484172        1.272972        1.188539        1.321349   \n",
       "4          0.841616        0.457436        0.534375        0.376650   \n",
       "5         -0.024147        0.136198        1.174866       -0.197264   \n",
       "..              ...             ...             ...             ...   \n",
       "496        0.022706       -0.047897        0.474691       -0.016551   \n",
       "497       -1.475840       -1.294104       -1.230311       -1.231267   \n",
       "498        1.002035        0.870014        0.037003        0.963333   \n",
       "499        0.330749        0.305096        0.692611        0.211861   \n",
       "500       -1.477784       -1.536384       -1.974211       -1.430588   \n",
       "\n",
       "     BlendProperty5  BlendProperty6  BlendProperty7  BlendProperty8  \\\n",
       "ID                                                                    \n",
       "1         -0.411504        0.015352        0.454957        0.065651   \n",
       "2         -0.577571       -0.294264       -1.396187       -0.856044   \n",
       "3          1.472491        1.237584        1.192748        1.575889   \n",
       "4          1.593406        0.157950        0.516430        0.632370   \n",
       "5          2.463520        0.418315        1.185596        0.509797   \n",
       "..              ...             ...             ...             ...   \n",
       "496       -0.431127       -0.081999        0.462777        0.089287   \n",
       "497       -0.303306       -0.977209       -1.217209       -1.553847   \n",
       "498       -0.261270        0.620495        0.029488        0.414339   \n",
       "499       -0.629404        0.222873        0.679603        0.295588   \n",
       "500       -0.478197       -1.539213       -1.947190       -1.503319   \n",
       "\n",
       "     BlendProperty9  BlendProperty10  \n",
       "ID                                    \n",
       "1         -0.146684        -0.140500  \n",
       "2         -0.003241        -0.246948  \n",
       "3          0.773926         1.917254  \n",
       "4          0.376289        -0.446052  \n",
       "5         -0.434762         0.807128  \n",
       "..              ...              ...  \n",
       "496       -0.608682         0.516307  \n",
       "497       -1.126938        -1.407277  \n",
       "498        0.726121        -0.088445  \n",
       "499       -0.061082         0.818857  \n",
       "500       -1.813341        -0.509822  \n",
       "\n",
       "[500 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('133e814757ed11f0/dataset/train.csv')\n",
    "test_dataset  = pd.read_csv('133e814757ed11f0/dataset/test.csv',index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 65 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Component1_fraction    2000 non-null   float64\n",
      " 1   Component2_fraction    2000 non-null   float64\n",
      " 2   Component3_fraction    2000 non-null   float64\n",
      " 3   Component4_fraction    2000 non-null   float64\n",
      " 4   Component5_fraction    2000 non-null   float64\n",
      " 5   Component1_Property1   2000 non-null   float64\n",
      " 6   Component2_Property1   2000 non-null   float64\n",
      " 7   Component3_Property1   2000 non-null   float64\n",
      " 8   Component4_Property1   2000 non-null   float64\n",
      " 9   Component5_Property1   2000 non-null   float64\n",
      " 10  Component1_Property2   2000 non-null   float64\n",
      " 11  Component2_Property2   2000 non-null   float64\n",
      " 12  Component3_Property2   2000 non-null   float64\n",
      " 13  Component4_Property2   2000 non-null   float64\n",
      " 14  Component5_Property2   2000 non-null   float64\n",
      " 15  Component1_Property3   2000 non-null   float64\n",
      " 16  Component2_Property3   2000 non-null   float64\n",
      " 17  Component3_Property3   2000 non-null   float64\n",
      " 18  Component4_Property3   2000 non-null   float64\n",
      " 19  Component5_Property3   2000 non-null   float64\n",
      " 20  Component1_Property4   2000 non-null   float64\n",
      " 21  Component2_Property4   2000 non-null   float64\n",
      " 22  Component3_Property4   2000 non-null   float64\n",
      " 23  Component4_Property4   2000 non-null   float64\n",
      " 24  Component5_Property4   2000 non-null   float64\n",
      " 25  Component1_Property5   2000 non-null   float64\n",
      " 26  Component2_Property5   2000 non-null   float64\n",
      " 27  Component3_Property5   2000 non-null   float64\n",
      " 28  Component4_Property5   2000 non-null   float64\n",
      " 29  Component5_Property5   2000 non-null   float64\n",
      " 30  Component1_Property6   2000 non-null   float64\n",
      " 31  Component2_Property6   2000 non-null   float64\n",
      " 32  Component3_Property6   2000 non-null   float64\n",
      " 33  Component4_Property6   2000 non-null   float64\n",
      " 34  Component5_Property6   2000 non-null   float64\n",
      " 35  Component1_Property7   2000 non-null   float64\n",
      " 36  Component2_Property7   2000 non-null   float64\n",
      " 37  Component3_Property7   2000 non-null   float64\n",
      " 38  Component4_Property7   2000 non-null   float64\n",
      " 39  Component5_Property7   2000 non-null   float64\n",
      " 40  Component1_Property8   2000 non-null   float64\n",
      " 41  Component2_Property8   2000 non-null   float64\n",
      " 42  Component3_Property8   2000 non-null   float64\n",
      " 43  Component4_Property8   2000 non-null   float64\n",
      " 44  Component5_Property8   2000 non-null   float64\n",
      " 45  Component1_Property9   2000 non-null   float64\n",
      " 46  Component2_Property9   2000 non-null   float64\n",
      " 47  Component3_Property9   2000 non-null   float64\n",
      " 48  Component4_Property9   2000 non-null   float64\n",
      " 49  Component5_Property9   2000 non-null   float64\n",
      " 50  Component1_Property10  2000 non-null   float64\n",
      " 51  Component2_Property10  2000 non-null   float64\n",
      " 52  Component3_Property10  2000 non-null   float64\n",
      " 53  Component4_Property10  2000 non-null   float64\n",
      " 54  Component5_Property10  2000 non-null   float64\n",
      " 55  BlendProperty1         2000 non-null   float64\n",
      " 56  BlendProperty2         2000 non-null   float64\n",
      " 57  BlendProperty3         2000 non-null   float64\n",
      " 58  BlendProperty4         2000 non-null   float64\n",
      " 59  BlendProperty5         2000 non-null   float64\n",
      " 60  BlendProperty6         2000 non-null   float64\n",
      " 61  BlendProperty7         2000 non-null   float64\n",
      " 62  BlendProperty8         2000 non-null   float64\n",
      " 63  BlendProperty9         2000 non-null   float64\n",
      " 64  BlendProperty10        2000 non-null   float64\n",
      "dtypes: float64(65)\n",
      "memory usage: 1015.8 KB\n"
     ]
    }
   ],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, output_blends = train_dataset.iloc[:,:55],train_dataset.iloc[:,55:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500 entries, 1 to 500\n",
      "Data columns (total 55 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Component1_fraction    500 non-null    float64\n",
      " 1   Component2_fraction    500 non-null    float64\n",
      " 2   Component3_fraction    500 non-null    float64\n",
      " 3   Component4_fraction    500 non-null    float64\n",
      " 4   Component5_fraction    500 non-null    float64\n",
      " 5   Component1_Property1   500 non-null    float64\n",
      " 6   Component2_Property1   500 non-null    float64\n",
      " 7   Component3_Property1   500 non-null    float64\n",
      " 8   Component4_Property1   500 non-null    float64\n",
      " 9   Component5_Property1   500 non-null    float64\n",
      " 10  Component1_Property2   500 non-null    float64\n",
      " 11  Component2_Property2   500 non-null    float64\n",
      " 12  Component3_Property2   500 non-null    float64\n",
      " 13  Component4_Property2   500 non-null    float64\n",
      " 14  Component5_Property2   500 non-null    float64\n",
      " 15  Component1_Property3   500 non-null    float64\n",
      " 16  Component2_Property3   500 non-null    float64\n",
      " 17  Component3_Property3   500 non-null    float64\n",
      " 18  Component4_Property3   500 non-null    float64\n",
      " 19  Component5_Property3   500 non-null    float64\n",
      " 20  Component1_Property4   500 non-null    float64\n",
      " 21  Component2_Property4   500 non-null    float64\n",
      " 22  Component3_Property4   500 non-null    float64\n",
      " 23  Component4_Property4   500 non-null    float64\n",
      " 24  Component5_Property4   500 non-null    float64\n",
      " 25  Component1_Property5   500 non-null    float64\n",
      " 26  Component2_Property5   500 non-null    float64\n",
      " 27  Component3_Property5   500 non-null    float64\n",
      " 28  Component4_Property5   500 non-null    float64\n",
      " 29  Component5_Property5   500 non-null    float64\n",
      " 30  Component1_Property6   500 non-null    float64\n",
      " 31  Component2_Property6   500 non-null    float64\n",
      " 32  Component3_Property6   500 non-null    float64\n",
      " 33  Component4_Property6   500 non-null    float64\n",
      " 34  Component5_Property6   500 non-null    float64\n",
      " 35  Component1_Property7   500 non-null    float64\n",
      " 36  Component2_Property7   500 non-null    float64\n",
      " 37  Component3_Property7   500 non-null    float64\n",
      " 38  Component4_Property7   500 non-null    float64\n",
      " 39  Component5_Property7   500 non-null    float64\n",
      " 40  Component1_Property8   500 non-null    float64\n",
      " 41  Component2_Property8   500 non-null    float64\n",
      " 42  Component3_Property8   500 non-null    float64\n",
      " 43  Component4_Property8   500 non-null    float64\n",
      " 44  Component5_Property8   500 non-null    float64\n",
      " 45  Component1_Property9   500 non-null    float64\n",
      " 46  Component2_Property9   500 non-null    float64\n",
      " 47  Component3_Property9   500 non-null    float64\n",
      " 48  Component4_Property9   500 non-null    float64\n",
      " 49  Component5_Property9   500 non-null    float64\n",
      " 50  Component1_Property10  500 non-null    float64\n",
      " 51  Component2_Property10  500 non-null    float64\n",
      " 52  Component3_Property10  500 non-null    float64\n",
      " 53  Component4_Property10  500 non-null    float64\n",
      " 54  Component5_Property10  500 non-null    float64\n",
      "dtypes: float64(55)\n",
      "memory usage: 218.8 KB\n"
     ]
    }
   ],
   "source": [
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component1_fraction</th>\n",
       "      <th>Component2_fraction</th>\n",
       "      <th>Component3_fraction</th>\n",
       "      <th>Component4_fraction</th>\n",
       "      <th>Component5_fraction</th>\n",
       "      <th>Component1_Property1</th>\n",
       "      <th>Component2_Property1</th>\n",
       "      <th>Component3_Property1</th>\n",
       "      <th>Component4_Property1</th>\n",
       "      <th>Component5_Property1</th>\n",
       "      <th>...</th>\n",
       "      <th>Component1_Property9</th>\n",
       "      <th>Component2_Property9</th>\n",
       "      <th>Component3_Property9</th>\n",
       "      <th>Component4_Property9</th>\n",
       "      <th>Component5_Property9</th>\n",
       "      <th>Component1_Property10</th>\n",
       "      <th>Component2_Property10</th>\n",
       "      <th>Component3_Property10</th>\n",
       "      <th>Component4_Property10</th>\n",
       "      <th>Component5_Property10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.021782</td>\n",
       "      <td>1.981251</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0.140315</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480368</td>\n",
       "      <td>1.044967</td>\n",
       "      <td>-0.450956</td>\n",
       "      <td>0.674572</td>\n",
       "      <td>-0.636394</td>\n",
       "      <td>-1.244963</td>\n",
       "      <td>-1.355050</td>\n",
       "      <td>-0.314423</td>\n",
       "      <td>0.993593</td>\n",
       "      <td>-2.728928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.224339</td>\n",
       "      <td>1.148036</td>\n",
       "      <td>-1.107840</td>\n",
       "      <td>0.149533</td>\n",
       "      <td>-0.354000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.958826</td>\n",
       "      <td>-0.019603</td>\n",
       "      <td>-0.807923</td>\n",
       "      <td>0.148715</td>\n",
       "      <td>1.439313</td>\n",
       "      <td>-1.160435</td>\n",
       "      <td>-0.014276</td>\n",
       "      <td>-0.135968</td>\n",
       "      <td>-1.221155</td>\n",
       "      <td>0.896222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.457763</td>\n",
       "      <td>0.242591</td>\n",
       "      <td>-0.922492</td>\n",
       "      <td>0.908213</td>\n",
       "      <td>0.972003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.798978</td>\n",
       "      <td>-0.444027</td>\n",
       "      <td>0.148405</td>\n",
       "      <td>-0.793607</td>\n",
       "      <td>0.123834</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>0.668734</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>-0.098661</td>\n",
       "      <td>-0.424314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.577734</td>\n",
       "      <td>-0.930826</td>\n",
       "      <td>0.815284</td>\n",
       "      <td>0.447514</td>\n",
       "      <td>0.455717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.534135</td>\n",
       "      <td>1.155513</td>\n",
       "      <td>-0.760428</td>\n",
       "      <td>0.450159</td>\n",
       "      <td>-0.973779</td>\n",
       "      <td>0.052972</td>\n",
       "      <td>-1.024785</td>\n",
       "      <td>0.118951</td>\n",
       "      <td>2.400556</td>\n",
       "      <td>-0.576430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.120415</td>\n",
       "      <td>0.666268</td>\n",
       "      <td>-0.626934</td>\n",
       "      <td>2.725357</td>\n",
       "      <td>0.392259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.389350</td>\n",
       "      <td>1.799238</td>\n",
       "      <td>-0.912374</td>\n",
       "      <td>1.767557</td>\n",
       "      <td>-0.467038</td>\n",
       "      <td>2.104922</td>\n",
       "      <td>0.858593</td>\n",
       "      <td>-0.469110</td>\n",
       "      <td>0.715789</td>\n",
       "      <td>-2.038341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>-0.054170</td>\n",
       "      <td>-0.391227</td>\n",
       "      <td>0.400222</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>1.138839</td>\n",
       "      <td>1.666804</td>\n",
       "      <td>-1.413339</td>\n",
       "      <td>0.405253</td>\n",
       "      <td>0.766653</td>\n",
       "      <td>-0.322096</td>\n",
       "      <td>1.399468</td>\n",
       "      <td>1.096369</td>\n",
       "      <td>-0.346225</td>\n",
       "      <td>0.641193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.887185</td>\n",
       "      <td>0.610050</td>\n",
       "      <td>0.178606</td>\n",
       "      <td>1.083154</td>\n",
       "      <td>-2.822749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.782418</td>\n",
       "      <td>0.784366</td>\n",
       "      <td>1.113626</td>\n",
       "      <td>1.328112</td>\n",
       "      <td>-2.537512</td>\n",
       "      <td>0.461525</td>\n",
       "      <td>0.647984</td>\n",
       "      <td>-0.618766</td>\n",
       "      <td>-0.047918</td>\n",
       "      <td>0.397253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.568978</td>\n",
       "      <td>-0.196759</td>\n",
       "      <td>-0.646318</td>\n",
       "      <td>-0.980070</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.813747</td>\n",
       "      <td>-0.197880</td>\n",
       "      <td>-0.549162</td>\n",
       "      <td>0.810814</td>\n",
       "      <td>1.567580</td>\n",
       "      <td>-0.694918</td>\n",
       "      <td>-1.710215</td>\n",
       "      <td>-0.233936</td>\n",
       "      <td>-0.133002</td>\n",
       "      <td>-0.284672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.067453</td>\n",
       "      <td>0.321977</td>\n",
       "      <td>-0.137535</td>\n",
       "      <td>0.238507</td>\n",
       "      <td>0.017455</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262477</td>\n",
       "      <td>-0.925444</td>\n",
       "      <td>-0.823345</td>\n",
       "      <td>0.427648</td>\n",
       "      <td>-0.161447</td>\n",
       "      <td>0.628131</td>\n",
       "      <td>-0.038484</td>\n",
       "      <td>0.343058</td>\n",
       "      <td>0.448748</td>\n",
       "      <td>0.193507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.284090</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>-0.831267</td>\n",
       "      <td>-1.084474</td>\n",
       "      <td>0.845087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.530443</td>\n",
       "      <td>-0.307187</td>\n",
       "      <td>-1.171040</td>\n",
       "      <td>0.476657</td>\n",
       "      <td>0.431925</td>\n",
       "      <td>0.937046</td>\n",
       "      <td>0.504811</td>\n",
       "      <td>0.031798</td>\n",
       "      <td>0.406206</td>\n",
       "      <td>-0.392435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Component1_fraction  Component2_fraction  Component3_fraction  \\\n",
       "0                    0.21                 0.00                 0.42   \n",
       "1                    0.02                 0.33                 0.19   \n",
       "2                    0.08                 0.08                 0.18   \n",
       "3                    0.25                 0.42                 0.00   \n",
       "4                    0.26                 0.16                 0.08   \n",
       "...                   ...                  ...                  ...   \n",
       "1995                 0.50                 0.12                 0.00   \n",
       "1996                 0.19                 0.31                 0.00   \n",
       "1997                 0.38                 0.06                 0.14   \n",
       "1998                 0.50                 0.16                 0.00   \n",
       "1999                 0.00                 0.34                 0.21   \n",
       "\n",
       "      Component4_fraction  Component5_fraction  Component1_Property1  \\\n",
       "0                    0.25                 0.12             -0.021782   \n",
       "1                    0.46                 0.00             -0.224339   \n",
       "2                    0.50                 0.16              0.457763   \n",
       "3                    0.07                 0.26             -0.577734   \n",
       "4                    0.50                 0.00              0.120415   \n",
       "...                   ...                  ...                   ...   \n",
       "1995                 0.26                 0.12              0.279523   \n",
       "1996                 0.37                 0.13             -0.887185   \n",
       "1997                 0.31                 0.11              0.568978   \n",
       "1998                 0.18                 0.16             -0.067453   \n",
       "1999                 0.45                 0.00              0.284090   \n",
       "\n",
       "      Component2_Property1  Component3_Property1  Component4_Property1  \\\n",
       "0                 1.981251              0.020036              0.140315   \n",
       "1                 1.148036             -1.107840              0.149533   \n",
       "2                 0.242591             -0.922492              0.908213   \n",
       "3                -0.930826              0.815284              0.447514   \n",
       "4                 0.666268             -0.626934              2.725357   \n",
       "...                    ...                   ...                   ...   \n",
       "1995             -0.054170             -0.391227              0.400222   \n",
       "1996              0.610050              0.178606              1.083154   \n",
       "1997             -0.196759             -0.646318             -0.980070   \n",
       "1998              0.321977             -0.137535              0.238507   \n",
       "1999              0.189099             -0.831267             -1.084474   \n",
       "\n",
       "      Component5_Property1  ...  Component1_Property9  Component2_Property9  \\\n",
       "0                 1.032029  ...              0.480368              1.044967   \n",
       "1                -0.354000  ...             -1.958826             -0.019603   \n",
       "2                 0.972003  ...             -0.798978             -0.444027   \n",
       "3                 0.455717  ...             -0.534135              1.155513   \n",
       "4                 0.392259  ...             -0.389350              1.799238   \n",
       "...                    ...  ...                   ...                   ...   \n",
       "1995              1.032029  ...              1.138839              1.666804   \n",
       "1996             -2.822749  ...             -0.782418              0.784366   \n",
       "1997              1.032029  ...             -0.813747             -0.197880   \n",
       "1998              0.017455  ...              1.262477             -0.925444   \n",
       "1999              0.845087  ...             -0.530443             -0.307187   \n",
       "\n",
       "      Component3_Property9  Component4_Property9  Component5_Property9  \\\n",
       "0                -0.450956              0.674572             -0.636394   \n",
       "1                -0.807923              0.148715              1.439313   \n",
       "2                 0.148405             -0.793607              0.123834   \n",
       "3                -0.760428              0.450159             -0.973779   \n",
       "4                -0.912374              1.767557             -0.467038   \n",
       "...                    ...                   ...                   ...   \n",
       "1995             -1.413339              0.405253              0.766653   \n",
       "1996              1.113626              1.328112             -2.537512   \n",
       "1997             -0.549162              0.810814              1.567580   \n",
       "1998             -0.823345              0.427648             -0.161447   \n",
       "1999             -1.171040              0.476657              0.431925   \n",
       "\n",
       "      Component1_Property10  Component2_Property10  Component3_Property10  \\\n",
       "0                 -1.244963              -1.355050              -0.314423   \n",
       "1                 -1.160435              -0.014276              -0.135968   \n",
       "2                  0.006829               0.668734               0.015449   \n",
       "3                  0.052972              -1.024785               0.118951   \n",
       "4                  2.104922               0.858593              -0.469110   \n",
       "...                     ...                    ...                    ...   \n",
       "1995              -0.322096               1.399468               1.096369   \n",
       "1996               0.461525               0.647984              -0.618766   \n",
       "1997              -0.694918              -1.710215              -0.233936   \n",
       "1998               0.628131              -0.038484               0.343058   \n",
       "1999               0.937046               0.504811               0.031798   \n",
       "\n",
       "      Component4_Property10  Component5_Property10  \n",
       "0                  0.993593              -2.728928  \n",
       "1                 -1.221155               0.896222  \n",
       "2                 -0.098661              -0.424314  \n",
       "3                  2.400556              -0.576430  \n",
       "4                  0.715789              -2.038341  \n",
       "...                     ...                    ...  \n",
       "1995              -0.346225               0.641193  \n",
       "1996              -0.047918               0.397253  \n",
       "1997              -0.133002              -0.284672  \n",
       "1998               0.448748               0.193507  \n",
       "1999               0.406206              -0.392435  \n",
       "\n",
       "[2000 rows x 55 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlendProperty1</th>\n",
       "      <th>BlendProperty2</th>\n",
       "      <th>BlendProperty3</th>\n",
       "      <th>BlendProperty4</th>\n",
       "      <th>BlendProperty5</th>\n",
       "      <th>BlendProperty6</th>\n",
       "      <th>BlendProperty7</th>\n",
       "      <th>BlendProperty8</th>\n",
       "      <th>BlendProperty9</th>\n",
       "      <th>BlendProperty10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.489143</td>\n",
       "      <td>0.607589</td>\n",
       "      <td>0.321670</td>\n",
       "      <td>-1.236055</td>\n",
       "      <td>1.601132</td>\n",
       "      <td>1.384662</td>\n",
       "      <td>0.305850</td>\n",
       "      <td>0.193460</td>\n",
       "      <td>0.580374</td>\n",
       "      <td>-0.762738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.257481</td>\n",
       "      <td>-1.475283</td>\n",
       "      <td>-0.437385</td>\n",
       "      <td>-1.402911</td>\n",
       "      <td>0.147941</td>\n",
       "      <td>-1.143244</td>\n",
       "      <td>-0.439171</td>\n",
       "      <td>-1.379041</td>\n",
       "      <td>-1.280989</td>\n",
       "      <td>-0.503625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.784349</td>\n",
       "      <td>0.450467</td>\n",
       "      <td>0.622687</td>\n",
       "      <td>1.375614</td>\n",
       "      <td>-0.428790</td>\n",
       "      <td>1.161616</td>\n",
       "      <td>0.601289</td>\n",
       "      <td>0.872950</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>2.024576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.066422</td>\n",
       "      <td>0.483730</td>\n",
       "      <td>-1.865442</td>\n",
       "      <td>-0.046295</td>\n",
       "      <td>-0.163820</td>\n",
       "      <td>-0.209693</td>\n",
       "      <td>-1.840566</td>\n",
       "      <td>0.300293</td>\n",
       "      <td>-0.351336</td>\n",
       "      <td>-1.551914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.118913</td>\n",
       "      <td>-1.172398</td>\n",
       "      <td>0.301785</td>\n",
       "      <td>-1.787407</td>\n",
       "      <td>-0.493361</td>\n",
       "      <td>-0.528049</td>\n",
       "      <td>0.286344</td>\n",
       "      <td>-0.265192</td>\n",
       "      <td>0.430513</td>\n",
       "      <td>0.735073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-0.028366</td>\n",
       "      <td>-0.327297</td>\n",
       "      <td>-0.316933</td>\n",
       "      <td>-1.294092</td>\n",
       "      <td>-0.530259</td>\n",
       "      <td>-0.421526</td>\n",
       "      <td>-0.320869</td>\n",
       "      <td>0.709627</td>\n",
       "      <td>-0.737244</td>\n",
       "      <td>-0.744289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-0.449245</td>\n",
       "      <td>0.156778</td>\n",
       "      <td>-0.367445</td>\n",
       "      <td>-0.938615</td>\n",
       "      <td>-0.577451</td>\n",
       "      <td>-0.209996</td>\n",
       "      <td>-0.370505</td>\n",
       "      <td>-0.195531</td>\n",
       "      <td>-0.032834</td>\n",
       "      <td>0.269718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.029135</td>\n",
       "      <td>0.164890</td>\n",
       "      <td>-0.092942</td>\n",
       "      <td>-1.134490</td>\n",
       "      <td>-0.437479</td>\n",
       "      <td>-0.695636</td>\n",
       "      <td>-0.101073</td>\n",
       "      <td>0.063650</td>\n",
       "      <td>0.624368</td>\n",
       "      <td>-0.477053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-0.232960</td>\n",
       "      <td>-0.464947</td>\n",
       "      <td>0.112536</td>\n",
       "      <td>-0.793522</td>\n",
       "      <td>-0.811272</td>\n",
       "      <td>-1.194914</td>\n",
       "      <td>0.100644</td>\n",
       "      <td>0.760116</td>\n",
       "      <td>-0.751394</td>\n",
       "      <td>-0.857598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-1.797180</td>\n",
       "      <td>-1.312212</td>\n",
       "      <td>-0.511896</td>\n",
       "      <td>-1.450066</td>\n",
       "      <td>-0.365154</td>\n",
       "      <td>-1.087937</td>\n",
       "      <td>-0.512119</td>\n",
       "      <td>-0.582473</td>\n",
       "      <td>-0.834879</td>\n",
       "      <td>-0.272462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BlendProperty1  BlendProperty2  BlendProperty3  BlendProperty4  \\\n",
       "0           0.489143        0.607589        0.321670       -1.236055   \n",
       "1          -1.257481       -1.475283       -0.437385       -1.402911   \n",
       "2           1.784349        0.450467        0.622687        1.375614   \n",
       "3          -0.066422        0.483730       -1.865442       -0.046295   \n",
       "4          -0.118913       -1.172398        0.301785       -1.787407   \n",
       "...              ...             ...             ...             ...   \n",
       "1995       -0.028366       -0.327297       -0.316933       -1.294092   \n",
       "1996       -0.449245        0.156778       -0.367445       -0.938615   \n",
       "1997        0.029135        0.164890       -0.092942       -1.134490   \n",
       "1998       -0.232960       -0.464947        0.112536       -0.793522   \n",
       "1999       -1.797180       -1.312212       -0.511896       -1.450066   \n",
       "\n",
       "      BlendProperty5  BlendProperty6  BlendProperty7  BlendProperty8  \\\n",
       "0           1.601132        1.384662        0.305850        0.193460   \n",
       "1           0.147941       -1.143244       -0.439171       -1.379041   \n",
       "2          -0.428790        1.161616        0.601289        0.872950   \n",
       "3          -0.163820       -0.209693       -1.840566        0.300293   \n",
       "4          -0.493361       -0.528049        0.286344       -0.265192   \n",
       "...              ...             ...             ...             ...   \n",
       "1995       -0.530259       -0.421526       -0.320869        0.709627   \n",
       "1996       -0.577451       -0.209996       -0.370505       -0.195531   \n",
       "1997       -0.437479       -0.695636       -0.101073        0.063650   \n",
       "1998       -0.811272       -1.194914        0.100644        0.760116   \n",
       "1999       -0.365154       -1.087937       -0.512119       -0.582473   \n",
       "\n",
       "      BlendProperty9  BlendProperty10  \n",
       "0           0.580374        -0.762738  \n",
       "1          -1.280989        -0.503625  \n",
       "2           0.660000         2.024576  \n",
       "3          -0.351336        -1.551914  \n",
       "4           0.430513         0.735073  \n",
       "...              ...              ...  \n",
       "1995       -0.737244        -0.744289  \n",
       "1996       -0.032834         0.269718  \n",
       "1997        0.624368        -0.477053  \n",
       "1998       -0.751394        -0.857598  \n",
       "1999       -0.834879        -0.272462  \n",
       "\n",
       "[2000 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_blends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlendProperty1</th>\n",
       "      <th>BlendProperty2</th>\n",
       "      <th>BlendProperty3</th>\n",
       "      <th>BlendProperty4</th>\n",
       "      <th>BlendProperty5</th>\n",
       "      <th>BlendProperty6</th>\n",
       "      <th>BlendProperty7</th>\n",
       "      <th>BlendProperty8</th>\n",
       "      <th>BlendProperty9</th>\n",
       "      <th>BlendProperty10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BlendProperty1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.726115</td>\n",
       "      <td>0.451207</td>\n",
       "      <td>0.742979</td>\n",
       "      <td>0.154810</td>\n",
       "      <td>0.637866</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.644980</td>\n",
       "      <td>0.597190</td>\n",
       "      <td>0.380908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlendProperty2</th>\n",
       "      <td>0.726115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.431597</td>\n",
       "      <td>0.706317</td>\n",
       "      <td>0.124643</td>\n",
       "      <td>0.638396</td>\n",
       "      <td>0.432767</td>\n",
       "      <td>0.642155</td>\n",
       "      <td>0.603799</td>\n",
       "      <td>0.284212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlendProperty3</th>\n",
       "      <td>0.451207</td>\n",
       "      <td>0.431597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.432625</td>\n",
       "      <td>0.374290</td>\n",
       "      <td>0.415293</td>\n",
       "      <td>0.997246</td>\n",
       "      <td>0.627322</td>\n",
       "      <td>0.179044</td>\n",
       "      <td>0.512494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlendProperty4</th>\n",
       "      <td>0.742979</td>\n",
       "      <td>0.706317</td>\n",
       "      <td>0.432625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.153385</td>\n",
       "      <td>0.636376</td>\n",
       "      <td>0.435700</td>\n",
       "      <td>0.641747</td>\n",
       "      <td>0.586330</td>\n",
       "      <td>0.358780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlendProperty5</th>\n",
       "      <td>0.154810</td>\n",
       "      <td>0.124643</td>\n",
       "      <td>0.374290</td>\n",
       "      <td>0.153385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152318</td>\n",
       "      <td>0.380571</td>\n",
       "      <td>0.270996</td>\n",
       "      <td>0.028121</td>\n",
       "      <td>0.158801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlendProperty6</th>\n",
       "      <td>0.637866</td>\n",
       "      <td>0.638396</td>\n",
       "      <td>0.415293</td>\n",
       "      <td>0.636376</td>\n",
       "      <td>0.152318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.416414</td>\n",
       "      <td>0.574911</td>\n",
       "      <td>0.665098</td>\n",
       "      <td>0.255511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlendProperty7</th>\n",
       "      <td>0.450704</td>\n",
       "      <td>0.432767</td>\n",
       "      <td>0.997246</td>\n",
       "      <td>0.435700</td>\n",
       "      <td>0.380571</td>\n",
       "      <td>0.416414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.629038</td>\n",
       "      <td>0.179592</td>\n",
       "      <td>0.510099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlendProperty8</th>\n",
       "      <td>0.644980</td>\n",
       "      <td>0.642155</td>\n",
       "      <td>0.627322</td>\n",
       "      <td>0.641747</td>\n",
       "      <td>0.270996</td>\n",
       "      <td>0.574911</td>\n",
       "      <td>0.629038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.474233</td>\n",
       "      <td>0.377589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlendProperty9</th>\n",
       "      <td>0.597190</td>\n",
       "      <td>0.603799</td>\n",
       "      <td>0.179044</td>\n",
       "      <td>0.586330</td>\n",
       "      <td>0.028121</td>\n",
       "      <td>0.665098</td>\n",
       "      <td>0.179592</td>\n",
       "      <td>0.474233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.158135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BlendProperty10</th>\n",
       "      <td>0.380908</td>\n",
       "      <td>0.284212</td>\n",
       "      <td>0.512494</td>\n",
       "      <td>0.358780</td>\n",
       "      <td>0.158801</td>\n",
       "      <td>0.255511</td>\n",
       "      <td>0.510099</td>\n",
       "      <td>0.377589</td>\n",
       "      <td>0.158135</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BlendProperty1  BlendProperty2  BlendProperty3  \\\n",
       "BlendProperty1         1.000000        0.726115        0.451207   \n",
       "BlendProperty2         0.726115        1.000000        0.431597   \n",
       "BlendProperty3         0.451207        0.431597        1.000000   \n",
       "BlendProperty4         0.742979        0.706317        0.432625   \n",
       "BlendProperty5         0.154810        0.124643        0.374290   \n",
       "BlendProperty6         0.637866        0.638396        0.415293   \n",
       "BlendProperty7         0.450704        0.432767        0.997246   \n",
       "BlendProperty8         0.644980        0.642155        0.627322   \n",
       "BlendProperty9         0.597190        0.603799        0.179044   \n",
       "BlendProperty10        0.380908        0.284212        0.512494   \n",
       "\n",
       "                 BlendProperty4  BlendProperty5  BlendProperty6  \\\n",
       "BlendProperty1         0.742979        0.154810        0.637866   \n",
       "BlendProperty2         0.706317        0.124643        0.638396   \n",
       "BlendProperty3         0.432625        0.374290        0.415293   \n",
       "BlendProperty4         1.000000        0.153385        0.636376   \n",
       "BlendProperty5         0.153385        1.000000        0.152318   \n",
       "BlendProperty6         0.636376        0.152318        1.000000   \n",
       "BlendProperty7         0.435700        0.380571        0.416414   \n",
       "BlendProperty8         0.641747        0.270996        0.574911   \n",
       "BlendProperty9         0.586330        0.028121        0.665098   \n",
       "BlendProperty10        0.358780        0.158801        0.255511   \n",
       "\n",
       "                 BlendProperty7  BlendProperty8  BlendProperty9  \\\n",
       "BlendProperty1         0.450704        0.644980        0.597190   \n",
       "BlendProperty2         0.432767        0.642155        0.603799   \n",
       "BlendProperty3         0.997246        0.627322        0.179044   \n",
       "BlendProperty4         0.435700        0.641747        0.586330   \n",
       "BlendProperty5         0.380571        0.270996        0.028121   \n",
       "BlendProperty6         0.416414        0.574911        0.665098   \n",
       "BlendProperty7         1.000000        0.629038        0.179592   \n",
       "BlendProperty8         0.629038        1.000000        0.474233   \n",
       "BlendProperty9         0.179592        0.474233        1.000000   \n",
       "BlendProperty10        0.510099        0.377589        0.158135   \n",
       "\n",
       "                 BlendProperty10  \n",
       "BlendProperty1          0.380908  \n",
       "BlendProperty2          0.284212  \n",
       "BlendProperty3          0.512494  \n",
       "BlendProperty4          0.358780  \n",
       "BlendProperty5          0.158801  \n",
       "BlendProperty6          0.255511  \n",
       "BlendProperty7          0.510099  \n",
       "BlendProperty8          0.377589  \n",
       "BlendProperty9          0.158135  \n",
       "BlendProperty10         1.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(output_blends.corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Min']      = train_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Max']      = train_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4276239847.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Variance'] = train_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Min']      = train_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Max']      = train_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4276239847.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Variance'] = train_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Min']      = train_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Max']      = train_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4276239847.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Variance'] = train_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Min']      = train_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Max']      = train_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4276239847.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Variance'] = train_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Min']      = train_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Max']      = train_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4276239847.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Variance'] = train_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Min']      = train_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Max']      = train_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4276239847.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Variance'] = train_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Min']      = train_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Max']      = train_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4276239847.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_Variance'] = train_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:72: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop_Mean'] = train_dataset[comp_props].mean(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop_Std']  = train_dataset[comp_props].std(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop_Mean'] = train_dataset[comp_props].mean(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop_Std']  = train_dataset[comp_props].std(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop_Mean'] = train_dataset[comp_props].mean(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop_Std']  = train_dataset[comp_props].std(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop_Mean'] = train_dataset[comp_props].mean(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop_Std']  = train_dataset[comp_props].std(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop_Mean'] = train_dataset[comp_props].mean(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:82: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop_Std']  = train_dataset[comp_props].std(axis=1)\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:85: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{frac_col}_Sq']   = train_dataset[frac_col] ** 2\n",
      "/tmp/ipykernel_92608/4276239847.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{frac_col}_Sqrt'] = np.sqrt(train_dataset[frac_col])\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/tmp/ipykernel_92608/4276239847.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{frac_col}_Sq']   = train_dataset[frac_col] ** 2\n",
      "/tmp/ipykernel_92608/4276239847.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{frac_col}_Sqrt'] = np.sqrt(train_dataset[frac_col])\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/tmp/ipykernel_92608/4276239847.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{frac_col}_Sq']   = train_dataset[frac_col] ** 2\n",
      "/tmp/ipykernel_92608/4276239847.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{frac_col}_Sqrt'] = np.sqrt(train_dataset[frac_col])\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/tmp/ipykernel_92608/4276239847.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{frac_col}_Sq']   = train_dataset[frac_col] ** 2\n",
      "/tmp/ipykernel_92608/4276239847.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{frac_col}_Sqrt'] = np.sqrt(train_dataset[frac_col])\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/tmp/ipykernel_92608/4276239847.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{frac_col}_Sq']   = train_dataset[frac_col] ** 2\n",
      "/tmp/ipykernel_92608/4276239847.py:96: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{frac_col}_Sqrt'] = np.sqrt(train_dataset[frac_col])\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4276239847.py:100: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
      "/tmp/ipykernel_92608/4276239847.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
      "/tmp/ipykernel_92608/4276239847.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:110: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4276239847.py:116: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Blend_Cluster'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 152\u001b[0m\n\u001b[1;32m    143\u001b[0m         train_dataset[contrib_col] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             train_dataset[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponent\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomp_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_fraction\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39m train_dataset[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponent\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomp_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Property\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    146\u001b[0m             \u001b[38;5;241m/\u001b[39m (train_dataset[w_col] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-10\u001b[39m)\n\u001b[1;32m    147\u001b[0m         )\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# 10.  CLEAN‑UP\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBlend_Cluster\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Blend_Cluster'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 0.  LOAD & COPY ORIGINAL DATAFRAME\n",
    "# ------------------------------------------------------------------\n",
    "# assume your raw dataframe is named `df`\n",
    "# train_dataset = df.copy()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  COLUMN SET‑UP\n",
    "# ------------------------------------------------------------------\n",
    "fraction_cols = [f'Component{i}_fraction' for i in range(1, 6)]\n",
    "\n",
    "property_cols = {}\n",
    "for prop_idx in range(1, 11):\n",
    "    property_cols[prop_idx] = [\n",
    "        f'Component{i}_Property{prop_idx}' for i in range(1, 6)\n",
    "    ]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  LINEAR BLEND FEATURES\n",
    "# ------------------------------------------------------------------\n",
    "for prop_idx in range(1, 11):\n",
    "    w_col = f'Weighted_Prop{prop_idx}'\n",
    "    train_dataset[w_col] = 0.0\n",
    "    for comp_idx in range(1, 6):\n",
    "        train_dataset[w_col] += (\n",
    "            train_dataset[f'Component{comp_idx}_fraction']\n",
    "            * train_dataset[f'Component{comp_idx}_Property{prop_idx}']\n",
    "        )\n",
    "    for comp_idx in range(1, 6):\n",
    "        train_dataset[f'Deviation_{comp_idx}_Prop{prop_idx}'] = (\n",
    "            train_dataset[f'Component{comp_idx}_Property{prop_idx}']\n",
    "            - train_dataset[w_col]\n",
    "        )\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  FRACTION‑BASED FEATURES\n",
    "# ------------------------------------------------------------------\n",
    "train_dataset['Fraction_Entropy'] = (\n",
    "    -train_dataset[fraction_cols] * np.log(train_dataset[fraction_cols] + 1e-10)\n",
    ").sum(axis=1)\n",
    "train_dataset['Dominant_Fraction'] = train_dataset[fraction_cols].max(axis=1)\n",
    "train_dataset['Fraction_Range']    = (\n",
    "    train_dataset[fraction_cols].max(axis=1)\n",
    "    - train_dataset[fraction_cols].min(axis=1)\n",
    ")\n",
    "\n",
    "for i in range(1, 6):\n",
    "    for j in range(i + 1, 6):\n",
    "        train_dataset[f'Frac_Interaction_{i}_{j}'] = (\n",
    "            train_dataset[f'Component{i}_fraction']\n",
    "            * train_dataset[f'Component{j}_fraction']\n",
    "        )\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  PROPERTY INTERACTION FEATURES\n",
    "# ------------------------------------------------------------------\n",
    "for prop_idx in range(1, 11):\n",
    "    cols = property_cols[prop_idx]\n",
    "    train_dataset[f'Prop{prop_idx}_Min']      = train_dataset[cols].min(axis=1)\n",
    "    train_dataset[f'Prop{prop_idx}_Max']      = train_dataset[cols].max(axis=1)\n",
    "    train_dataset[f'Prop{prop_idx}_Range']    = (\n",
    "        train_dataset[f'Prop{prop_idx}_Max'] - train_dataset[f'Prop{prop_idx}_Min']\n",
    "    )\n",
    "    train_dataset[f'Prop{prop_idx}_Variance'] = train_dataset[cols].var(axis=1)\n",
    "\n",
    "    max_vals = train_dataset[cols].max(axis=1)\n",
    "    for comp_idx in range(1, 6):\n",
    "        train_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
    "            train_dataset[cols[comp_idx - 1]] == max_vals\n",
    "        ).astype(int)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5.  CROSS‑PROPERTY INTERACTIONS\n",
    "# ------------------------------------------------------------------\n",
    "for comp_idx in range(1, 6):\n",
    "    comp_props = [f'Component{comp_idx}_Property{p}' for p in range(1, 11)]\n",
    "    train_dataset[f'Comp{comp_idx}_Prop_Mean'] = train_dataset[comp_props].mean(axis=1)\n",
    "    train_dataset[f'Comp{comp_idx}_Prop_Std']  = train_dataset[comp_props].std(axis=1)\n",
    "\n",
    "    for prop_idx in range(1, 11):\n",
    "        train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
    "            train_dataset[f'Component{comp_idx}_fraction']\n",
    "            * train_dataset[f'Component{comp_idx}_Property{prop_idx}']\n",
    "        )\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6.  NON‑LINEAR TRANSFORMATIONS\n",
    "# ------------------------------------------------------------------\n",
    "for comp_idx in range(1, 6):\n",
    "    frac_col = f'Component{comp_idx}_fraction'\n",
    "    train_dataset[f'{frac_col}_Sq']   = train_dataset[frac_col] ** 2\n",
    "    train_dataset[f'{frac_col}_Sqrt'] = np.sqrt(train_dataset[frac_col])\n",
    "\n",
    "    for prop_idx in range(1, 11):\n",
    "        col = f'Component{comp_idx}_Property{prop_idx}'\n",
    "        train_dataset[f'{col}_Log'] = np.log1p(train_dataset[col])\n",
    "        train_dataset[f'{col}_Sq']  = train_dataset[col] ** 2\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7.  MIXTURE CHARACTERISTICS\n",
    "# ------------------------------------------------------------------\n",
    "for prop_idx in range(1, 11):\n",
    "    cols = property_cols[prop_idx]\n",
    "    max_val = train_dataset[cols].max(axis=1)\n",
    "    min_val = train_dataset[cols].min(axis=1)\n",
    "    train_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
    "        (max_val - min_val) / (max_val + 1e-10)\n",
    "    )\n",
    "\n",
    "    for comp_idx in range(1, 6):\n",
    "        col = f'Component{comp_idx}_Property{prop_idx}'\n",
    "        train_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
    "            train_dataset[col] * (1 + train_dataset[f'Component{comp_idx}_fraction'])\n",
    "        )\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 8.  CLUSTER LABEL (optional, no target leak)\n",
    "# ------------------------------------------------------------------\n",
    "cluster_features = [f'Weighted_Prop{i}' for i in range(1, 11)] + fraction_cols\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "# fit on train\n",
    "_ = kmeans.fit(train_dataset[cluster_features])\n",
    "\n",
    "# train: compute distances to each center\n",
    "train_dists = kmeans.transform(train_dataset[cluster_features])\n",
    "train_dist_df = pd.DataFrame(\n",
    "    train_dists,\n",
    "    columns=[f'Cluster_Dist_{i}' for i in range(5)],\n",
    "    index=train_dataset.index\n",
    ")\n",
    "train_dataset = pd.concat([train_dataset, train_dist_df], axis=1)\n",
    "# ------------------------------------------------------------------\n",
    "# 9.  TARGET‑INDEPENDENT CONTRIBUTIONS\n",
    "# ------------------------------------------------------------------\n",
    "for target_idx in range(1, 11):\n",
    "    w_col = f'Weighted_Prop{target_idx}'\n",
    "    for comp_idx in range(1, 6):\n",
    "        contrib_col = f'Comp{comp_idx}_Contrib_Prop{target_idx}'\n",
    "        train_dataset[contrib_col] = (\n",
    "            train_dataset[f'Component{comp_idx}_fraction']\n",
    "            * train_dataset[f'Component{comp_idx}_Property{target_idx}']\n",
    "            / (train_dataset[w_col] + 1e-10)\n",
    "        )\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 10.  CLEAN‑UP\n",
    "# ------------------------------------------------------------------\n",
    "train_dataset.drop(columns=['Blend_Cluster'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component1_fraction</th>\n",
       "      <th>Component2_fraction</th>\n",
       "      <th>Component3_fraction</th>\n",
       "      <th>Component4_fraction</th>\n",
       "      <th>Component5_fraction</th>\n",
       "      <th>Component1_Property1</th>\n",
       "      <th>Component2_Property1</th>\n",
       "      <th>Component3_Property1</th>\n",
       "      <th>Component4_Property1</th>\n",
       "      <th>Component5_Property1</th>\n",
       "      <th>...</th>\n",
       "      <th>Comp1_Contrib_Prop9</th>\n",
       "      <th>Comp2_Contrib_Prop9</th>\n",
       "      <th>Comp3_Contrib_Prop9</th>\n",
       "      <th>Comp4_Contrib_Prop9</th>\n",
       "      <th>Comp5_Contrib_Prop9</th>\n",
       "      <th>Comp1_Contrib_Prop10</th>\n",
       "      <th>Comp2_Contrib_Prop10</th>\n",
       "      <th>Comp3_Contrib_Prop10</th>\n",
       "      <th>Comp4_Contrib_Prop10</th>\n",
       "      <th>Comp5_Contrib_Prop10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.021782</td>\n",
       "      <td>1.981251</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0.140315</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>26.889721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-50.486585</td>\n",
       "      <td>44.953230</td>\n",
       "      <td>-20.356366</td>\n",
       "      <td>0.553231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279444</td>\n",
       "      <td>-0.525630</td>\n",
       "      <td>0.692954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.224339</td>\n",
       "      <td>1.148036</td>\n",
       "      <td>-1.107840</td>\n",
       "      <td>0.149533</td>\n",
       "      <td>-0.354000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299647</td>\n",
       "      <td>0.049479</td>\n",
       "      <td>1.174108</td>\n",
       "      <td>-0.523234</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.037708</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.041973</td>\n",
       "      <td>0.912665</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.457763</td>\n",
       "      <td>0.242591</td>\n",
       "      <td>-0.922492</td>\n",
       "      <td>0.908213</td>\n",
       "      <td>0.972003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142130</td>\n",
       "      <td>0.078988</td>\n",
       "      <td>-0.059399</td>\n",
       "      <td>0.882339</td>\n",
       "      <td>-0.044057</td>\n",
       "      <td>-0.009046</td>\n",
       "      <td>-0.885818</td>\n",
       "      <td>-0.046045</td>\n",
       "      <td>0.816799</td>\n",
       "      <td>1.124109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.577734</td>\n",
       "      <td>-0.930826</td>\n",
       "      <td>0.815284</td>\n",
       "      <td>0.447514</td>\n",
       "      <td>0.455717</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.026313</td>\n",
       "      <td>3.730034</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.242188</td>\n",
       "      <td>-1.945908</td>\n",
       "      <td>-0.033191</td>\n",
       "      <td>1.078722</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.421151</td>\n",
       "      <td>0.375619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.120415</td>\n",
       "      <td>0.666268</td>\n",
       "      <td>-0.626934</td>\n",
       "      <td>2.725357</td>\n",
       "      <td>0.392259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101491</td>\n",
       "      <td>0.288618</td>\n",
       "      <td>-0.073178</td>\n",
       "      <td>0.886051</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.544546</td>\n",
       "      <td>0.136689</td>\n",
       "      <td>-0.037341</td>\n",
       "      <td>0.356107</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>-0.054170</td>\n",
       "      <td>-0.391227</td>\n",
       "      <td>0.400222</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588973</td>\n",
       "      <td>0.206885</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.108984</td>\n",
       "      <td>0.095158</td>\n",
       "      <td>26.030345</td>\n",
       "      <td>-27.143699</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>14.549770</td>\n",
       "      <td>-12.436416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.887185</td>\n",
       "      <td>0.610050</td>\n",
       "      <td>0.178606</td>\n",
       "      <td>1.083154</td>\n",
       "      <td>-2.822749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.580659</td>\n",
       "      <td>0.949748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.919396</td>\n",
       "      <td>-1.288486</td>\n",
       "      <td>0.271925</td>\n",
       "      <td>0.622911</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.054979</td>\n",
       "      <td>0.160144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.568978</td>\n",
       "      <td>-0.196759</td>\n",
       "      <td>-0.646318</td>\n",
       "      <td>-0.980070</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.982363</td>\n",
       "      <td>-0.460069</td>\n",
       "      <td>-2.979187</td>\n",
       "      <td>9.739846</td>\n",
       "      <td>6.681772</td>\n",
       "      <td>0.559495</td>\n",
       "      <td>0.217411</td>\n",
       "      <td>0.069391</td>\n",
       "      <td>0.087357</td>\n",
       "      <td>0.066346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.067453</td>\n",
       "      <td>0.321977</td>\n",
       "      <td>-0.137535</td>\n",
       "      <td>0.238507</td>\n",
       "      <td>0.017455</td>\n",
       "      <td>...</td>\n",
       "      <td>1.181403</td>\n",
       "      <td>-0.277124</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.144067</td>\n",
       "      <td>-0.048345</td>\n",
       "      <td>0.748410</td>\n",
       "      <td>-0.014673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192484</td>\n",
       "      <td>0.073780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.284090</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>-0.831267</td>\n",
       "      <td>-1.084474</td>\n",
       "      <td>0.845087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768723</td>\n",
       "      <td>1.810005</td>\n",
       "      <td>-1.578728</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475306</td>\n",
       "      <td>0.018492</td>\n",
       "      <td>0.506202</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Component1_fraction  Component2_fraction  Component3_fraction  \\\n",
       "0                    0.21                 0.00                 0.42   \n",
       "1                    0.02                 0.33                 0.19   \n",
       "2                    0.08                 0.08                 0.18   \n",
       "3                    0.25                 0.42                 0.00   \n",
       "4                    0.26                 0.16                 0.08   \n",
       "...                   ...                  ...                  ...   \n",
       "1995                 0.50                 0.12                 0.00   \n",
       "1996                 0.19                 0.31                 0.00   \n",
       "1997                 0.38                 0.06                 0.14   \n",
       "1998                 0.50                 0.16                 0.00   \n",
       "1999                 0.00                 0.34                 0.21   \n",
       "\n",
       "      Component4_fraction  Component5_fraction  Component1_Property1  \\\n",
       "0                    0.25                 0.12             -0.021782   \n",
       "1                    0.46                 0.00             -0.224339   \n",
       "2                    0.50                 0.16              0.457763   \n",
       "3                    0.07                 0.26             -0.577734   \n",
       "4                    0.50                 0.00              0.120415   \n",
       "...                   ...                  ...                   ...   \n",
       "1995                 0.26                 0.12              0.279523   \n",
       "1996                 0.37                 0.13             -0.887185   \n",
       "1997                 0.31                 0.11              0.568978   \n",
       "1998                 0.18                 0.16             -0.067453   \n",
       "1999                 0.45                 0.00              0.284090   \n",
       "\n",
       "      Component2_Property1  Component3_Property1  Component4_Property1  \\\n",
       "0                 1.981251              0.020036              0.140315   \n",
       "1                 1.148036             -1.107840              0.149533   \n",
       "2                 0.242591             -0.922492              0.908213   \n",
       "3                -0.930826              0.815284              0.447514   \n",
       "4                 0.666268             -0.626934              2.725357   \n",
       "...                    ...                   ...                   ...   \n",
       "1995             -0.054170             -0.391227              0.400222   \n",
       "1996              0.610050              0.178606              1.083154   \n",
       "1997             -0.196759             -0.646318             -0.980070   \n",
       "1998              0.321977             -0.137535              0.238507   \n",
       "1999              0.189099             -0.831267             -1.084474   \n",
       "\n",
       "      Component5_Property1  ...  Comp1_Contrib_Prop9  Comp2_Contrib_Prop9  \\\n",
       "0                 1.032029  ...            26.889721             0.000000   \n",
       "1                -0.354000  ...             0.299647             0.049479   \n",
       "2                 0.972003  ...             0.142130             0.078988   \n",
       "3                 0.455717  ...            -1.026313             3.730034   \n",
       "4                 0.392259  ...            -0.101491             0.288618   \n",
       "...                    ...  ...                  ...                  ...   \n",
       "1995              1.032029  ...             0.588973             0.206885   \n",
       "1996             -2.822749  ...            -0.580659             0.949748   \n",
       "1997              1.032029  ...           -11.982363            -0.460069   \n",
       "1998              0.017455  ...             1.181403            -0.277124   \n",
       "1999              0.845087  ...             0.000000             0.768723   \n",
       "\n",
       "      Comp3_Contrib_Prop9  Comp4_Contrib_Prop9  Comp5_Contrib_Prop9  \\\n",
       "0              -50.486585            44.953230           -20.356366   \n",
       "1                1.174108            -0.523234            -0.000000   \n",
       "2               -0.059399             0.882339            -0.044057   \n",
       "3               -0.000000             0.242188            -1.945908   \n",
       "4               -0.073178             0.886051            -0.000000   \n",
       "...                   ...                  ...                  ...   \n",
       "1995            -0.000000             0.108984             0.095158   \n",
       "1996             0.000000             1.919396            -1.288486   \n",
       "1997            -2.979187             9.739846             6.681772   \n",
       "1998            -0.000000             0.144067            -0.048345   \n",
       "1999             1.810005            -1.578728            -0.000000   \n",
       "\n",
       "      Comp1_Contrib_Prop10  Comp2_Contrib_Prop10  Comp3_Contrib_Prop10  \\\n",
       "0                 0.553231              0.000000              0.279444   \n",
       "1                 0.037708              0.007654              0.041973   \n",
       "2                -0.009046             -0.885818             -0.046045   \n",
       "3                -0.033191              1.078722             -0.000000   \n",
       "4                 0.544546              0.136689             -0.037341   \n",
       "...                    ...                   ...                   ...   \n",
       "1995             26.030345            -27.143699             -0.000000   \n",
       "1996              0.271925              0.622911             -0.000000   \n",
       "1997              0.559495              0.217411              0.069391   \n",
       "1998              0.748410             -0.014673              0.000000   \n",
       "1999              0.000000              0.475306              0.018492   \n",
       "\n",
       "      Comp4_Contrib_Prop10  Comp5_Contrib_Prop10  \n",
       "0                -0.525630              0.692954  \n",
       "1                 0.912665             -0.000000  \n",
       "2                 0.816799              1.124109  \n",
       "3                -0.421151              0.375619  \n",
       "4                 0.356107             -0.000000  \n",
       "...                    ...                   ...  \n",
       "1995             14.549770            -12.436416  \n",
       "1996             -0.054979              0.160144  \n",
       "1997              0.087357              0.066346  \n",
       "1998              0.192484              0.073780  \n",
       "1999              0.506202             -0.000000  \n",
       "\n",
       "[2000 rows x 503 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Min']      = test_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Max']      = test_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4065723515.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Variance'] = test_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Min']      = test_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Max']      = test_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4065723515.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Variance'] = test_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Min']      = test_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Max']      = test_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4065723515.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Variance'] = test_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Min']      = test_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Max']      = test_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4065723515.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Variance'] = test_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Min']      = test_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Max']      = test_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4065723515.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Variance'] = test_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Min']      = test_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Max']      = test_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4065723515.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Variance'] = test_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:61: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Min']      = test_dataset[cols].min(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Max']      = test_dataset[cols].max(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Range']    = (\n",
      "/tmp/ipykernel_92608/4065723515.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_Variance'] = test_dataset[cols].var(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop_Mean'] = test_dataset[comp_props].mean(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop_Std']  = test_dataset[comp_props].std(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop_Mean'] = test_dataset[comp_props].mean(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop_Std']  = test_dataset[comp_props].std(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop_Mean'] = test_dataset[comp_props].mean(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop_Std']  = test_dataset[comp_props].std(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop_Mean'] = test_dataset[comp_props].mean(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop_Std']  = test_dataset[comp_props].std(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop_Mean'] = test_dataset[comp_props].mean(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop_Std']  = test_dataset[comp_props].std(axis=1)\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:83: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{frac_col}_Sq']   = test_dataset[frac_col] ** 2\n",
      "/tmp/ipykernel_92608/4065723515.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{frac_col}_Sqrt'] = np.sqrt(test_dataset[frac_col])\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/tmp/ipykernel_92608/4065723515.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{frac_col}_Sq']   = test_dataset[frac_col] ** 2\n",
      "/tmp/ipykernel_92608/4065723515.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{frac_col}_Sqrt'] = np.sqrt(test_dataset[frac_col])\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/tmp/ipykernel_92608/4065723515.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{frac_col}_Sq']   = test_dataset[frac_col] ** 2\n",
      "/tmp/ipykernel_92608/4065723515.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{frac_col}_Sqrt'] = np.sqrt(test_dataset[frac_col])\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/tmp/ipykernel_92608/4065723515.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{frac_col}_Sq']   = test_dataset[frac_col] ** 2\n",
      "/tmp/ipykernel_92608/4065723515.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{frac_col}_Sqrt'] = np.sqrt(test_dataset[frac_col])\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/tmp/ipykernel_92608/4065723515.py:93: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{frac_col}_Sq']   = test_dataset[frac_col] ** 2\n",
      "/tmp/ipykernel_92608/4065723515.py:94: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{frac_col}_Sqrt'] = np.sqrt(test_dataset[frac_col])\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/tmp/ipykernel_92608/4065723515.py:98: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
      "/tmp/ipykernel_92608/4065723515.py:99: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
      "/tmp/ipykernel_92608/4065723515.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
      "/tmp/ipykernel_92608/4065723515.py:114: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Blend_Cluster'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 148\u001b[0m\n\u001b[1;32m    139\u001b[0m         test_dataset[contrib_col] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    140\u001b[0m             test_dataset[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponent\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomp_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_fraction\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;241m*\u001b[39m test_dataset[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponent\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcomp_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Property\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprop_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;241m/\u001b[39m (test_dataset[w_col] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-10\u001b[39m)\n\u001b[1;32m    143\u001b[0m         )\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# 10. CLEAN-UP\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m \u001b[43mtest_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBlend_Cluster\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Blend_Cluster'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0. COPY RAW TEST DATA\n",
    "# ------------------------------------------------------------\n",
    "# assume your test dataframe is named `test_df`\n",
    "# test_dataset = test_df.copy()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. COLUMN SETUP\n",
    "# ------------------------------------------------------------\n",
    "fraction_cols = [f'Component{i}_fraction' for i in range(1, 6)]\n",
    "property_cols = {\n",
    "    prop_idx: [f'Component{i}_Property{prop_idx}' for i in range(1, 6)]\n",
    "    for prop_idx in range(1, 11)\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. LINEAR BLEND FEATURES\n",
    "# ------------------------------------------------------------\n",
    "for prop_idx in range(1, 11):\n",
    "    w_col = f'Weighted_Prop{prop_idx}'\n",
    "    test_dataset[w_col] = 0.0\n",
    "    for comp_idx in range(1, 6):\n",
    "        test_dataset[w_col] += (\n",
    "            test_dataset[f'Component{comp_idx}_fraction']\n",
    "            * test_dataset[f'Component{comp_idx}_Property{prop_idx}']\n",
    "        )\n",
    "    for comp_idx in range(1, 6):\n",
    "        test_dataset[f'Deviation_{comp_idx}_Prop{prop_idx}'] = (\n",
    "            test_dataset[f'Component{comp_idx}_Property{prop_idx}']\n",
    "            - test_dataset[w_col]\n",
    "        )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. FRACTION-BASED FEATURES\n",
    "# ------------------------------------------------------------\n",
    "test_dataset['Fraction_Entropy'] = (\n",
    "    -test_dataset[fraction_cols] * np.log(test_dataset[fraction_cols] + 1e-10)\n",
    ").sum(axis=1)\n",
    "test_dataset['Dominant_Fraction'] = test_dataset[fraction_cols].max(axis=1)\n",
    "test_dataset['Fraction_Range']    = (\n",
    "    test_dataset[fraction_cols].max(axis=1)\n",
    "    - test_dataset[fraction_cols].min(axis=1)\n",
    ")\n",
    "\n",
    "for i in range(1, 6):\n",
    "    for j in range(i + 1, 6):\n",
    "        test_dataset[f'Frac_Interaction_{i}_{j}'] = (\n",
    "            test_dataset[f'Component{i}_fraction']\n",
    "            * test_dataset[f'Component{j}_fraction']\n",
    "        )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. PROPERTY INTERACTION FEATURES\n",
    "# ------------------------------------------------------------\n",
    "for prop_idx in range(1, 11):\n",
    "    cols = property_cols[prop_idx]\n",
    "    test_dataset[f'Prop{prop_idx}_Min']      = test_dataset[cols].min(axis=1)\n",
    "    test_dataset[f'Prop{prop_idx}_Max']      = test_dataset[cols].max(axis=1)\n",
    "    test_dataset[f'Prop{prop_idx}_Range']    = (\n",
    "        test_dataset[f'Prop{prop_idx}_Max'] - test_dataset[f'Prop{prop_idx}_Min']\n",
    "    )\n",
    "    test_dataset[f'Prop{prop_idx}_Variance'] = test_dataset[cols].var(axis=1)\n",
    "\n",
    "    max_vals = test_dataset[cols].max(axis=1)\n",
    "    for comp_idx in range(1, 6):\n",
    "        test_dataset[f'IsMax_Comp{comp_idx}_Prop{prop_idx}'] = (\n",
    "            test_dataset[cols[comp_idx - 1]] == max_vals\n",
    "        ).astype(int)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. CROSS-PROPERTY INTERACTIONS\n",
    "# ------------------------------------------------------------\n",
    "for comp_idx in range(1, 6):\n",
    "    comp_props = [f'Component{comp_idx}_Property{p}' for p in range(1, 11)]\n",
    "    test_dataset[f'Comp{comp_idx}_Prop_Mean'] = test_dataset[comp_props].mean(axis=1)\n",
    "    test_dataset[f'Comp{comp_idx}_Prop_Std']  = test_dataset[comp_props].std(axis=1)\n",
    "\n",
    "    for prop_idx in range(1, 11):\n",
    "        test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Scaled'] = (\n",
    "            test_dataset[f'Component{comp_idx}_fraction']\n",
    "            * test_dataset[f'Component{comp_idx}_Property{prop_idx}']\n",
    "        )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. NON-LINEAR TRANSFORMATIONS\n",
    "# ------------------------------------------------------------\n",
    "for comp_idx in range(1, 6):\n",
    "    frac_col = f'Component{comp_idx}_fraction'\n",
    "    test_dataset[f'{frac_col}_Sq']   = test_dataset[frac_col] ** 2\n",
    "    test_dataset[f'{frac_col}_Sqrt'] = np.sqrt(test_dataset[frac_col])\n",
    "\n",
    "    for prop_idx in range(1, 11):\n",
    "        col = f'Component{comp_idx}_Property{prop_idx}'\n",
    "        test_dataset[f'{col}_Log'] = np.log1p(test_dataset[col])\n",
    "        test_dataset[f'{col}_Sq']  = test_dataset[col] ** 2\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. MIXTURE CHARACTERISTICS\n",
    "# ------------------------------------------------------------\n",
    "for prop_idx in range(1, 11):\n",
    "    cols = property_cols[prop_idx]\n",
    "    max_val = test_dataset[cols].max(axis=1)\n",
    "    min_val = test_dataset[cols].min(axis=1)\n",
    "    test_dataset[f'Prop{prop_idx}_BlendRatio'] = (\n",
    "        (max_val - min_val) / (max_val + 1e-10)\n",
    "    )\n",
    "\n",
    "    for comp_idx in range(1, 6):\n",
    "        col = f'Component{comp_idx}_Property{prop_idx}'\n",
    "        test_dataset[f'Comp{comp_idx}_Prop{prop_idx}_Adj'] = (\n",
    "            test_dataset[col] * (1 + test_dataset[f'Component{comp_idx}_fraction'])\n",
    "        )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8. OPTIONAL: CLUSTER LABEL (no target leak)\n",
    "# ------------------------------------------------------------\n",
    "cluster_features = [f'Weighted_Prop{i}' for i in range(1, 11)] + fraction_cols\n",
    "\n",
    "# test: compute distances\n",
    "test_dists = kmeans.transform(test_dataset[cluster_features])\n",
    "test_dist_df = pd.DataFrame(\n",
    "    test_dists,\n",
    "    columns=[f'Cluster_Dist_{i}' for i in range(5)],\n",
    "    index=test_dataset.index\n",
    ")\n",
    "test_dataset = pd.concat([test_dataset, test_dist_df], axis=1)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9. TARGET-INDEPENDENT CONTRIBUTIONS\n",
    "# ------------------------------------------------------------\n",
    "for prop_idx in range(1, 11):\n",
    "    w_col = f'Weighted_Prop{prop_idx}'\n",
    "    for comp_idx in range(1, 6):\n",
    "        contrib_col = f'Comp{comp_idx}_Contrib_Prop{prop_idx}'\n",
    "        test_dataset[contrib_col] = (\n",
    "            test_dataset[f'Component{comp_idx}_fraction']\n",
    "            * test_dataset[f'Component{comp_idx}_Property{prop_idx}']\n",
    "            / (test_dataset[w_col] + 1e-10)\n",
    "        )\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 10. CLEAN-UP\n",
    "# ------------------------------------------------------------\n",
    "test_dataset.drop(columns=['Blend_Cluster'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Add More Featurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component1_fraction</th>\n",
       "      <th>Component2_fraction</th>\n",
       "      <th>Component3_fraction</th>\n",
       "      <th>Component4_fraction</th>\n",
       "      <th>Component5_fraction</th>\n",
       "      <th>Component1_Property1</th>\n",
       "      <th>Component2_Property1</th>\n",
       "      <th>Component3_Property1</th>\n",
       "      <th>Component4_Property1</th>\n",
       "      <th>Component5_Property1</th>\n",
       "      <th>...</th>\n",
       "      <th>Comp1_Contrib_Prop9</th>\n",
       "      <th>Comp2_Contrib_Prop9</th>\n",
       "      <th>Comp3_Contrib_Prop9</th>\n",
       "      <th>Comp4_Contrib_Prop9</th>\n",
       "      <th>Comp5_Contrib_Prop9</th>\n",
       "      <th>Comp1_Contrib_Prop10</th>\n",
       "      <th>Comp2_Contrib_Prop10</th>\n",
       "      <th>Comp3_Contrib_Prop10</th>\n",
       "      <th>Comp4_Contrib_Prop10</th>\n",
       "      <th>Comp5_Contrib_Prop10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.177804</td>\n",
       "      <td>-0.741219</td>\n",
       "      <td>0.769821</td>\n",
       "      <td>-0.877069</td>\n",
       "      <td>0.602809</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.613360</td>\n",
       "      <td>0.854447</td>\n",
       "      <td>1.264097</td>\n",
       "      <td>-8.880794</td>\n",
       "      <td>14.375610</td>\n",
       "      <td>-5.896530</td>\n",
       "      <td>1.596623</td>\n",
       "      <td>-20.281949</td>\n",
       "      <td>19.282980</td>\n",
       "      <td>6.298877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.501354</td>\n",
       "      <td>0.177344</td>\n",
       "      <td>-0.498739</td>\n",
       "      <td>-0.196742</td>\n",
       "      <td>-1.943463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365887</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.702329</td>\n",
       "      <td>-0.068216</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.136398</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.271652</td>\n",
       "      <td>-0.408050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.547324</td>\n",
       "      <td>0.891479</td>\n",
       "      <td>0.030627</td>\n",
       "      <td>-0.368678</td>\n",
       "      <td>-0.294728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.325015</td>\n",
       "      <td>1.111306</td>\n",
       "      <td>-0.034776</td>\n",
       "      <td>-0.709326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.256346</td>\n",
       "      <td>1.838264</td>\n",
       "      <td>0.127407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.424427</td>\n",
       "      <td>1.016862</td>\n",
       "      <td>-1.182979</td>\n",
       "      <td>-0.854225</td>\n",
       "      <td>-0.830186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516786</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.024645</td>\n",
       "      <td>0.216259</td>\n",
       "      <td>0.242310</td>\n",
       "      <td>2.080386</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>1.322353</td>\n",
       "      <td>-2.404868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.187062</td>\n",
       "      <td>-0.762173</td>\n",
       "      <td>-0.473660</td>\n",
       "      <td>2.074087</td>\n",
       "      <td>0.756849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.973529</td>\n",
       "      <td>-0.973529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.617826</td>\n",
       "      <td>3.617826</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.036797</td>\n",
       "      <td>1.415667</td>\n",
       "      <td>0.793302</td>\n",
       "      <td>-0.446630</td>\n",
       "      <td>0.395524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685804</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>0.063311</td>\n",
       "      <td>0.202802</td>\n",
       "      <td>0.046744</td>\n",
       "      <td>0.780083</td>\n",
       "      <td>0.009782</td>\n",
       "      <td>0.030665</td>\n",
       "      <td>0.225261</td>\n",
       "      <td>-0.045791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-1.305137</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>-0.989537</td>\n",
       "      <td>0.903203</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118870</td>\n",
       "      <td>0.912187</td>\n",
       "      <td>-0.079909</td>\n",
       "      <td>0.088940</td>\n",
       "      <td>-0.040088</td>\n",
       "      <td>0.529741</td>\n",
       "      <td>0.827689</td>\n",
       "      <td>-0.010229</td>\n",
       "      <td>-0.209668</td>\n",
       "      <td>-0.137534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.806590</td>\n",
       "      <td>0.607324</td>\n",
       "      <td>0.359058</td>\n",
       "      <td>0.283394</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190230</td>\n",
       "      <td>0.008189</td>\n",
       "      <td>0.112344</td>\n",
       "      <td>0.314207</td>\n",
       "      <td>0.375031</td>\n",
       "      <td>1.473952</td>\n",
       "      <td>0.033349</td>\n",
       "      <td>0.165223</td>\n",
       "      <td>-0.655451</td>\n",
       "      <td>-0.017072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.792140</td>\n",
       "      <td>0.674275</td>\n",
       "      <td>-1.783487</td>\n",
       "      <td>0.848296</td>\n",
       "      <td>0.164798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308757</td>\n",
       "      <td>0.013231</td>\n",
       "      <td>-0.509276</td>\n",
       "      <td>0.480761</td>\n",
       "      <td>0.706528</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>0.135626</td>\n",
       "      <td>0.494294</td>\n",
       "      <td>0.469566</td>\n",
       "      <td>-0.103506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.327778</td>\n",
       "      <td>0.248042</td>\n",
       "      <td>-1.199065</td>\n",
       "      <td>1.845241</td>\n",
       "      <td>0.772672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.176398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.176398</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640390</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Component1_fraction  Component2_fraction  Component3_fraction  \\\n",
       "ID                                                                   \n",
       "1                   0.18                 0.05                 0.32   \n",
       "2                   0.00                 0.50                 0.00   \n",
       "3                   0.16                 0.00                 0.17   \n",
       "4                   0.50                 0.00                 0.17   \n",
       "5                   0.00                 0.00                 0.50   \n",
       "..                   ...                  ...                  ...   \n",
       "496                 0.44                 0.01                 0.08   \n",
       "497                 0.19                 0.47                 0.03   \n",
       "498                 0.43                 0.01                 0.12   \n",
       "499                 0.03                 0.04                 0.42   \n",
       "500                 0.00                 0.50                 0.00   \n",
       "\n",
       "     Component4_fraction  Component5_fraction  Component1_Property1  \\\n",
       "ID                                                                    \n",
       "1                   0.37                 0.08             -0.177804   \n",
       "2                   0.37                 0.13              2.501354   \n",
       "3                   0.50                 0.17              1.547324   \n",
       "4                   0.16                 0.17             -0.424427   \n",
       "5                   0.50                 0.00             -0.187062   \n",
       "..                   ...                  ...                   ...   \n",
       "496                 0.41                 0.06              1.036797   \n",
       "497                 0.23                 0.08             -1.305137   \n",
       "498                 0.21                 0.23              0.806590   \n",
       "499                 0.42                 0.09             -0.792140   \n",
       "500                 0.50                 0.00             -0.327778   \n",
       "\n",
       "     Component2_Property1  Component3_Property1  Component4_Property1  \\\n",
       "ID                                                                      \n",
       "1               -0.741219              0.769821             -0.877069   \n",
       "2                0.177344             -0.498739             -0.196742   \n",
       "3                0.891479              0.030627             -0.368678   \n",
       "4                1.016862             -1.182979             -0.854225   \n",
       "5               -0.762173             -0.473660              2.074087   \n",
       "..                    ...                   ...                   ...   \n",
       "496              1.415667              0.793302             -0.446630   \n",
       "497             -1.520941             -0.989537              0.903203   \n",
       "498              0.607324              0.359058              0.283394   \n",
       "499              0.674275             -1.783487              0.848296   \n",
       "500              0.248042             -1.199065              1.845241   \n",
       "\n",
       "     Component5_Property1  ...  Comp1_Contrib_Prop9  Comp2_Contrib_Prop9  \\\n",
       "ID                         ...                                             \n",
       "1                0.602809  ...            -6.613360             0.854447   \n",
       "2               -1.943463  ...             0.000000             0.365887   \n",
       "3               -0.294728  ...             0.248486             0.000000   \n",
       "4               -0.830186  ...             0.516786            -0.000000   \n",
       "5                0.756849  ...             0.000000             0.000000   \n",
       "..                    ...  ...                  ...                  ...   \n",
       "496              0.395524  ...             0.685804             0.001340   \n",
       "497              1.032029  ...             0.118870             0.912187   \n",
       "498              1.032029  ...             0.190230             0.008189   \n",
       "499              0.164798  ...             0.308757             0.013231   \n",
       "500              0.772672  ...             0.000000            -0.176398   \n",
       "\n",
       "     Comp3_Contrib_Prop9  Comp4_Contrib_Prop9  Comp5_Contrib_Prop9  \\\n",
       "ID                                                                   \n",
       "1               1.264097            -8.880794            14.375610   \n",
       "2               0.000000             0.702329            -0.068216   \n",
       "3              -0.325015             1.111306            -0.034776   \n",
       "4               0.024645             0.216259             0.242310   \n",
       "5               1.973529            -0.973529             0.000000   \n",
       "..                   ...                  ...                  ...   \n",
       "496             0.063311             0.202802             0.046744   \n",
       "497            -0.079909             0.088940            -0.040088   \n",
       "498             0.112344             0.314207             0.375031   \n",
       "499            -0.509276             0.480761             0.706528   \n",
       "500             0.000000             1.176398            -0.000000   \n",
       "\n",
       "     Comp1_Contrib_Prop10  Comp2_Contrib_Prop10  Comp3_Contrib_Prop10  \\\n",
       "ID                                                                      \n",
       "1               -5.896530              1.596623            -20.281949   \n",
       "2               -0.000000              1.136398             -0.000000   \n",
       "3               -0.709326              0.000000             -0.256346   \n",
       "4                2.080386             -0.000000              0.002130   \n",
       "5               -0.000000              0.000000             -2.617826   \n",
       "..                    ...                   ...                   ...   \n",
       "496              0.780083              0.009782              0.030665   \n",
       "497              0.529741              0.827689             -0.010229   \n",
       "498              1.473952              0.033349              0.165223   \n",
       "499              0.004020              0.135626              0.494294   \n",
       "500              0.000000              0.359610              0.000000   \n",
       "\n",
       "     Comp4_Contrib_Prop10  Comp5_Contrib_Prop10  \n",
       "ID                                               \n",
       "1               19.282980              6.298877  \n",
       "2                0.271652             -0.408050  \n",
       "3                1.838264              0.127407  \n",
       "4                1.322353             -2.404868  \n",
       "5                3.617826              0.000000  \n",
       "..                    ...                   ...  \n",
       "496              0.225261             -0.045791  \n",
       "497             -0.209668             -0.137534  \n",
       "498             -0.655451             -0.017072  \n",
       "499              0.469566             -0.103506  \n",
       "500              0.640390              0.000000  \n",
       "\n",
       "[500 rows x 503 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def create_blending_features(df):\n",
    "    # Create a copy to avoid modifying original data\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Assumptions about property indices (based on petroleum blending domain knowledge):\n",
    "    # Property1: API Gravity (density measure)\n",
    "    # Property2: RVP (Reid Vapor Pressure)\n",
    "    # Property3: RON (Research Octane Number)\n",
    "    # Property4: Olefins content\n",
    "    # Property5: Aromatics content\n",
    "    # Property6: T10 (10% distillation temperature)\n",
    "    # Property7: T50 (50% distillation temperature)\n",
    "    # Property8: T90 (90% distillation temperature)\n",
    "    # Property9: Viscosity\n",
    "    # Property10: Cetane Index\n",
    "    \n",
    "    # 1. Density and Gravity Features\n",
    "    for i in range(1, 6):\n",
    "        # Convert API to Specific Gravity (60/60)\n",
    "        df[f'Component{i}_SG'] = 141.5 / (df[f'Component{i}_Property1'] + 131.5)\n",
    "        \n",
    "        # Calculate density blending index\n",
    "        df[f'Component{i}_Density_Index'] = df[f'Component{i}_SG'] ** (-0.06)\n",
    "    \n",
    "    # Blend density index volumetrically\n",
    "    df['Blend_Density_Index'] = 0\n",
    "    for i in range(1, 6):\n",
    "        df['Blend_Density_Index'] += df[f'Component{i}_fraction'] * df[f'Component{i}_Density_Index']\n",
    "    \n",
    "    # Convert back to specific gravity\n",
    "    df['Blend_SG'] = df['Blend_Density_Index'] ** (-1/0.06)\n",
    "    df['Blend_API'] = (141.5 / df['Blend_SG']) - 131.5\n",
    "    \n",
    "    # 2. Sulfur Blending (gravimetric) - assuming Property2 is sulfur-related\n",
    "    df['Blend_Sulfur'] = 0\n",
    "    for i in range(1, 6):\n",
    "        df['Blend_Sulfur'] += (df[f'Component{i}_fraction'] * df[f'Component{i}_SG'] * \n",
    "                              df[f'Component{i}_Property2']) / df['Blend_SG']\n",
    "    \n",
    "    # 3. RVP Blending (Index Method)\n",
    "    rvp_exponent = -0.07  # Texaco method exponent\n",
    "    for i in range(1, 6):\n",
    "        df[f'Component{i}_RVP_Index'] = df[f'Component{i}_Property2'] ** rvp_exponent\n",
    "    \n",
    "    df['Blend_RVP_Index'] = 0\n",
    "    for i in range(1, 6):\n",
    "        df['Blend_RVP_Index'] += df[f'Component{i}_fraction'] * df[f'Component{i}_RVP_Index']\n",
    "    \n",
    "    df['Blend_RVP'] = df['Blend_RVP_Index'] ** (1/rvp_exponent)\n",
    "    \n",
    "    # 4. Octane Blending (Ethyl RT-70 method)\n",
    "    for i in range(1, 6):\n",
    "        # Simplified octane interaction term\n",
    "        df[f'Component{i}_RON_BlendValue'] = (\n",
    "            df[f'Component{i}_Property3'] + \n",
    "            0.1 * df[f'Component{i}_Property4'] - \n",
    "            0.05 * df[f'Component{i}_Property5']\n",
    "        )\n",
    "    \n",
    "    df['Blend_RON'] = 0\n",
    "    for i in range(1, 6):\n",
    "        df['Blend_RON'] += df[f'Component{i}_fraction'] * df[f'Component{i}_RON_BlendValue']\n",
    "    \n",
    "    # 5. Distillation Blending (Ethyl S-Curve Model)\n",
    "    distillation_points = {'T10': 6, 'T50': 7, 'T90': 8}\n",
    "    for point, prop_idx in distillation_points.items():\n",
    "        for i in range(1, 6):\n",
    "            # Simplified distillation blending index\n",
    "            df[f'Component{i}_{point}_Index'] = np.log(df[f'Component{i}_Property{prop_idx}'])\n",
    "        \n",
    "        df[f'Blend_{point}_Index'] = 0\n",
    "        for i in range(1, 6):\n",
    "            df[f'Blend_{point}_Index'] += (\n",
    "                df[f'Component{i}_fraction'] * \n",
    "                df[f'Component{i}_{point}_Index']\n",
    "            )\n",
    "        \n",
    "        df[f'Blend_{point}'] = np.exp(df[f'Blend_{point}_Index'])\n",
    "    \n",
    "    # 6. Cetane Index (ASTM D-976)\n",
    "    for i in range(1, 6):\n",
    "        df[f'Component{i}_Cetane_Index'] = (\n",
    "            420.34 + 0.016 * df[f'Component{i}_Property1']**2 + \n",
    "            0.192 * df[f'Component{i}_Property1'] * np.log(df[f'Component{i}_Property7']) + \n",
    "            65.01 * (np.log(df[f'Component{i}_Property7']))**2 - \n",
    "            0.0001809 * df[f'Component{i}_Property7']**2\n",
    "        )\n",
    "    \n",
    "    df['Blend_Cetane'] = 0\n",
    "    for i in range(1, 6):\n",
    "        df['Blend_Cetane'] += df[f'Component{i}_fraction'] * df[f'Component{i}_Cetane_Index']\n",
    "    \n",
    "    # 7. Viscosity Blending\n",
    "    for i in range(1, 6):\n",
    "        df[f'Component{i}_Visc_Index'] = np.log(np.log(df[f'Component{i}_Property9'] + 0.8))\n",
    "    \n",
    "    df['Blend_Visc_Index'] = 0\n",
    "    for i in range(1, 6):\n",
    "        df['Blend_Visc_Index'] += df[f'Component{i}_fraction'] * df[f'Component{i}_Visc_Index']\n",
    "    \n",
    "    df['Blend_Viscosity'] = np.exp(np.exp(df['Blend_Visc_Index'])) - 0.8\n",
    "    \n",
    "    # # 8. Interaction Terms\n",
    "    # for i in range(1, 6):\n",
    "    #     for j in range(i+1, 6):\n",
    "    #         df[f'Frac_Interaction_{i}_{j}'] = (\n",
    "    #             df[f'Component{i}_fraction'] * \n",
    "    #             df[f'Component{j}_fraction']\n",
    "    #         )\n",
    "    \n",
    "    # 9. Polynomial Features\n",
    "    # poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    # component_features = [f'Component{i}_fraction' for i in range(1, 6)] + \\\n",
    "    #                      [f'Component{i}_Property1' for i in range(1, 6)] + \\\n",
    "    #                      [f'Component{i}_Property2' for i in range(1, 6)]\n",
    "    \n",
    "    # poly_features = poly.fit_transform(df[component_features])\n",
    "    # poly_cols = [f'Poly_{i}' for i in range(poly_features.shape[1])]\n",
    "    # poly_df = pd.DataFrame(poly_features, columns=poly_cols)\n",
    "    # df = pd.concat([df, poly_df], axis=1)\n",
    "    \n",
    "    # 10. Mixture Complexity Metrics\n",
    "    fractions = [f'Component{i}_fraction' for i in range(1, 6)]\n",
    "    df['Fraction_Entropy'] = (-df[fractions] * np.log(df[fractions] + 1e-9)).sum(axis=1)\n",
    "    df['Dominant_Fraction'] = df[fractions].max(axis=1)\n",
    "    \n",
    "    # 11. Final Cleaning\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering to both datasets\n",
    "train_dataset = create_blending_features(train_dataset)\n",
    "test_dataset = create_blending_features(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component1_fraction</th>\n",
       "      <th>Component2_fraction</th>\n",
       "      <th>Component3_fraction</th>\n",
       "      <th>Component4_fraction</th>\n",
       "      <th>Component5_fraction</th>\n",
       "      <th>Component1_Property1</th>\n",
       "      <th>Component2_Property1</th>\n",
       "      <th>Component3_Property1</th>\n",
       "      <th>Component4_Property1</th>\n",
       "      <th>Component5_Property1</th>\n",
       "      <th>...</th>\n",
       "      <th>Component4_Cetane_Index</th>\n",
       "      <th>Component5_Cetane_Index</th>\n",
       "      <th>Blend_Cetane</th>\n",
       "      <th>Component1_Visc_Index</th>\n",
       "      <th>Component2_Visc_Index</th>\n",
       "      <th>Component3_Visc_Index</th>\n",
       "      <th>Component4_Visc_Index</th>\n",
       "      <th>Component5_Visc_Index</th>\n",
       "      <th>Blend_Visc_Index</th>\n",
       "      <th>Blend_Viscosity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.021782</td>\n",
       "      <td>1.981251</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0.140315</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>686.546409</td>\n",
       "      <td>567.997235</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-1.397769</td>\n",
       "      <td>-0.490269</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-0.945803</td>\n",
       "      <td>-0.975395</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.224339</td>\n",
       "      <td>1.148036</td>\n",
       "      <td>-1.107840</td>\n",
       "      <td>0.149533</td>\n",
       "      <td>-0.354000</td>\n",
       "      <td>...</td>\n",
       "      <td>485.796592</td>\n",
       "      <td>701.435666</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.955023</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-1.020018</td>\n",
       "      <td>-0.215462</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.457763</td>\n",
       "      <td>0.242591</td>\n",
       "      <td>-0.922492</td>\n",
       "      <td>0.908213</td>\n",
       "      <td>0.972003</td>\n",
       "      <td>...</td>\n",
       "      <td>519.163309</td>\n",
       "      <td>534.327773</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.955023</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-1.020018</td>\n",
       "      <td>-0.975395</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.577734</td>\n",
       "      <td>-0.930826</td>\n",
       "      <td>0.815284</td>\n",
       "      <td>0.447514</td>\n",
       "      <td>0.455717</td>\n",
       "      <td>...</td>\n",
       "      <td>420.665290</td>\n",
       "      <td>534.327773</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.399504</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-1.499369</td>\n",
       "      <td>-0.975395</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.120415</td>\n",
       "      <td>0.666268</td>\n",
       "      <td>-0.626934</td>\n",
       "      <td>2.725357</td>\n",
       "      <td>0.392259</td>\n",
       "      <td>...</td>\n",
       "      <td>519.163309</td>\n",
       "      <td>450.234034</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.045815</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-0.058737</td>\n",
       "      <td>-0.975395</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>-0.054170</td>\n",
       "      <td>-0.391227</td>\n",
       "      <td>0.400222</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>423.640833</td>\n",
       "      <td>421.011697</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.412355</td>\n",
       "      <td>-0.102118</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-1.678307</td>\n",
       "      <td>-0.800862</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.887185</td>\n",
       "      <td>0.610050</td>\n",
       "      <td>0.178606</td>\n",
       "      <td>1.083154</td>\n",
       "      <td>-2.822749</td>\n",
       "      <td>...</td>\n",
       "      <td>519.163309</td>\n",
       "      <td>534.327773</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.776129</td>\n",
       "      <td>-0.432323</td>\n",
       "      <td>-0.280726</td>\n",
       "      <td>-0.975395</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.568978</td>\n",
       "      <td>-0.196759</td>\n",
       "      <td>-0.646318</td>\n",
       "      <td>-0.980070</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>519.163309</td>\n",
       "      <td>534.327773</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.955023</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-0.740785</td>\n",
       "      <td>-0.148653</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.067453</td>\n",
       "      <td>0.321977</td>\n",
       "      <td>-0.137535</td>\n",
       "      <td>0.238507</td>\n",
       "      <td>0.017455</td>\n",
       "      <td>...</td>\n",
       "      <td>446.859486</td>\n",
       "      <td>430.098069</td>\n",
       "      <td>427.511045</td>\n",
       "      <td>-0.323091</td>\n",
       "      <td>-0.955023</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-1.584259</td>\n",
       "      <td>-0.975395</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.284090</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>-0.831267</td>\n",
       "      <td>-1.084474</td>\n",
       "      <td>0.845087</td>\n",
       "      <td>...</td>\n",
       "      <td>461.220981</td>\n",
       "      <td>449.562499</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.955023</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-1.409583</td>\n",
       "      <td>-1.567443</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Component1_fraction  Component2_fraction  Component3_fraction  \\\n",
       "0                    0.21                 0.00                 0.42   \n",
       "1                    0.02                 0.33                 0.19   \n",
       "2                    0.08                 0.08                 0.18   \n",
       "3                    0.25                 0.42                 0.00   \n",
       "4                    0.26                 0.16                 0.08   \n",
       "...                   ...                  ...                  ...   \n",
       "1995                 0.50                 0.12                 0.00   \n",
       "1996                 0.19                 0.31                 0.00   \n",
       "1997                 0.38                 0.06                 0.14   \n",
       "1998                 0.50                 0.16                 0.00   \n",
       "1999                 0.00                 0.34                 0.21   \n",
       "\n",
       "      Component4_fraction  Component5_fraction  Component1_Property1  \\\n",
       "0                    0.25                 0.12             -0.021782   \n",
       "1                    0.46                 0.00             -0.224339   \n",
       "2                    0.50                 0.16              0.457763   \n",
       "3                    0.07                 0.26             -0.577734   \n",
       "4                    0.50                 0.00              0.120415   \n",
       "...                   ...                  ...                   ...   \n",
       "1995                 0.26                 0.12              0.279523   \n",
       "1996                 0.37                 0.13             -0.887185   \n",
       "1997                 0.31                 0.11              0.568978   \n",
       "1998                 0.18                 0.16             -0.067453   \n",
       "1999                 0.45                 0.00              0.284090   \n",
       "\n",
       "      Component2_Property1  Component3_Property1  Component4_Property1  \\\n",
       "0                 1.981251              0.020036              0.140315   \n",
       "1                 1.148036             -1.107840              0.149533   \n",
       "2                 0.242591             -0.922492              0.908213   \n",
       "3                -0.930826              0.815284              0.447514   \n",
       "4                 0.666268             -0.626934              2.725357   \n",
       "...                    ...                   ...                   ...   \n",
       "1995             -0.054170             -0.391227              0.400222   \n",
       "1996              0.610050              0.178606              1.083154   \n",
       "1997             -0.196759             -0.646318             -0.980070   \n",
       "1998              0.321977             -0.137535              0.238507   \n",
       "1999              0.189099             -0.831267             -1.084474   \n",
       "\n",
       "      Component5_Property1  ...  Component4_Cetane_Index  \\\n",
       "0                 1.032029  ...               686.546409   \n",
       "1                -0.354000  ...               485.796592   \n",
       "2                 0.972003  ...               519.163309   \n",
       "3                 0.455717  ...               420.665290   \n",
       "4                 0.392259  ...               519.163309   \n",
       "...                    ...  ...                      ...   \n",
       "1995              1.032029  ...               423.640833   \n",
       "1996             -2.822749  ...               519.163309   \n",
       "1997              1.032029  ...               519.163309   \n",
       "1998              0.017455  ...               446.859486   \n",
       "1999              0.845087  ...               461.220981   \n",
       "\n",
       "      Component5_Cetane_Index  Blend_Cetane  Component1_Visc_Index  \\\n",
       "0                  567.997235    504.410185              -1.397769   \n",
       "1                  701.435666    504.410185              -0.979237   \n",
       "2                  534.327773    504.410185              -0.979237   \n",
       "3                  534.327773    504.410185              -0.979237   \n",
       "4                  450.234034    504.410185              -0.979237   \n",
       "...                       ...           ...                    ...   \n",
       "1995               421.011697    504.410185              -0.412355   \n",
       "1996               534.327773    504.410185              -0.979237   \n",
       "1997               534.327773    504.410185              -0.979237   \n",
       "1998               430.098069    427.511045              -0.323091   \n",
       "1999               449.562499    504.410185              -0.979237   \n",
       "\n",
       "      Component2_Visc_Index  Component3_Visc_Index  Component4_Visc_Index  \\\n",
       "0                 -0.490269              -1.013895              -0.945803   \n",
       "1                 -0.955023              -1.013895              -1.020018   \n",
       "2                 -0.955023              -1.013895              -1.020018   \n",
       "3                 -0.399504              -1.013895              -1.499369   \n",
       "4                 -0.045815              -1.013895              -0.058737   \n",
       "...                     ...                    ...                    ...   \n",
       "1995              -0.102118              -1.013895              -1.678307   \n",
       "1996              -0.776129              -0.432323              -0.280726   \n",
       "1997              -0.955023              -1.013895              -0.740785   \n",
       "1998              -0.955023              -1.013895              -1.584259   \n",
       "1999              -0.955023              -1.013895              -1.409583   \n",
       "\n",
       "      Component5_Visc_Index  Blend_Visc_Index  Blend_Viscosity  \n",
       "0                 -0.975395         -1.117089         0.681842  \n",
       "1                 -0.215462         -1.117089         0.681842  \n",
       "2                 -0.975395         -1.117089         0.681842  \n",
       "3                 -0.975395         -1.117089         0.681842  \n",
       "4                 -0.975395         -1.117089         0.681842  \n",
       "...                     ...               ...              ...  \n",
       "1995              -0.800862         -1.117089         0.681842  \n",
       "1996              -0.975395         -1.117089         0.681842  \n",
       "1997              -0.148653         -1.117089         0.681842  \n",
       "1998              -0.975395         -1.117089         0.681842  \n",
       "1999              -1.567443         -1.117089         0.681842  \n",
       "\n",
       "[2000 rows x 564 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component1_fraction</th>\n",
       "      <th>Component2_fraction</th>\n",
       "      <th>Component3_fraction</th>\n",
       "      <th>Component4_fraction</th>\n",
       "      <th>Component5_fraction</th>\n",
       "      <th>Component1_Property1</th>\n",
       "      <th>Component2_Property1</th>\n",
       "      <th>Component3_Property1</th>\n",
       "      <th>Component4_Property1</th>\n",
       "      <th>Component5_Property1</th>\n",
       "      <th>...</th>\n",
       "      <th>Component4_Cetane_Index</th>\n",
       "      <th>Component5_Cetane_Index</th>\n",
       "      <th>Blend_Cetane</th>\n",
       "      <th>Component1_Visc_Index</th>\n",
       "      <th>Component2_Visc_Index</th>\n",
       "      <th>Component3_Visc_Index</th>\n",
       "      <th>Component4_Visc_Index</th>\n",
       "      <th>Component5_Visc_Index</th>\n",
       "      <th>Blend_Visc_Index</th>\n",
       "      <th>Blend_Viscosity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.177804</td>\n",
       "      <td>-0.741219</td>\n",
       "      <td>0.769821</td>\n",
       "      <td>-0.877069</td>\n",
       "      <td>0.602809</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.299825</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.501354</td>\n",
       "      <td>0.177344</td>\n",
       "      <td>-0.498739</td>\n",
       "      <td>-0.196742</td>\n",
       "      <td>-1.943463</td>\n",
       "      <td>...</td>\n",
       "      <td>430.534316</td>\n",
       "      <td>423.240164</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-1.219901</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.547324</td>\n",
       "      <td>0.891479</td>\n",
       "      <td>0.030627</td>\n",
       "      <td>-0.368678</td>\n",
       "      <td>-0.294728</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>663.815825</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-0.663087</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.424427</td>\n",
       "      <td>1.016862</td>\n",
       "      <td>-1.182979</td>\n",
       "      <td>-0.854225</td>\n",
       "      <td>-0.830186</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-2.890751</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.187062</td>\n",
       "      <td>-0.762173</td>\n",
       "      <td>-0.473660</td>\n",
       "      <td>2.074087</td>\n",
       "      <td>0.756849</td>\n",
       "      <td>...</td>\n",
       "      <td>456.068496</td>\n",
       "      <td>424.246233</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-3.376006</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.036797</td>\n",
       "      <td>1.415667</td>\n",
       "      <td>0.793302</td>\n",
       "      <td>-0.446630</td>\n",
       "      <td>0.395524</td>\n",
       "      <td>...</td>\n",
       "      <td>422.428886</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-1.305137</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>-0.989537</td>\n",
       "      <td>0.903203</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>436.733566</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>0.012447</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-1.866185</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.806590</td>\n",
       "      <td>0.607324</td>\n",
       "      <td>0.359058</td>\n",
       "      <td>0.283394</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.792140</td>\n",
       "      <td>0.674275</td>\n",
       "      <td>-1.783487</td>\n",
       "      <td>0.848296</td>\n",
       "      <td>0.164798</td>\n",
       "      <td>...</td>\n",
       "      <td>427.382124</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-2.395279</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.327778</td>\n",
       "      <td>0.248042</td>\n",
       "      <td>-1.199065</td>\n",
       "      <td>1.845241</td>\n",
       "      <td>0.772672</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>446.468787</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.739801</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Component1_fraction  Component2_fraction  Component3_fraction  \\\n",
       "ID                                                                   \n",
       "1                   0.18                 0.05                 0.32   \n",
       "2                   0.00                 0.50                 0.00   \n",
       "3                   0.16                 0.00                 0.17   \n",
       "4                   0.50                 0.00                 0.17   \n",
       "5                   0.00                 0.00                 0.50   \n",
       "..                   ...                  ...                  ...   \n",
       "496                 0.44                 0.01                 0.08   \n",
       "497                 0.19                 0.47                 0.03   \n",
       "498                 0.43                 0.01                 0.12   \n",
       "499                 0.03                 0.04                 0.42   \n",
       "500                 0.00                 0.50                 0.00   \n",
       "\n",
       "     Component4_fraction  Component5_fraction  Component1_Property1  \\\n",
       "ID                                                                    \n",
       "1                   0.37                 0.08             -0.177804   \n",
       "2                   0.37                 0.13              2.501354   \n",
       "3                   0.50                 0.17              1.547324   \n",
       "4                   0.16                 0.17             -0.424427   \n",
       "5                   0.50                 0.00             -0.187062   \n",
       "..                   ...                  ...                   ...   \n",
       "496                 0.41                 0.06              1.036797   \n",
       "497                 0.23                 0.08             -1.305137   \n",
       "498                 0.21                 0.23              0.806590   \n",
       "499                 0.42                 0.09             -0.792140   \n",
       "500                 0.50                 0.00             -0.327778   \n",
       "\n",
       "     Component2_Property1  Component3_Property1  Component4_Property1  \\\n",
       "ID                                                                      \n",
       "1               -0.741219              0.769821             -0.877069   \n",
       "2                0.177344             -0.498739             -0.196742   \n",
       "3                0.891479              0.030627             -0.368678   \n",
       "4                1.016862             -1.182979             -0.854225   \n",
       "5               -0.762173             -0.473660              2.074087   \n",
       "..                    ...                   ...                   ...   \n",
       "496              1.415667              0.793302             -0.446630   \n",
       "497             -1.520941             -0.989537              0.903203   \n",
       "498              0.607324              0.359058              0.283394   \n",
       "499              0.674275             -1.783487              0.848296   \n",
       "500              0.248042             -1.199065              1.845241   \n",
       "\n",
       "     Component5_Property1  ...  Component4_Cetane_Index  \\\n",
       "ID                         ...                            \n",
       "1                0.602809  ...               533.739728   \n",
       "2               -1.943463  ...               430.534316   \n",
       "3               -0.294728  ...               533.739728   \n",
       "4               -0.830186  ...               533.739728   \n",
       "5                0.756849  ...               456.068496   \n",
       "..                    ...  ...                      ...   \n",
       "496              0.395524  ...               422.428886   \n",
       "497              1.032029  ...               436.733566   \n",
       "498              1.032029  ...               533.739728   \n",
       "499              0.164798  ...               427.382124   \n",
       "500              0.772672  ...               533.739728   \n",
       "\n",
       "     Component5_Cetane_Index  Blend_Cetane  Component1_Visc_Index  \\\n",
       "ID                                                                  \n",
       "1                 517.803098    476.367101              -1.055064   \n",
       "2                 423.240164    476.367101              -1.055064   \n",
       "3                 663.815825    476.367101              -1.055064   \n",
       "4                 517.803098    476.367101              -1.055064   \n",
       "5                 424.246233    476.367101              -1.055064   \n",
       "..                       ...           ...                    ...   \n",
       "496               517.803098    476.367101              -1.055064   \n",
       "497               517.803098    476.367101              -1.055064   \n",
       "498               517.803098    476.367101              -1.055064   \n",
       "499               517.803098    476.367101              -1.055064   \n",
       "500               446.468787    476.367101              -1.055064   \n",
       "\n",
       "     Component2_Visc_Index  Component3_Visc_Index  Component4_Visc_Index  \\\n",
       "ID                                                                         \n",
       "1                -0.845686              -1.197669              -1.111906   \n",
       "2                -0.845686              -1.197669              -1.111906   \n",
       "3                -0.845686              -0.663087              -1.111906   \n",
       "4                -2.890751              -1.197669              -1.111906   \n",
       "5                -0.845686              -1.197669              -3.376006   \n",
       "..                     ...                    ...                    ...   \n",
       "496              -0.845686              -1.197669              -1.111906   \n",
       "497              -0.845686               0.012447              -1.111906   \n",
       "498              -0.845686              -1.197669              -1.111906   \n",
       "499              -0.845686              -2.395279              -1.111906   \n",
       "500              -0.845686              -1.197669              -1.111906   \n",
       "\n",
       "     Component5_Visc_Index  Blend_Visc_Index  Blend_Viscosity  \n",
       "ID                                                             \n",
       "1                -0.299825         -1.303419         0.549224  \n",
       "2                -1.219901         -1.303419         0.549224  \n",
       "3                -0.970853         -1.303419         0.549224  \n",
       "4                -0.970853         -1.303419         0.549224  \n",
       "5                -0.970853         -1.303419         0.549224  \n",
       "..                     ...               ...              ...  \n",
       "496              -0.970853         -1.303419         0.549224  \n",
       "497              -1.866185         -1.303419         0.549224  \n",
       "498              -0.970853         -1.303419         0.549224  \n",
       "499              -0.970853         -1.303419         0.549224  \n",
       "500              -0.739801         -1.303419         0.549224  \n",
       "\n",
       "[500 rows x 564 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component1_fraction</th>\n",
       "      <th>Component2_fraction</th>\n",
       "      <th>Component3_fraction</th>\n",
       "      <th>Component4_fraction</th>\n",
       "      <th>Component5_fraction</th>\n",
       "      <th>Component1_Property1</th>\n",
       "      <th>Component2_Property1</th>\n",
       "      <th>Component3_Property1</th>\n",
       "      <th>Component4_Property1</th>\n",
       "      <th>Component5_Property1</th>\n",
       "      <th>...</th>\n",
       "      <th>Component4_Cetane_Index</th>\n",
       "      <th>Component5_Cetane_Index</th>\n",
       "      <th>Blend_Cetane</th>\n",
       "      <th>Component1_Visc_Index</th>\n",
       "      <th>Component2_Visc_Index</th>\n",
       "      <th>Component3_Visc_Index</th>\n",
       "      <th>Component4_Visc_Index</th>\n",
       "      <th>Component5_Visc_Index</th>\n",
       "      <th>Blend_Visc_Index</th>\n",
       "      <th>Blend_Viscosity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.021782</td>\n",
       "      <td>1.981251</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0.140315</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>686.546409</td>\n",
       "      <td>567.997235</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-1.397769</td>\n",
       "      <td>-0.490269</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-0.945803</td>\n",
       "      <td>-0.975395</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.224339</td>\n",
       "      <td>1.148036</td>\n",
       "      <td>-1.107840</td>\n",
       "      <td>0.149533</td>\n",
       "      <td>-0.354000</td>\n",
       "      <td>...</td>\n",
       "      <td>485.796592</td>\n",
       "      <td>701.435666</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.955023</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-1.020018</td>\n",
       "      <td>-0.215462</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.457763</td>\n",
       "      <td>0.242591</td>\n",
       "      <td>-0.922492</td>\n",
       "      <td>0.908213</td>\n",
       "      <td>0.972003</td>\n",
       "      <td>...</td>\n",
       "      <td>519.163309</td>\n",
       "      <td>534.327773</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.955023</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-1.020018</td>\n",
       "      <td>-0.975395</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.577734</td>\n",
       "      <td>-0.930826</td>\n",
       "      <td>0.815284</td>\n",
       "      <td>0.447514</td>\n",
       "      <td>0.455717</td>\n",
       "      <td>...</td>\n",
       "      <td>420.665290</td>\n",
       "      <td>534.327773</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.399504</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-1.499369</td>\n",
       "      <td>-0.975395</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.120415</td>\n",
       "      <td>0.666268</td>\n",
       "      <td>-0.626934</td>\n",
       "      <td>2.725357</td>\n",
       "      <td>0.392259</td>\n",
       "      <td>...</td>\n",
       "      <td>519.163309</td>\n",
       "      <td>450.234034</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.045815</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-0.058737</td>\n",
       "      <td>-0.975395</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>-0.054170</td>\n",
       "      <td>-0.391227</td>\n",
       "      <td>0.400222</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>423.640833</td>\n",
       "      <td>421.011697</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.412355</td>\n",
       "      <td>-0.102118</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-1.678307</td>\n",
       "      <td>-0.800862</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.887185</td>\n",
       "      <td>0.610050</td>\n",
       "      <td>0.178606</td>\n",
       "      <td>1.083154</td>\n",
       "      <td>-2.822749</td>\n",
       "      <td>...</td>\n",
       "      <td>519.163309</td>\n",
       "      <td>534.327773</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.776129</td>\n",
       "      <td>-0.432323</td>\n",
       "      <td>-0.280726</td>\n",
       "      <td>-0.975395</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.568978</td>\n",
       "      <td>-0.196759</td>\n",
       "      <td>-0.646318</td>\n",
       "      <td>-0.980070</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>519.163309</td>\n",
       "      <td>534.327773</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.955023</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-0.740785</td>\n",
       "      <td>-0.148653</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.067453</td>\n",
       "      <td>0.321977</td>\n",
       "      <td>-0.137535</td>\n",
       "      <td>0.238507</td>\n",
       "      <td>0.017455</td>\n",
       "      <td>...</td>\n",
       "      <td>446.859486</td>\n",
       "      <td>430.098069</td>\n",
       "      <td>427.511045</td>\n",
       "      <td>-0.323091</td>\n",
       "      <td>-0.955023</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-1.584259</td>\n",
       "      <td>-0.975395</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.284090</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>-0.831267</td>\n",
       "      <td>-1.084474</td>\n",
       "      <td>0.845087</td>\n",
       "      <td>...</td>\n",
       "      <td>461.220981</td>\n",
       "      <td>449.562499</td>\n",
       "      <td>504.410185</td>\n",
       "      <td>-0.979237</td>\n",
       "      <td>-0.955023</td>\n",
       "      <td>-1.013895</td>\n",
       "      <td>-1.409583</td>\n",
       "      <td>-1.567443</td>\n",
       "      <td>-1.117089</td>\n",
       "      <td>0.681842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Component1_fraction  Component2_fraction  Component3_fraction  \\\n",
       "0                    0.21                 0.00                 0.42   \n",
       "1                    0.02                 0.33                 0.19   \n",
       "2                    0.08                 0.08                 0.18   \n",
       "3                    0.25                 0.42                 0.00   \n",
       "4                    0.26                 0.16                 0.08   \n",
       "...                   ...                  ...                  ...   \n",
       "1995                 0.50                 0.12                 0.00   \n",
       "1996                 0.19                 0.31                 0.00   \n",
       "1997                 0.38                 0.06                 0.14   \n",
       "1998                 0.50                 0.16                 0.00   \n",
       "1999                 0.00                 0.34                 0.21   \n",
       "\n",
       "      Component4_fraction  Component5_fraction  Component1_Property1  \\\n",
       "0                    0.25                 0.12             -0.021782   \n",
       "1                    0.46                 0.00             -0.224339   \n",
       "2                    0.50                 0.16              0.457763   \n",
       "3                    0.07                 0.26             -0.577734   \n",
       "4                    0.50                 0.00              0.120415   \n",
       "...                   ...                  ...                   ...   \n",
       "1995                 0.26                 0.12              0.279523   \n",
       "1996                 0.37                 0.13             -0.887185   \n",
       "1997                 0.31                 0.11              0.568978   \n",
       "1998                 0.18                 0.16             -0.067453   \n",
       "1999                 0.45                 0.00              0.284090   \n",
       "\n",
       "      Component2_Property1  Component3_Property1  Component4_Property1  \\\n",
       "0                 1.981251              0.020036              0.140315   \n",
       "1                 1.148036             -1.107840              0.149533   \n",
       "2                 0.242591             -0.922492              0.908213   \n",
       "3                -0.930826              0.815284              0.447514   \n",
       "4                 0.666268             -0.626934              2.725357   \n",
       "...                    ...                   ...                   ...   \n",
       "1995             -0.054170             -0.391227              0.400222   \n",
       "1996              0.610050              0.178606              1.083154   \n",
       "1997             -0.196759             -0.646318             -0.980070   \n",
       "1998              0.321977             -0.137535              0.238507   \n",
       "1999              0.189099             -0.831267             -1.084474   \n",
       "\n",
       "      Component5_Property1  ...  Component4_Cetane_Index  \\\n",
       "0                 1.032029  ...               686.546409   \n",
       "1                -0.354000  ...               485.796592   \n",
       "2                 0.972003  ...               519.163309   \n",
       "3                 0.455717  ...               420.665290   \n",
       "4                 0.392259  ...               519.163309   \n",
       "...                    ...  ...                      ...   \n",
       "1995              1.032029  ...               423.640833   \n",
       "1996             -2.822749  ...               519.163309   \n",
       "1997              1.032029  ...               519.163309   \n",
       "1998              0.017455  ...               446.859486   \n",
       "1999              0.845087  ...               461.220981   \n",
       "\n",
       "      Component5_Cetane_Index  Blend_Cetane  Component1_Visc_Index  \\\n",
       "0                  567.997235    504.410185              -1.397769   \n",
       "1                  701.435666    504.410185              -0.979237   \n",
       "2                  534.327773    504.410185              -0.979237   \n",
       "3                  534.327773    504.410185              -0.979237   \n",
       "4                  450.234034    504.410185              -0.979237   \n",
       "...                       ...           ...                    ...   \n",
       "1995               421.011697    504.410185              -0.412355   \n",
       "1996               534.327773    504.410185              -0.979237   \n",
       "1997               534.327773    504.410185              -0.979237   \n",
       "1998               430.098069    427.511045              -0.323091   \n",
       "1999               449.562499    504.410185              -0.979237   \n",
       "\n",
       "      Component2_Visc_Index  Component3_Visc_Index  Component4_Visc_Index  \\\n",
       "0                 -0.490269              -1.013895              -0.945803   \n",
       "1                 -0.955023              -1.013895              -1.020018   \n",
       "2                 -0.955023              -1.013895              -1.020018   \n",
       "3                 -0.399504              -1.013895              -1.499369   \n",
       "4                 -0.045815              -1.013895              -0.058737   \n",
       "...                     ...                    ...                    ...   \n",
       "1995              -0.102118              -1.013895              -1.678307   \n",
       "1996              -0.776129              -0.432323              -0.280726   \n",
       "1997              -0.955023              -1.013895              -0.740785   \n",
       "1998              -0.955023              -1.013895              -1.584259   \n",
       "1999              -0.955023              -1.013895              -1.409583   \n",
       "\n",
       "      Component5_Visc_Index  Blend_Visc_Index  Blend_Viscosity  \n",
       "0                 -0.975395         -1.117089         0.681842  \n",
       "1                 -0.215462         -1.117089         0.681842  \n",
       "2                 -0.975395         -1.117089         0.681842  \n",
       "3                 -0.975395         -1.117089         0.681842  \n",
       "4                 -0.975395         -1.117089         0.681842  \n",
       "...                     ...               ...              ...  \n",
       "1995              -0.800862         -1.117089         0.681842  \n",
       "1996              -0.975395         -1.117089         0.681842  \n",
       "1997              -0.148653         -1.117089         0.681842  \n",
       "1998              -0.975395         -1.117089         0.681842  \n",
       "1999              -1.567443         -1.117089         0.681842  \n",
       "\n",
       "[2000 rows x 564 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component1_fraction</th>\n",
       "      <th>Component2_fraction</th>\n",
       "      <th>Component3_fraction</th>\n",
       "      <th>Component4_fraction</th>\n",
       "      <th>Component5_fraction</th>\n",
       "      <th>Component1_Property1</th>\n",
       "      <th>Component2_Property1</th>\n",
       "      <th>Component3_Property1</th>\n",
       "      <th>Component4_Property1</th>\n",
       "      <th>Component5_Property1</th>\n",
       "      <th>...</th>\n",
       "      <th>Component4_Cetane_Index</th>\n",
       "      <th>Component5_Cetane_Index</th>\n",
       "      <th>Blend_Cetane</th>\n",
       "      <th>Component1_Visc_Index</th>\n",
       "      <th>Component2_Visc_Index</th>\n",
       "      <th>Component3_Visc_Index</th>\n",
       "      <th>Component4_Visc_Index</th>\n",
       "      <th>Component5_Visc_Index</th>\n",
       "      <th>Blend_Visc_Index</th>\n",
       "      <th>Blend_Viscosity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.177804</td>\n",
       "      <td>-0.741219</td>\n",
       "      <td>0.769821</td>\n",
       "      <td>-0.877069</td>\n",
       "      <td>0.602809</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.299825</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.501354</td>\n",
       "      <td>0.177344</td>\n",
       "      <td>-0.498739</td>\n",
       "      <td>-0.196742</td>\n",
       "      <td>-1.943463</td>\n",
       "      <td>...</td>\n",
       "      <td>430.534316</td>\n",
       "      <td>423.240164</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-1.219901</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.547324</td>\n",
       "      <td>0.891479</td>\n",
       "      <td>0.030627</td>\n",
       "      <td>-0.368678</td>\n",
       "      <td>-0.294728</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>663.815825</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-0.663087</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.424427</td>\n",
       "      <td>1.016862</td>\n",
       "      <td>-1.182979</td>\n",
       "      <td>-0.854225</td>\n",
       "      <td>-0.830186</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-2.890751</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.187062</td>\n",
       "      <td>-0.762173</td>\n",
       "      <td>-0.473660</td>\n",
       "      <td>2.074087</td>\n",
       "      <td>0.756849</td>\n",
       "      <td>...</td>\n",
       "      <td>456.068496</td>\n",
       "      <td>424.246233</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-3.376006</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.036797</td>\n",
       "      <td>1.415667</td>\n",
       "      <td>0.793302</td>\n",
       "      <td>-0.446630</td>\n",
       "      <td>0.395524</td>\n",
       "      <td>...</td>\n",
       "      <td>422.428886</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-1.305137</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>-0.989537</td>\n",
       "      <td>0.903203</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>436.733566</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>0.012447</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-1.866185</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.806590</td>\n",
       "      <td>0.607324</td>\n",
       "      <td>0.359058</td>\n",
       "      <td>0.283394</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.792140</td>\n",
       "      <td>0.674275</td>\n",
       "      <td>-1.783487</td>\n",
       "      <td>0.848296</td>\n",
       "      <td>0.164798</td>\n",
       "      <td>...</td>\n",
       "      <td>427.382124</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-2.395279</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.327778</td>\n",
       "      <td>0.248042</td>\n",
       "      <td>-1.199065</td>\n",
       "      <td>1.845241</td>\n",
       "      <td>0.772672</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>446.468787</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.739801</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Component1_fraction  Component2_fraction  Component3_fraction  \\\n",
       "ID                                                                   \n",
       "1                   0.18                 0.05                 0.32   \n",
       "2                   0.00                 0.50                 0.00   \n",
       "3                   0.16                 0.00                 0.17   \n",
       "4                   0.50                 0.00                 0.17   \n",
       "5                   0.00                 0.00                 0.50   \n",
       "..                   ...                  ...                  ...   \n",
       "496                 0.44                 0.01                 0.08   \n",
       "497                 0.19                 0.47                 0.03   \n",
       "498                 0.43                 0.01                 0.12   \n",
       "499                 0.03                 0.04                 0.42   \n",
       "500                 0.00                 0.50                 0.00   \n",
       "\n",
       "     Component4_fraction  Component5_fraction  Component1_Property1  \\\n",
       "ID                                                                    \n",
       "1                   0.37                 0.08             -0.177804   \n",
       "2                   0.37                 0.13              2.501354   \n",
       "3                   0.50                 0.17              1.547324   \n",
       "4                   0.16                 0.17             -0.424427   \n",
       "5                   0.50                 0.00             -0.187062   \n",
       "..                   ...                  ...                   ...   \n",
       "496                 0.41                 0.06              1.036797   \n",
       "497                 0.23                 0.08             -1.305137   \n",
       "498                 0.21                 0.23              0.806590   \n",
       "499                 0.42                 0.09             -0.792140   \n",
       "500                 0.50                 0.00             -0.327778   \n",
       "\n",
       "     Component2_Property1  Component3_Property1  Component4_Property1  \\\n",
       "ID                                                                      \n",
       "1               -0.741219              0.769821             -0.877069   \n",
       "2                0.177344             -0.498739             -0.196742   \n",
       "3                0.891479              0.030627             -0.368678   \n",
       "4                1.016862             -1.182979             -0.854225   \n",
       "5               -0.762173             -0.473660              2.074087   \n",
       "..                    ...                   ...                   ...   \n",
       "496              1.415667              0.793302             -0.446630   \n",
       "497             -1.520941             -0.989537              0.903203   \n",
       "498              0.607324              0.359058              0.283394   \n",
       "499              0.674275             -1.783487              0.848296   \n",
       "500              0.248042             -1.199065              1.845241   \n",
       "\n",
       "     Component5_Property1  ...  Component4_Cetane_Index  \\\n",
       "ID                         ...                            \n",
       "1                0.602809  ...               533.739728   \n",
       "2               -1.943463  ...               430.534316   \n",
       "3               -0.294728  ...               533.739728   \n",
       "4               -0.830186  ...               533.739728   \n",
       "5                0.756849  ...               456.068496   \n",
       "..                    ...  ...                      ...   \n",
       "496              0.395524  ...               422.428886   \n",
       "497              1.032029  ...               436.733566   \n",
       "498              1.032029  ...               533.739728   \n",
       "499              0.164798  ...               427.382124   \n",
       "500              0.772672  ...               533.739728   \n",
       "\n",
       "     Component5_Cetane_Index  Blend_Cetane  Component1_Visc_Index  \\\n",
       "ID                                                                  \n",
       "1                 517.803098    476.367101              -1.055064   \n",
       "2                 423.240164    476.367101              -1.055064   \n",
       "3                 663.815825    476.367101              -1.055064   \n",
       "4                 517.803098    476.367101              -1.055064   \n",
       "5                 424.246233    476.367101              -1.055064   \n",
       "..                       ...           ...                    ...   \n",
       "496               517.803098    476.367101              -1.055064   \n",
       "497               517.803098    476.367101              -1.055064   \n",
       "498               517.803098    476.367101              -1.055064   \n",
       "499               517.803098    476.367101              -1.055064   \n",
       "500               446.468787    476.367101              -1.055064   \n",
       "\n",
       "     Component2_Visc_Index  Component3_Visc_Index  Component4_Visc_Index  \\\n",
       "ID                                                                         \n",
       "1                -0.845686              -1.197669              -1.111906   \n",
       "2                -0.845686              -1.197669              -1.111906   \n",
       "3                -0.845686              -0.663087              -1.111906   \n",
       "4                -2.890751              -1.197669              -1.111906   \n",
       "5                -0.845686              -1.197669              -3.376006   \n",
       "..                     ...                    ...                    ...   \n",
       "496              -0.845686              -1.197669              -1.111906   \n",
       "497              -0.845686               0.012447              -1.111906   \n",
       "498              -0.845686              -1.197669              -1.111906   \n",
       "499              -0.845686              -2.395279              -1.111906   \n",
       "500              -0.845686              -1.197669              -1.111906   \n",
       "\n",
       "     Component5_Visc_Index  Blend_Visc_Index  Blend_Viscosity  \n",
       "ID                                                             \n",
       "1                -0.299825         -1.303419         0.549224  \n",
       "2                -1.219901         -1.303419         0.549224  \n",
       "3                -0.970853         -1.303419         0.549224  \n",
       "4                -0.970853         -1.303419         0.549224  \n",
       "5                -0.970853         -1.303419         0.549224  \n",
       "..                     ...               ...              ...  \n",
       "496              -0.970853         -1.303419         0.549224  \n",
       "497              -1.866185         -1.303419         0.549224  \n",
       "498              -0.970853         -1.303419         0.549224  \n",
       "499              -0.970853         -1.303419         0.549224  \n",
       "500              -0.739801         -1.303419         0.549224  \n",
       "\n",
       "[500 rows x 564 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500 entries, 1 to 500\n",
      "Columns: 564 entries, Component1_fraction to Blend_Viscosity\n",
      "dtypes: float64(514), int64(50)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# polynomial _Features creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component1_fraction</th>\n",
       "      <th>Component2_fraction</th>\n",
       "      <th>Component3_fraction</th>\n",
       "      <th>Component4_fraction</th>\n",
       "      <th>Component5_fraction</th>\n",
       "      <th>Component1_Property1</th>\n",
       "      <th>Component2_Property1</th>\n",
       "      <th>Component3_Property1</th>\n",
       "      <th>Component4_Property1</th>\n",
       "      <th>Component5_Property1</th>\n",
       "      <th>...</th>\n",
       "      <th>Component4_Cetane_Index</th>\n",
       "      <th>Component5_Cetane_Index</th>\n",
       "      <th>Blend_Cetane</th>\n",
       "      <th>Component1_Visc_Index</th>\n",
       "      <th>Component2_Visc_Index</th>\n",
       "      <th>Component3_Visc_Index</th>\n",
       "      <th>Component4_Visc_Index</th>\n",
       "      <th>Component5_Visc_Index</th>\n",
       "      <th>Blend_Visc_Index</th>\n",
       "      <th>Blend_Viscosity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Component1_fraction</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.452466</td>\n",
       "      <td>-0.441056</td>\n",
       "      <td>-0.128280</td>\n",
       "      <td>0.028830</td>\n",
       "      <td>-0.015530</td>\n",
       "      <td>-0.032505</td>\n",
       "      <td>-0.000743</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>0.042178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010787</td>\n",
       "      <td>-0.001266</td>\n",
       "      <td>0.025797</td>\n",
       "      <td>-0.004061</td>\n",
       "      <td>0.011581</td>\n",
       "      <td>0.006799</td>\n",
       "      <td>-0.016042</td>\n",
       "      <td>-0.038140</td>\n",
       "      <td>-0.017628</td>\n",
       "      <td>-0.014670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component2_fraction</th>\n",
       "      <td>-0.452466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.430003</td>\n",
       "      <td>-0.162097</td>\n",
       "      <td>0.056293</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>0.020551</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>-0.007805</td>\n",
       "      <td>-0.025751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027715</td>\n",
       "      <td>0.013182</td>\n",
       "      <td>-0.014697</td>\n",
       "      <td>-0.000662</td>\n",
       "      <td>-0.017036</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.015175</td>\n",
       "      <td>0.008998</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>-0.004778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component3_fraction</th>\n",
       "      <td>-0.441056</td>\n",
       "      <td>-0.430003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.205391</td>\n",
       "      <td>0.063267</td>\n",
       "      <td>-0.024512</td>\n",
       "      <td>0.010782</td>\n",
       "      <td>0.030103</td>\n",
       "      <td>-0.001353</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041647</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>-0.004948</td>\n",
       "      <td>0.008847</td>\n",
       "      <td>-0.012119</td>\n",
       "      <td>-0.005723</td>\n",
       "      <td>0.020535</td>\n",
       "      <td>-0.005795</td>\n",
       "      <td>0.006216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component4_fraction</th>\n",
       "      <td>-0.128280</td>\n",
       "      <td>-0.162097</td>\n",
       "      <td>-0.205391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.741647</td>\n",
       "      <td>0.017562</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.014451</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>-0.008616</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008742</td>\n",
       "      <td>-0.022524</td>\n",
       "      <td>-0.004275</td>\n",
       "      <td>0.015597</td>\n",
       "      <td>-0.009794</td>\n",
       "      <td>-0.001066</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.014911</td>\n",
       "      <td>0.012088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component5_fraction</th>\n",
       "      <td>0.028830</td>\n",
       "      <td>0.056293</td>\n",
       "      <td>0.063267</td>\n",
       "      <td>-0.741647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>-0.004848</td>\n",
       "      <td>-0.004726</td>\n",
       "      <td>-0.004142</td>\n",
       "      <td>-0.007248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023205</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>-0.019091</td>\n",
       "      <td>-0.007568</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>0.005447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component3_Visc_Index</th>\n",
       "      <td>0.006799</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>-0.012119</td>\n",
       "      <td>-0.001066</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>-0.032115</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>-0.032231</td>\n",
       "      <td>0.051967</td>\n",
       "      <td>-0.003773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006205</td>\n",
       "      <td>-0.025820</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>-0.018536</td>\n",
       "      <td>-0.013417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033565</td>\n",
       "      <td>-0.014322</td>\n",
       "      <td>0.026345</td>\n",
       "      <td>0.016418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component4_Visc_Index</th>\n",
       "      <td>-0.016042</td>\n",
       "      <td>0.015175</td>\n",
       "      <td>-0.005723</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>-0.001411</td>\n",
       "      <td>0.051331</td>\n",
       "      <td>-0.012324</td>\n",
       "      <td>-0.002322</td>\n",
       "      <td>-0.002776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007882</td>\n",
       "      <td>0.029241</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.024949</td>\n",
       "      <td>-0.033565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025208</td>\n",
       "      <td>0.145118</td>\n",
       "      <td>0.142020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component5_Visc_Index</th>\n",
       "      <td>-0.038140</td>\n",
       "      <td>0.008998</td>\n",
       "      <td>0.020535</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.011962</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.013595</td>\n",
       "      <td>0.021193</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009631</td>\n",
       "      <td>0.010931</td>\n",
       "      <td>0.010468</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>-0.003710</td>\n",
       "      <td>-0.014322</td>\n",
       "      <td>-0.025208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022677</td>\n",
       "      <td>0.032171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blend_Visc_Index</th>\n",
       "      <td>-0.017628</td>\n",
       "      <td>0.005702</td>\n",
       "      <td>-0.005795</td>\n",
       "      <td>0.014911</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>-0.033564</td>\n",
       "      <td>-0.007880</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.012339</td>\n",
       "      <td>-0.038177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>0.096620</td>\n",
       "      <td>0.027934</td>\n",
       "      <td>0.058577</td>\n",
       "      <td>0.085858</td>\n",
       "      <td>0.026345</td>\n",
       "      <td>0.145118</td>\n",
       "      <td>0.022677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blend_Viscosity</th>\n",
       "      <td>-0.014670</td>\n",
       "      <td>-0.004778</td>\n",
       "      <td>0.006216</td>\n",
       "      <td>0.012088</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>-0.022210</td>\n",
       "      <td>-0.008511</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>-0.026500</td>\n",
       "      <td>-0.026020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.105775</td>\n",
       "      <td>0.029789</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>0.086809</td>\n",
       "      <td>0.016418</td>\n",
       "      <td>0.142020</td>\n",
       "      <td>0.032171</td>\n",
       "      <td>0.910826</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>564 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Component1_fraction  Component2_fraction  \\\n",
       "Component1_fraction               1.000000            -0.452466   \n",
       "Component2_fraction              -0.452466             1.000000   \n",
       "Component3_fraction              -0.441056            -0.430003   \n",
       "Component4_fraction              -0.128280            -0.162097   \n",
       "Component5_fraction               0.028830             0.056293   \n",
       "...                                    ...                  ...   \n",
       "Component3_Visc_Index             0.006799             0.000670   \n",
       "Component4_Visc_Index            -0.016042             0.015175   \n",
       "Component5_Visc_Index            -0.038140             0.008998   \n",
       "Blend_Visc_Index                 -0.017628             0.005702   \n",
       "Blend_Viscosity                  -0.014670            -0.004778   \n",
       "\n",
       "                       Component3_fraction  Component4_fraction  \\\n",
       "Component1_fraction              -0.441056            -0.128280   \n",
       "Component2_fraction              -0.430003            -0.162097   \n",
       "Component3_fraction               1.000000            -0.205391   \n",
       "Component4_fraction              -0.205391             1.000000   \n",
       "Component5_fraction               0.063267            -0.741647   \n",
       "...                                    ...                  ...   \n",
       "Component3_Visc_Index            -0.012119            -0.001066   \n",
       "Component4_Visc_Index            -0.005723             0.002305   \n",
       "Component5_Visc_Index             0.020535             0.004947   \n",
       "Blend_Visc_Index                 -0.005795             0.014911   \n",
       "Blend_Viscosity                   0.006216             0.012088   \n",
       "\n",
       "                       Component5_fraction  Component1_Property1  \\\n",
       "Component1_fraction               0.028830             -0.015530   \n",
       "Component2_fraction               0.056293              0.024858   \n",
       "Component3_fraction               0.063267             -0.024512   \n",
       "Component4_fraction              -0.741647              0.017562   \n",
       "Component5_fraction               1.000000              0.000784   \n",
       "...                                    ...                   ...   \n",
       "Component3_Visc_Index             0.011797             -0.032115   \n",
       "Component4_Visc_Index             0.009477             -0.001411   \n",
       "Component5_Visc_Index             0.007961              0.011962   \n",
       "Blend_Visc_Index                  0.010008             -0.033564   \n",
       "Blend_Viscosity                   0.005447             -0.022210   \n",
       "\n",
       "                       Component2_Property1  Component3_Property1  \\\n",
       "Component1_fraction               -0.032505             -0.000743   \n",
       "Component2_fraction                0.020551             -0.039978   \n",
       "Component3_fraction                0.010782              0.030103   \n",
       "Component4_fraction                0.003803              0.014451   \n",
       "Component5_fraction               -0.004848             -0.004726   \n",
       "...                                     ...                   ...   \n",
       "Component3_Visc_Index              0.005463             -0.032231   \n",
       "Component4_Visc_Index              0.051331             -0.012324   \n",
       "Component5_Visc_Index              0.008306              0.013595   \n",
       "Blend_Visc_Index                  -0.007880              0.000299   \n",
       "Blend_Viscosity                   -0.008511              0.000189   \n",
       "\n",
       "                       Component4_Property1  Component5_Property1  ...  \\\n",
       "Component1_fraction                0.006344              0.042178  ...   \n",
       "Component2_fraction               -0.007805             -0.025751  ...   \n",
       "Component3_fraction               -0.001353             -0.005236  ...   \n",
       "Component4_fraction                0.005666             -0.008616  ...   \n",
       "Component5_fraction               -0.004142             -0.007248  ...   \n",
       "...                                     ...                   ...  ...   \n",
       "Component3_Visc_Index              0.051967             -0.003773  ...   \n",
       "Component4_Visc_Index             -0.002322             -0.002776  ...   \n",
       "Component5_Visc_Index              0.021193              0.000460  ...   \n",
       "Blend_Visc_Index                  -0.012339             -0.038177  ...   \n",
       "Blend_Viscosity                   -0.026500             -0.026020  ...   \n",
       "\n",
       "                       Component4_Cetane_Index  Component5_Cetane_Index  \\\n",
       "Component1_fraction                   0.010787                -0.001266   \n",
       "Component2_fraction                   0.027715                 0.013182   \n",
       "Component3_fraction                  -0.041647                 0.006413   \n",
       "Component4_fraction                  -0.008742                -0.022524   \n",
       "Component5_fraction                   0.023205                 0.002005   \n",
       "...                                        ...                      ...   \n",
       "Component3_Visc_Index                -0.006205                -0.025820   \n",
       "Component4_Visc_Index                -0.007882                 0.029241   \n",
       "Component5_Visc_Index                -0.009631                 0.010931   \n",
       "Blend_Visc_Index                      0.006121                 0.096620   \n",
       "Blend_Viscosity                       0.001168                 0.105775   \n",
       "\n",
       "                       Blend_Cetane  Component1_Visc_Index  \\\n",
       "Component1_fraction        0.025797              -0.004061   \n",
       "Component2_fraction       -0.014697              -0.000662   \n",
       "Component3_fraction        0.001988              -0.004948   \n",
       "Component4_fraction       -0.004275               0.015597   \n",
       "Component5_fraction       -0.019091              -0.007568   \n",
       "...                             ...                    ...   \n",
       "Component3_Visc_Index      0.000603              -0.018536   \n",
       "Component4_Visc_Index      0.000466               0.001560   \n",
       "Component5_Visc_Index      0.010468               0.017342   \n",
       "Blend_Visc_Index           0.027934               0.058577   \n",
       "Blend_Viscosity            0.029789               0.051802   \n",
       "\n",
       "                       Component2_Visc_Index  Component3_Visc_Index  \\\n",
       "Component1_fraction                 0.011581               0.006799   \n",
       "Component2_fraction                -0.017036               0.000670   \n",
       "Component3_fraction                 0.008847              -0.012119   \n",
       "Component4_fraction                -0.009794              -0.001066   \n",
       "Component5_fraction                 0.010096               0.011797   \n",
       "...                                      ...                    ...   \n",
       "Component3_Visc_Index              -0.013417               1.000000   \n",
       "Component4_Visc_Index               0.024949              -0.033565   \n",
       "Component5_Visc_Index              -0.003710              -0.014322   \n",
       "Blend_Visc_Index                    0.085858               0.026345   \n",
       "Blend_Viscosity                     0.086809               0.016418   \n",
       "\n",
       "                       Component4_Visc_Index  Component5_Visc_Index  \\\n",
       "Component1_fraction                -0.016042              -0.038140   \n",
       "Component2_fraction                 0.015175               0.008998   \n",
       "Component3_fraction                -0.005723               0.020535   \n",
       "Component4_fraction                 0.002305               0.004947   \n",
       "Component5_fraction                 0.009477               0.007961   \n",
       "...                                      ...                    ...   \n",
       "Component3_Visc_Index              -0.033565              -0.014322   \n",
       "Component4_Visc_Index               1.000000              -0.025208   \n",
       "Component5_Visc_Index              -0.025208               1.000000   \n",
       "Blend_Visc_Index                    0.145118               0.022677   \n",
       "Blend_Viscosity                     0.142020               0.032171   \n",
       "\n",
       "                       Blend_Visc_Index  Blend_Viscosity  \n",
       "Component1_fraction           -0.017628        -0.014670  \n",
       "Component2_fraction            0.005702        -0.004778  \n",
       "Component3_fraction           -0.005795         0.006216  \n",
       "Component4_fraction            0.014911         0.012088  \n",
       "Component5_fraction            0.010008         0.005447  \n",
       "...                                 ...              ...  \n",
       "Component3_Visc_Index          0.026345         0.016418  \n",
       "Component4_Visc_Index          0.145118         0.142020  \n",
       "Component5_Visc_Index          0.022677         0.032171  \n",
       "Blend_Visc_Index               1.000000         0.910826  \n",
       "Blend_Viscosity                0.910826         1.000000  \n",
       "\n",
       "[564 rows x 564 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component1_fraction</th>\n",
       "      <th>Component2_fraction</th>\n",
       "      <th>Component3_fraction</th>\n",
       "      <th>Component4_fraction</th>\n",
       "      <th>Component5_fraction</th>\n",
       "      <th>Component1_Property1</th>\n",
       "      <th>Component2_Property1</th>\n",
       "      <th>Component3_Property1</th>\n",
       "      <th>Component4_Property1</th>\n",
       "      <th>Component5_Property1</th>\n",
       "      <th>...</th>\n",
       "      <th>Component4_Cetane_Index</th>\n",
       "      <th>Component5_Cetane_Index</th>\n",
       "      <th>Blend_Cetane</th>\n",
       "      <th>Component1_Visc_Index</th>\n",
       "      <th>Component2_Visc_Index</th>\n",
       "      <th>Component3_Visc_Index</th>\n",
       "      <th>Component4_Visc_Index</th>\n",
       "      <th>Component5_Visc_Index</th>\n",
       "      <th>Blend_Visc_Index</th>\n",
       "      <th>Blend_Viscosity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Component1_fraction</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.417048</td>\n",
       "      <td>-0.471631</td>\n",
       "      <td>-0.167389</td>\n",
       "      <td>-0.008025</td>\n",
       "      <td>-0.027875</td>\n",
       "      <td>0.053371</td>\n",
       "      <td>-0.033673</td>\n",
       "      <td>0.021528</td>\n",
       "      <td>-0.036265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087875</td>\n",
       "      <td>-0.015246</td>\n",
       "      <td>8.067531e-03</td>\n",
       "      <td>-0.022745</td>\n",
       "      <td>-0.051726</td>\n",
       "      <td>-0.027253</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>-0.031384</td>\n",
       "      <td>0.051916</td>\n",
       "      <td>0.053481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component2_fraction</th>\n",
       "      <td>-0.417048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.414109</td>\n",
       "      <td>-0.232240</td>\n",
       "      <td>0.127492</td>\n",
       "      <td>-0.066247</td>\n",
       "      <td>-0.036146</td>\n",
       "      <td>-0.030215</td>\n",
       "      <td>-0.055298</td>\n",
       "      <td>0.030308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021001</td>\n",
       "      <td>-0.068870</td>\n",
       "      <td>-1.798708e-02</td>\n",
       "      <td>0.025552</td>\n",
       "      <td>-0.027303</td>\n",
       "      <td>-0.047138</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>-0.012047</td>\n",
       "      <td>-0.000568</td>\n",
       "      <td>-0.008005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component3_fraction</th>\n",
       "      <td>-0.471631</td>\n",
       "      <td>-0.414109</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.127871</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.022666</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.052068</td>\n",
       "      <td>-0.016428</td>\n",
       "      <td>0.013606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057357</td>\n",
       "      <td>0.089360</td>\n",
       "      <td>4.088864e-02</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.038046</td>\n",
       "      <td>0.071599</td>\n",
       "      <td>-0.079797</td>\n",
       "      <td>0.058767</td>\n",
       "      <td>-0.037559</td>\n",
       "      <td>-0.028843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component4_fraction</th>\n",
       "      <td>-0.167389</td>\n",
       "      <td>-0.232240</td>\n",
       "      <td>-0.127871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.693851</td>\n",
       "      <td>0.082520</td>\n",
       "      <td>-0.042324</td>\n",
       "      <td>0.017643</td>\n",
       "      <td>0.066503</td>\n",
       "      <td>-0.013267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044324</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>-2.999864e-02</td>\n",
       "      <td>0.015851</td>\n",
       "      <td>0.079788</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.043194</td>\n",
       "      <td>-0.010713</td>\n",
       "      <td>-0.024702</td>\n",
       "      <td>-0.023615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component5_fraction</th>\n",
       "      <td>-0.008025</td>\n",
       "      <td>0.127492</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>-0.693851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.053983</td>\n",
       "      <td>-0.006125</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>0.011192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053872</td>\n",
       "      <td>-0.023382</td>\n",
       "      <td>-1.216407e-02</td>\n",
       "      <td>-0.034740</td>\n",
       "      <td>-0.055724</td>\n",
       "      <td>-0.006029</td>\n",
       "      <td>0.048707</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>0.012440</td>\n",
       "      <td>0.004121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component3_Visc_Index</th>\n",
       "      <td>-0.027253</td>\n",
       "      <td>-0.047138</td>\n",
       "      <td>0.071599</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>-0.006029</td>\n",
       "      <td>0.041829</td>\n",
       "      <td>0.072967</td>\n",
       "      <td>0.013896</td>\n",
       "      <td>0.062971</td>\n",
       "      <td>-0.039238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012524</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>1.024779e-02</td>\n",
       "      <td>0.059567</td>\n",
       "      <td>-0.031880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.067017</td>\n",
       "      <td>-0.062365</td>\n",
       "      <td>-0.008237</td>\n",
       "      <td>-0.007775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component4_Visc_Index</th>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>-0.079797</td>\n",
       "      <td>0.043194</td>\n",
       "      <td>0.048707</td>\n",
       "      <td>-0.038648</td>\n",
       "      <td>0.077484</td>\n",
       "      <td>-0.010318</td>\n",
       "      <td>-0.023415</td>\n",
       "      <td>-0.041951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>-0.081022</td>\n",
       "      <td>-1.330528e-02</td>\n",
       "      <td>-0.005346</td>\n",
       "      <td>-0.009518</td>\n",
       "      <td>-0.067017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>0.224228</td>\n",
       "      <td>0.198419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Component5_Visc_Index</th>\n",
       "      <td>-0.031384</td>\n",
       "      <td>-0.012047</td>\n",
       "      <td>0.058767</td>\n",
       "      <td>-0.010713</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>-0.027988</td>\n",
       "      <td>-0.015058</td>\n",
       "      <td>-0.003946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219701</td>\n",
       "      <td>0.069831</td>\n",
       "      <td>-1.696028e-02</td>\n",
       "      <td>0.063523</td>\n",
       "      <td>0.047106</td>\n",
       "      <td>-0.062365</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.065482</td>\n",
       "      <td>-0.053600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blend_Visc_Index</th>\n",
       "      <td>0.051916</td>\n",
       "      <td>-0.000568</td>\n",
       "      <td>-0.037559</td>\n",
       "      <td>-0.024702</td>\n",
       "      <td>0.012440</td>\n",
       "      <td>-0.080831</td>\n",
       "      <td>-0.028490</td>\n",
       "      <td>-0.043929</td>\n",
       "      <td>-0.027459</td>\n",
       "      <td>0.006363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-1.893496e-16</td>\n",
       "      <td>-0.041048</td>\n",
       "      <td>-0.013691</td>\n",
       "      <td>-0.008237</td>\n",
       "      <td>0.224228</td>\n",
       "      <td>-0.065482</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blend_Viscosity</th>\n",
       "      <td>0.053481</td>\n",
       "      <td>-0.008005</td>\n",
       "      <td>-0.028843</td>\n",
       "      <td>-0.023615</td>\n",
       "      <td>0.004121</td>\n",
       "      <td>-0.082395</td>\n",
       "      <td>-0.039671</td>\n",
       "      <td>-0.047151</td>\n",
       "      <td>-0.020008</td>\n",
       "      <td>0.017693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>-0.003140</td>\n",
       "      <td>-2.313105e-16</td>\n",
       "      <td>-0.034632</td>\n",
       "      <td>-0.007185</td>\n",
       "      <td>-0.007775</td>\n",
       "      <td>0.198419</td>\n",
       "      <td>-0.053600</td>\n",
       "      <td>0.981551</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>564 rows × 564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Component1_fraction  Component2_fraction  \\\n",
       "Component1_fraction               1.000000            -0.417048   \n",
       "Component2_fraction              -0.417048             1.000000   \n",
       "Component3_fraction              -0.471631            -0.414109   \n",
       "Component4_fraction              -0.167389            -0.232240   \n",
       "Component5_fraction              -0.008025             0.127492   \n",
       "...                                    ...                  ...   \n",
       "Component3_Visc_Index            -0.027253            -0.047138   \n",
       "Component4_Visc_Index             0.016165             0.002990   \n",
       "Component5_Visc_Index            -0.031384            -0.012047   \n",
       "Blend_Visc_Index                  0.051916            -0.000568   \n",
       "Blend_Viscosity                   0.053481            -0.008005   \n",
       "\n",
       "                       Component3_fraction  Component4_fraction  \\\n",
       "Component1_fraction              -0.471631            -0.167389   \n",
       "Component2_fraction              -0.414109            -0.232240   \n",
       "Component3_fraction               1.000000            -0.127871   \n",
       "Component4_fraction              -0.127871             1.000000   \n",
       "Component5_fraction               0.002758            -0.693851   \n",
       "...                                    ...                  ...   \n",
       "Component3_Visc_Index             0.071599             0.006494   \n",
       "Component4_Visc_Index            -0.079797             0.043194   \n",
       "Component5_Visc_Index             0.058767            -0.010713   \n",
       "Blend_Visc_Index                 -0.037559            -0.024702   \n",
       "Blend_Viscosity                  -0.028843            -0.023615   \n",
       "\n",
       "                       Component5_fraction  Component1_Property1  \\\n",
       "Component1_fraction              -0.008025             -0.027875   \n",
       "Component2_fraction               0.127492             -0.066247   \n",
       "Component3_fraction               0.002758              0.022666   \n",
       "Component4_fraction              -0.693851              0.082520   \n",
       "Component5_fraction               1.000000              0.000474   \n",
       "...                                    ...                   ...   \n",
       "Component3_Visc_Index            -0.006029              0.041829   \n",
       "Component4_Visc_Index             0.048707             -0.038648   \n",
       "Component5_Visc_Index            -0.011495              0.007695   \n",
       "Blend_Visc_Index                  0.012440             -0.080831   \n",
       "Blend_Viscosity                   0.004121             -0.082395   \n",
       "\n",
       "                       Component2_Property1  Component3_Property1  \\\n",
       "Component1_fraction                0.053371             -0.033673   \n",
       "Component2_fraction               -0.036146             -0.030215   \n",
       "Component3_fraction               -0.008772              0.052068   \n",
       "Component4_fraction               -0.042324              0.017643   \n",
       "Component5_fraction                0.053983             -0.006125   \n",
       "...                                     ...                   ...   \n",
       "Component3_Visc_Index              0.072967              0.013896   \n",
       "Component4_Visc_Index              0.077484             -0.010318   \n",
       "Component5_Visc_Index              0.027681             -0.027988   \n",
       "Blend_Visc_Index                  -0.028490             -0.043929   \n",
       "Blend_Viscosity                   -0.039671             -0.047151   \n",
       "\n",
       "                       Component4_Property1  Component5_Property1  ...  \\\n",
       "Component1_fraction                0.021528             -0.036265  ...   \n",
       "Component2_fraction               -0.055298              0.030308  ...   \n",
       "Component3_fraction               -0.016428              0.013606  ...   \n",
       "Component4_fraction                0.066503             -0.013267  ...   \n",
       "Component5_fraction               -0.017857              0.011192  ...   \n",
       "...                                     ...                   ...  ...   \n",
       "Component3_Visc_Index              0.062971             -0.039238  ...   \n",
       "Component4_Visc_Index             -0.023415             -0.041951  ...   \n",
       "Component5_Visc_Index             -0.015058             -0.003946  ...   \n",
       "Blend_Visc_Index                  -0.027459              0.006363  ...   \n",
       "Blend_Viscosity                   -0.020008              0.017693  ...   \n",
       "\n",
       "                       Component4_Cetane_Index  Component5_Cetane_Index  \\\n",
       "Component1_fraction                   0.087875                -0.015246   \n",
       "Component2_fraction                  -0.021001                -0.068870   \n",
       "Component3_fraction                  -0.057357                 0.089360   \n",
       "Component4_fraction                  -0.044324                 0.005887   \n",
       "Component5_fraction                   0.053872                -0.023382   \n",
       "...                                        ...                      ...   \n",
       "Component3_Visc_Index                -0.012524                 0.002293   \n",
       "Component4_Visc_Index                 0.003464                -0.081022   \n",
       "Component5_Visc_Index                -0.219701                 0.069831   \n",
       "Blend_Visc_Index                      0.003366                 0.001392   \n",
       "Blend_Viscosity                       0.004022                -0.003140   \n",
       "\n",
       "                       Blend_Cetane  Component1_Visc_Index  \\\n",
       "Component1_fraction    8.067531e-03              -0.022745   \n",
       "Component2_fraction   -1.798708e-02               0.025552   \n",
       "Component3_fraction    4.088864e-02               0.001234   \n",
       "Component4_fraction   -2.999864e-02               0.015851   \n",
       "Component5_fraction   -1.216407e-02              -0.034740   \n",
       "...                             ...                    ...   \n",
       "Component3_Visc_Index  1.024779e-02               0.059567   \n",
       "Component4_Visc_Index -1.330528e-02              -0.005346   \n",
       "Component5_Visc_Index -1.696028e-02               0.063523   \n",
       "Blend_Visc_Index      -1.893496e-16              -0.041048   \n",
       "Blend_Viscosity       -2.313105e-16              -0.034632   \n",
       "\n",
       "                       Component2_Visc_Index  Component3_Visc_Index  \\\n",
       "Component1_fraction                -0.051726              -0.027253   \n",
       "Component2_fraction                -0.027303              -0.047138   \n",
       "Component3_fraction                 0.038046               0.071599   \n",
       "Component4_fraction                 0.079788               0.006494   \n",
       "Component5_fraction                -0.055724              -0.006029   \n",
       "...                                      ...                    ...   \n",
       "Component3_Visc_Index              -0.031880               1.000000   \n",
       "Component4_Visc_Index              -0.009518              -0.067017   \n",
       "Component5_Visc_Index               0.047106              -0.062365   \n",
       "Blend_Visc_Index                   -0.013691              -0.008237   \n",
       "Blend_Viscosity                    -0.007185              -0.007775   \n",
       "\n",
       "                       Component4_Visc_Index  Component5_Visc_Index  \\\n",
       "Component1_fraction                 0.016165              -0.031384   \n",
       "Component2_fraction                 0.002990              -0.012047   \n",
       "Component3_fraction                -0.079797               0.058767   \n",
       "Component4_fraction                 0.043194              -0.010713   \n",
       "Component5_fraction                 0.048707              -0.011495   \n",
       "...                                      ...                    ...   \n",
       "Component3_Visc_Index              -0.067017              -0.062365   \n",
       "Component4_Visc_Index               1.000000              -0.002016   \n",
       "Component5_Visc_Index              -0.002016               1.000000   \n",
       "Blend_Visc_Index                    0.224228              -0.065482   \n",
       "Blend_Viscosity                     0.198419              -0.053600   \n",
       "\n",
       "                       Blend_Visc_Index  Blend_Viscosity  \n",
       "Component1_fraction            0.051916         0.053481  \n",
       "Component2_fraction           -0.000568        -0.008005  \n",
       "Component3_fraction           -0.037559        -0.028843  \n",
       "Component4_fraction           -0.024702        -0.023615  \n",
       "Component5_fraction            0.012440         0.004121  \n",
       "...                                 ...              ...  \n",
       "Component3_Visc_Index         -0.008237        -0.007775  \n",
       "Component4_Visc_Index          0.224228         0.198419  \n",
       "Component5_Visc_Index         -0.065482        -0.053600  \n",
       "Blend_Visc_Index               1.000000         0.981551  \n",
       "Blend_Viscosity                0.981551         1.000000  \n",
       "\n",
       "[564 rows x 564 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(list(train_dataset.isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_dataset=train_dataset.interpolate(method='linear',limit_direction='both')#.isna().sum()\n",
    "# train_dataset.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# train_dataset=train_dataset.interpolate(method='linear',limit_direction='both')#.isna().sum()\n",
    "# poly = PolynomialFeatures(degree=(2),interaction_only=True,include_bias=False)\n",
    "# poly.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = poly.transform(train_dataset)\n",
    "# scaler = StandardScaler().fit(train_dataset)\n",
    "# train_dataset = scaler.transform(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset=test_dataset.interpolate(method='linear',limit_direction='both')#.isna().sum()\n",
    "# test_dataset.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# test_dataset=test_dataset.interpolate(method='linear',limit_direction='both')#.isna().sum()\n",
    "# test_dataset = poly.transform(test_dataset)\n",
    "# test_dataset = scaler.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset=train_dataset.interpolate(method='linear',limit_direction='both')\n",
    "# train_dataset.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# train_dataset=train_dataset.interpolate(method='linear',limit_direction='both')\n",
    "# poly = PolynomialFeatures(degree=(2),include_bias=False)\n",
    "# poly.fit(train_dataset.iloc[:,:55])\n",
    "# train_log = np.log1p(np.maximum(train_dataset.iloc[:, :55], 1e-6))  \n",
    "\n",
    "# train_dataset_55 = poly.transform(train_dataset.iloc[:,:55])\n",
    "# train_dataset = np.hstack([train_dataset_55, train_log,  np.array(train_dataset.iloc[:,55:])])\n",
    "# scaler = StandardScaler().fit(train_dataset)\n",
    "# train_dataset = pd.DataFrame(scaler.transform(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset=test_dataset.interpolate(method='linear',limit_direction='both')#.isna().sum()\n",
    "# test_dataset.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# test_dataset=test_dataset.interpolate(method='linear',limit_direction='both')#.isna().sum()\n",
    "# test_log = np.log1p(np.maximum(test_dataset.iloc[:, :55], 1e-6))\n",
    "\n",
    "# test_dataset_55 = poly.transform(test_dataset.iloc[:,:55])\n",
    "# test_dataset = pd.DataFrame(np.hstack([test_dataset_55, test_log, np.array(test_dataset.iloc[:,55:])]))\n",
    "# test_dataset = pd.DataFrame(scaler.transform(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Fix infinities and NaNs\n",
    "# train_dataset = train_dataset.replace([np.inf, -np.inf], np.nan)\n",
    "# train_dataset = train_dataset.interpolate(method='linear', limit_direction='both')\n",
    "# train_dataset = train_dataset.fillna(train_dataset.mean())\n",
    "\n",
    "# test_dataset = test_dataset.replace([np.inf, -np.inf], np.nan)\n",
    "# test_dataset = test_dataset.interpolate(method='linear', limit_direction='both')\n",
    "# test_dataset = test_dataset.fillna(test_dataset.mean())\n",
    "\n",
    "# # Apply log transform only to relevant features\n",
    "# log_cols = [col for col in train_dataset.columns if 'fraction' in col or 'Property' in col]\n",
    "# for col in log_cols:\n",
    "#     train_dataset[col] = np.log1p(np.maximum(train_dataset[col], 1e-6))\n",
    "#     test_dataset[col]  = np.log1p(np.maximum(test_dataset[col], 1e-6))\n",
    "\n",
    "# # Normalize everything\n",
    "# scaler = StandardScaler()\n",
    "# train_dataset = pd.DataFrame(scaler.fit_transform(train_dataset), columns=train_dataset.columns)\n",
    "# test_dataset  = pd.DataFrame(scaler.transform(test_dataset), columns=test_dataset.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 75 correlated features: ['Component4_fraction_Sq', 'Component4_fraction_Sqrt', 'Comp1_Prop1_Adj', 'Comp2_Prop1_Adj', 'Comp3_Prop1_Adj', 'Comp4_Prop1_Adj', 'Comp5_Prop1_Adj', 'Comp1_Prop2_Adj', 'Comp2_Prop2_Adj', 'Comp3_Prop2_Adj', 'Comp4_Prop2_Adj', 'Comp5_Prop2_Adj', 'Comp1_Prop3_Adj', 'Comp2_Prop3_Adj', 'Comp3_Prop3_Adj', 'Comp4_Prop3_Adj', 'Comp5_Prop3_Adj', 'Comp1_Prop4_Adj', 'Comp2_Prop4_Adj', 'Comp3_Prop4_Adj', 'Comp4_Prop4_Adj', 'Comp5_Prop4_Adj', 'Comp1_Prop5_Adj', 'Comp2_Prop5_Adj', 'Comp3_Prop5_Adj', 'Comp4_Prop5_Adj', 'Comp5_Prop5_Adj', 'Comp1_Prop6_Adj', 'Comp2_Prop6_Adj', 'Comp3_Prop6_Adj', 'Comp4_Prop6_Adj', 'Comp5_Prop6_Adj', 'Comp1_Prop7_Adj', 'Comp2_Prop7_Adj', 'Comp3_Prop7_Adj', 'Comp4_Prop7_Adj', 'Comp5_Prop7_Adj', 'Comp1_Prop8_Adj', 'Comp2_Prop8_Adj', 'Comp3_Prop8_Adj', 'Comp4_Prop8_Adj', 'Comp5_Prop8_Adj', 'Comp1_Prop9_Adj', 'Comp2_Prop9_Adj', 'Comp3_Prop9_Adj', 'Comp4_Prop9_Adj', 'Comp5_Prop9_Adj', 'Comp1_Prop10_Adj', 'Comp2_Prop10_Adj', 'Comp3_Prop10_Adj', 'Comp4_Prop10_Adj', 'Comp5_Prop10_Adj', 'Comp2_Contrib_Prop2', 'Comp3_Contrib_Prop2', 'Comp4_Contrib_Prop2', 'Comp5_Contrib_Prop2', 'Comp4_Contrib_Prop7', 'Comp5_Contrib_Prop7', 'Comp3_Contrib_Prop10', 'Comp4_Contrib_Prop10', 'Comp5_Contrib_Prop10', 'Component1_SG', 'Component2_SG', 'Component3_SG', 'Component4_SG', 'Component5_SG', 'Blend_SG', 'Blend_API', 'Blend_Sulfur', 'Component1_RON_BlendValue', 'Component2_RON_BlendValue', 'Component3_RON_BlendValue', 'Component4_RON_BlendValue', 'Component5_RON_BlendValue', 'Blend_RON']\n",
      "Final feature count: 483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# --- 1. Drop near-zero variance features ---\n",
    "# Threshold is the variance; tune as needed (e.g. 1e-5)\n",
    "var_selector = VarianceThreshold(threshold=1e-5)\n",
    "var_selector.fit(train_dataset)\n",
    "\n",
    "# Keep the mask of good features\n",
    "mask = var_selector.get_support()\n",
    "selected_features = train_dataset.columns[mask]\n",
    "\n",
    "# Reduce both datasets to those features\n",
    "train_dataset = train_dataset[selected_features]\n",
    "test_dataset  = test_dataset[selected_features]\n",
    "\n",
    "# --- 2. Drop highly correlated features ---\n",
    "# Compute correlation matrix on train only\n",
    "corr_matrix = train_dataset.corr().abs()\n",
    "upper_tri  = corr_matrix.where(\n",
    "    np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    ")\n",
    "\n",
    "# Identify columns to drop (corr > 0.98)\n",
    "to_drop = [col for col in upper_tri.columns if any(upper_tri[col] > 0.98)]\n",
    "\n",
    "# Drop them\n",
    "train_dataset = train_dataset.drop(columns=to_drop)\n",
    "test_dataset  = test_dataset.drop(columns=to_drop)\n",
    "\n",
    "print(f\"Dropped {len(to_drop)} correlated features: {to_drop}\")\n",
    "print(f\"Final feature count: {train_dataset.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component1_fraction</th>\n",
       "      <th>Component2_fraction</th>\n",
       "      <th>Component3_fraction</th>\n",
       "      <th>Component4_fraction</th>\n",
       "      <th>Component5_fraction</th>\n",
       "      <th>Component1_Property1</th>\n",
       "      <th>Component2_Property1</th>\n",
       "      <th>Component3_Property1</th>\n",
       "      <th>Component4_Property1</th>\n",
       "      <th>Component5_Property1</th>\n",
       "      <th>...</th>\n",
       "      <th>Component4_Cetane_Index</th>\n",
       "      <th>Component5_Cetane_Index</th>\n",
       "      <th>Blend_Cetane</th>\n",
       "      <th>Component1_Visc_Index</th>\n",
       "      <th>Component2_Visc_Index</th>\n",
       "      <th>Component3_Visc_Index</th>\n",
       "      <th>Component4_Visc_Index</th>\n",
       "      <th>Component5_Visc_Index</th>\n",
       "      <th>Blend_Visc_Index</th>\n",
       "      <th>Blend_Viscosity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.177804</td>\n",
       "      <td>-0.741219</td>\n",
       "      <td>0.769821</td>\n",
       "      <td>-0.877069</td>\n",
       "      <td>0.602809</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.299825</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.501354</td>\n",
       "      <td>0.177344</td>\n",
       "      <td>-0.498739</td>\n",
       "      <td>-0.196742</td>\n",
       "      <td>-1.943463</td>\n",
       "      <td>...</td>\n",
       "      <td>430.534316</td>\n",
       "      <td>423.240164</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-1.219901</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.547324</td>\n",
       "      <td>0.891479</td>\n",
       "      <td>0.030627</td>\n",
       "      <td>-0.368678</td>\n",
       "      <td>-0.294728</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>663.815825</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-0.663087</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.424427</td>\n",
       "      <td>1.016862</td>\n",
       "      <td>-1.182979</td>\n",
       "      <td>-0.854225</td>\n",
       "      <td>-0.830186</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-2.890751</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.187062</td>\n",
       "      <td>-0.762173</td>\n",
       "      <td>-0.473660</td>\n",
       "      <td>2.074087</td>\n",
       "      <td>0.756849</td>\n",
       "      <td>...</td>\n",
       "      <td>456.068496</td>\n",
       "      <td>424.246233</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-3.376006</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.036797</td>\n",
       "      <td>1.415667</td>\n",
       "      <td>0.793302</td>\n",
       "      <td>-0.446630</td>\n",
       "      <td>0.395524</td>\n",
       "      <td>...</td>\n",
       "      <td>422.428886</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-1.305137</td>\n",
       "      <td>-1.520941</td>\n",
       "      <td>-0.989537</td>\n",
       "      <td>0.903203</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>436.733566</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>0.012447</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-1.866185</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.806590</td>\n",
       "      <td>0.607324</td>\n",
       "      <td>0.359058</td>\n",
       "      <td>0.283394</td>\n",
       "      <td>1.032029</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.792140</td>\n",
       "      <td>0.674275</td>\n",
       "      <td>-1.783487</td>\n",
       "      <td>0.848296</td>\n",
       "      <td>0.164798</td>\n",
       "      <td>...</td>\n",
       "      <td>427.382124</td>\n",
       "      <td>517.803098</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-2.395279</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.970853</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.327778</td>\n",
       "      <td>0.248042</td>\n",
       "      <td>-1.199065</td>\n",
       "      <td>1.845241</td>\n",
       "      <td>0.772672</td>\n",
       "      <td>...</td>\n",
       "      <td>533.739728</td>\n",
       "      <td>446.468787</td>\n",
       "      <td>476.367101</td>\n",
       "      <td>-1.055064</td>\n",
       "      <td>-0.845686</td>\n",
       "      <td>-1.197669</td>\n",
       "      <td>-1.111906</td>\n",
       "      <td>-0.739801</td>\n",
       "      <td>-1.303419</td>\n",
       "      <td>0.549224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 483 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Component1_fraction  Component2_fraction  Component3_fraction  \\\n",
       "ID                                                                   \n",
       "1                   0.18                 0.05                 0.32   \n",
       "2                   0.00                 0.50                 0.00   \n",
       "3                   0.16                 0.00                 0.17   \n",
       "4                   0.50                 0.00                 0.17   \n",
       "5                   0.00                 0.00                 0.50   \n",
       "..                   ...                  ...                  ...   \n",
       "496                 0.44                 0.01                 0.08   \n",
       "497                 0.19                 0.47                 0.03   \n",
       "498                 0.43                 0.01                 0.12   \n",
       "499                 0.03                 0.04                 0.42   \n",
       "500                 0.00                 0.50                 0.00   \n",
       "\n",
       "     Component4_fraction  Component5_fraction  Component1_Property1  \\\n",
       "ID                                                                    \n",
       "1                   0.37                 0.08             -0.177804   \n",
       "2                   0.37                 0.13              2.501354   \n",
       "3                   0.50                 0.17              1.547324   \n",
       "4                   0.16                 0.17             -0.424427   \n",
       "5                   0.50                 0.00             -0.187062   \n",
       "..                   ...                  ...                   ...   \n",
       "496                 0.41                 0.06              1.036797   \n",
       "497                 0.23                 0.08             -1.305137   \n",
       "498                 0.21                 0.23              0.806590   \n",
       "499                 0.42                 0.09             -0.792140   \n",
       "500                 0.50                 0.00             -0.327778   \n",
       "\n",
       "     Component2_Property1  Component3_Property1  Component4_Property1  \\\n",
       "ID                                                                      \n",
       "1               -0.741219              0.769821             -0.877069   \n",
       "2                0.177344             -0.498739             -0.196742   \n",
       "3                0.891479              0.030627             -0.368678   \n",
       "4                1.016862             -1.182979             -0.854225   \n",
       "5               -0.762173             -0.473660              2.074087   \n",
       "..                    ...                   ...                   ...   \n",
       "496              1.415667              0.793302             -0.446630   \n",
       "497             -1.520941             -0.989537              0.903203   \n",
       "498              0.607324              0.359058              0.283394   \n",
       "499              0.674275             -1.783487              0.848296   \n",
       "500              0.248042             -1.199065              1.845241   \n",
       "\n",
       "     Component5_Property1  ...  Component4_Cetane_Index  \\\n",
       "ID                         ...                            \n",
       "1                0.602809  ...               533.739728   \n",
       "2               -1.943463  ...               430.534316   \n",
       "3               -0.294728  ...               533.739728   \n",
       "4               -0.830186  ...               533.739728   \n",
       "5                0.756849  ...               456.068496   \n",
       "..                    ...  ...                      ...   \n",
       "496              0.395524  ...               422.428886   \n",
       "497              1.032029  ...               436.733566   \n",
       "498              1.032029  ...               533.739728   \n",
       "499              0.164798  ...               427.382124   \n",
       "500              0.772672  ...               533.739728   \n",
       "\n",
       "     Component5_Cetane_Index  Blend_Cetane  Component1_Visc_Index  \\\n",
       "ID                                                                  \n",
       "1                 517.803098    476.367101              -1.055064   \n",
       "2                 423.240164    476.367101              -1.055064   \n",
       "3                 663.815825    476.367101              -1.055064   \n",
       "4                 517.803098    476.367101              -1.055064   \n",
       "5                 424.246233    476.367101              -1.055064   \n",
       "..                       ...           ...                    ...   \n",
       "496               517.803098    476.367101              -1.055064   \n",
       "497               517.803098    476.367101              -1.055064   \n",
       "498               517.803098    476.367101              -1.055064   \n",
       "499               517.803098    476.367101              -1.055064   \n",
       "500               446.468787    476.367101              -1.055064   \n",
       "\n",
       "     Component2_Visc_Index  Component3_Visc_Index  Component4_Visc_Index  \\\n",
       "ID                                                                         \n",
       "1                -0.845686              -1.197669              -1.111906   \n",
       "2                -0.845686              -1.197669              -1.111906   \n",
       "3                -0.845686              -0.663087              -1.111906   \n",
       "4                -2.890751              -1.197669              -1.111906   \n",
       "5                -0.845686              -1.197669              -3.376006   \n",
       "..                     ...                    ...                    ...   \n",
       "496              -0.845686              -1.197669              -1.111906   \n",
       "497              -0.845686               0.012447              -1.111906   \n",
       "498              -0.845686              -1.197669              -1.111906   \n",
       "499              -0.845686              -2.395279              -1.111906   \n",
       "500              -0.845686              -1.197669              -1.111906   \n",
       "\n",
       "     Component5_Visc_Index  Blend_Visc_Index  Blend_Viscosity  \n",
       "ID                                                             \n",
       "1                -0.299825         -1.303419         0.549224  \n",
       "2                -1.219901         -1.303419         0.549224  \n",
       "3                -0.970853         -1.303419         0.549224  \n",
       "4                -0.970853         -1.303419         0.549224  \n",
       "5                -0.970853         -1.303419         0.549224  \n",
       "..                     ...               ...              ...  \n",
       "496              -0.970853         -1.303419         0.549224  \n",
       "497              -1.866185         -1.303419         0.549224  \n",
       "498              -0.970853         -1.303419         0.549224  \n",
       "499              -0.970853         -1.303419         0.549224  \n",
       "500              -0.739801         -1.303419         0.549224  \n",
       "\n",
       "[500 rows x 483 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Columns: 483 entries, Component1_fraction to Blend_Viscosity\n",
      "dtypes: float64(433), int64(50)\n",
      "memory usage: 7.4 MB\n"
     ]
    }
   ],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the  test data and make testset and validationset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(train_dataset,output_blends, random_state=42, test_size=0.05,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (2000, 483)\n",
      "Test Shape : (500, 483)\n",
      "Any NaNs: 0 0\n",
      "Any Infs: 0 0\n"
     ]
    }
   ],
   "source": [
    "# sns.pairplot(train_dataset)\n",
    "print(\"Train Shape:\", train_dataset.shape)\n",
    "print(\"Test Shape :\", test_dataset.shape)\n",
    "print(\"Any NaNs:\", train_dataset.isna().sum().sum(), test_dataset.isna().sum().sum())\n",
    "print(\"Any Infs:\", np.isinf(train_dataset.to_numpy()).sum(), np.isinf(test_dataset.to_numpy()).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Tablenet The transformet approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabpfn in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (2.0.9)\n",
      "Requirement already satisfied: torch<3,>=2.1 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from tabpfn) (2.3.1.post100)\n",
      "Requirement already satisfied: scikit-learn<1.7,>=1.2.0 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from tabpfn) (1.6.1)\n",
      "Requirement already satisfied: typing_extensions>=4.4.0 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from tabpfn) (4.13.2)\n",
      "Requirement already satisfied: scipy<2,>=1.11.1 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from tabpfn) (1.13.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from tabpfn) (2.2.3)\n",
      "Requirement already satisfied: einops<0.9,>=0.2.0 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from tabpfn) (0.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1,>=0.0.1 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from tabpfn) (0.30.2)\n",
      "Requirement already satisfied: filelock in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from huggingface-hub<1,>=0.0.1->tabpfn) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from huggingface-hub<1,>=0.0.1->tabpfn) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from huggingface-hub<1,>=0.0.1->tabpfn) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from huggingface-hub<1,>=0.0.1->tabpfn) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from huggingface-hub<1,>=0.0.1->tabpfn) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from huggingface-hub<1,>=0.0.1->tabpfn) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from pandas<3,>=1.4.0->tabpfn) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from pandas<3,>=1.4.0->tabpfn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from pandas<3,>=1.4.0->tabpfn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from pandas<3,>=1.4.0->tabpfn) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from scikit-learn<1.7,>=1.2.0->tabpfn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from scikit-learn<1.7,>=1.2.0->tabpfn) (3.5.0)\n",
      "Requirement already satisfied: sympy in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from torch<3,>=2.1->tabpfn) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from torch<3,>=2.1->tabpfn) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from torch<3,>=2.1->tabpfn) (3.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->tabpfn) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from jinja2->torch<3,>=2.1->tabpfn) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from requests->huggingface-hub<1,>=0.0.1->tabpfn) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from requests->huggingface-hub<1,>=0.0.1->tabpfn) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from requests->huggingface-hub<1,>=0.0.1->tabpfn) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from requests->huggingface-hub<1,>=0.0.1->tabpfn) (2025.6.15)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/harshit/miniconda3/envs/dl_env/lib/python3.9/site-packages (from sympy->torch<3,>=2.1->tabpfn) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tabpfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier, TabPFNRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_reg = TabPFNRegressor(device=\"auto\",random_state=42,n_jobs=12)\n",
    "multioutput_tab_reg = MultiOutputRegressor(estimator=tab_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=TabPFNRegressor(n_jobs=12, random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultiOutputRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.multioutput.MultiOutputRegressor.html\">?<span>Documentation for MultiOutputRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultiOutputRegressor(estimator=TabPFNRegressor(n_jobs=12, random_state=42))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: TabPFNRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>TabPFNRegressor(n_jobs=12, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TabPFNRegressor</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>TabPFNRegressor(n_jobs=12, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputRegressor(estimator=TabPFNRegressor(n_jobs=12, random_state=42))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multioutput_tab_reg.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multioutput_tabpfn_model.pkl']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "# joblib.dump(multioutput_tab_reg, 'multioutput_tabpfn_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "loaded_model = joblib.load('models/multioutput_tabpfn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_0  = loaded_model.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.0015583925414830446\n",
      "MAE:  0.02197359874844551\n",
      "R2 :  0.9984424710273743\n",
      "MAPE: 0.08065234124660492\n"
     ]
    }
   ],
   "source": [
    "tab_reg_pred = val_pred_0 # loaded_model.predict(val_X)\n",
    "print(\"MSE: \", mean_squared_error(val_y, tab_reg_pred))\n",
    "print(\"MAE: \", mean_absolute_error(val_y, tab_reg_pred))\n",
    "print(\"R2 : \", r2_score(val_y, tab_reg_pred))\n",
    "print(\"MAPE:\", mean_absolute_percentage_error(val_y, tab_reg_pred))\n",
    "\n",
    "# MSE:  0.0047077895142138\n",
    "# MAE:  0.037359997630119324\n",
    "# R2 :  0.9953439831733704\n",
    "# MAPE: 0.09279724210500717"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tabpfn_0 = loaded_model.predict(train_X)\n",
    "train_y_0 = train_y-pred_tabpfn_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlendProperty1</th>\n",
       "      <th>BlendProperty2</th>\n",
       "      <th>BlendProperty3</th>\n",
       "      <th>BlendProperty4</th>\n",
       "      <th>BlendProperty5</th>\n",
       "      <th>BlendProperty6</th>\n",
       "      <th>BlendProperty7</th>\n",
       "      <th>BlendProperty8</th>\n",
       "      <th>BlendProperty9</th>\n",
       "      <th>BlendProperty10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146256</td>\n",
       "      <td>0.228081</td>\n",
       "      <td>0.724894</td>\n",
       "      <td>0.613146</td>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.705358</td>\n",
       "      <td>0.687902</td>\n",
       "      <td>0.360928</td>\n",
       "      <td>-0.336821</td>\n",
       "      <td>0.347265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.792640</td>\n",
       "      <td>-0.610718</td>\n",
       "      <td>-1.197447</td>\n",
       "      <td>0.063722</td>\n",
       "      <td>-0.728111</td>\n",
       "      <td>-0.120152</td>\n",
       "      <td>-1.191815</td>\n",
       "      <td>-1.050328</td>\n",
       "      <td>-0.933696</td>\n",
       "      <td>0.030162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.761511</td>\n",
       "      <td>1.128711</td>\n",
       "      <td>1.062112</td>\n",
       "      <td>1.069652</td>\n",
       "      <td>2.471631</td>\n",
       "      <td>1.876843</td>\n",
       "      <td>1.027547</td>\n",
       "      <td>1.999289</td>\n",
       "      <td>0.784179</td>\n",
       "      <td>2.252076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.457512</td>\n",
       "      <td>0.309946</td>\n",
       "      <td>0.901764</td>\n",
       "      <td>-0.718745</td>\n",
       "      <td>1.878562</td>\n",
       "      <td>-0.453220</td>\n",
       "      <td>0.831742</td>\n",
       "      <td>1.781024</td>\n",
       "      <td>0.877961</td>\n",
       "      <td>-0.963787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.158982</td>\n",
       "      <td>-1.220972</td>\n",
       "      <td>1.099539</td>\n",
       "      <td>0.456752</td>\n",
       "      <td>2.454814</td>\n",
       "      <td>0.276937</td>\n",
       "      <td>1.068825</td>\n",
       "      <td>-0.131095</td>\n",
       "      <td>-0.505778</td>\n",
       "      <td>1.060656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.173990</td>\n",
       "      <td>-0.857383</td>\n",
       "      <td>1.234391</td>\n",
       "      <td>-0.290468</td>\n",
       "      <td>-0.278197</td>\n",
       "      <td>-0.743100</td>\n",
       "      <td>1.197358</td>\n",
       "      <td>-0.444928</td>\n",
       "      <td>-1.457120</td>\n",
       "      <td>-0.432238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-2.176230</td>\n",
       "      <td>-1.322172</td>\n",
       "      <td>-1.020217</td>\n",
       "      <td>-2.378759</td>\n",
       "      <td>-0.627009</td>\n",
       "      <td>-2.445888</td>\n",
       "      <td>-1.020925</td>\n",
       "      <td>-1.907284</td>\n",
       "      <td>-1.337142</td>\n",
       "      <td>-1.347159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1.999039</td>\n",
       "      <td>2.208122</td>\n",
       "      <td>0.303988</td>\n",
       "      <td>1.188128</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.677275</td>\n",
       "      <td>0.290452</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>0.230334</td>\n",
       "      <td>0.483903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-0.117363</td>\n",
       "      <td>0.805450</td>\n",
       "      <td>1.646922</td>\n",
       "      <td>-1.404110</td>\n",
       "      <td>-0.913799</td>\n",
       "      <td>0.201230</td>\n",
       "      <td>1.987247</td>\n",
       "      <td>0.616391</td>\n",
       "      <td>0.171065</td>\n",
       "      <td>1.289822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-1.025699</td>\n",
       "      <td>-1.930219</td>\n",
       "      <td>-1.958083</td>\n",
       "      <td>-1.641897</td>\n",
       "      <td>-0.024012</td>\n",
       "      <td>-1.819605</td>\n",
       "      <td>-1.939444</td>\n",
       "      <td>-1.910300</td>\n",
       "      <td>-2.334517</td>\n",
       "      <td>-0.198695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BlendProperty1  BlendProperty2  BlendProperty3  BlendProperty4  \\\n",
       "ID                                                                    \n",
       "1          0.146256        0.228081        0.724894        0.613146   \n",
       "2         -0.792640       -0.610718       -1.197447        0.063722   \n",
       "3          1.761511        1.128711        1.062112        1.069652   \n",
       "4         -0.457512        0.309946        0.901764       -0.718745   \n",
       "5          0.158982       -1.220972        1.099539        0.456752   \n",
       "..              ...             ...             ...             ...   \n",
       "496        0.173990       -0.857383        1.234391       -0.290468   \n",
       "497       -2.176230       -1.322172       -1.020217       -2.378759   \n",
       "498        1.999039        2.208122        0.303988        1.188128   \n",
       "499       -0.117363        0.805450        1.646922       -1.404110   \n",
       "500       -1.025699       -1.930219       -1.958083       -1.641897   \n",
       "\n",
       "     BlendProperty5  BlendProperty6  BlendProperty7  BlendProperty8  \\\n",
       "ID                                                                    \n",
       "1          0.353818        0.705358        0.687902        0.360928   \n",
       "2         -0.728111       -0.120152       -1.191815       -1.050328   \n",
       "3          2.471631        1.876843        1.027547        1.999289   \n",
       "4          1.878562       -0.453220        0.831742        1.781024   \n",
       "5          2.454814        0.276937        1.068825       -0.131095   \n",
       "..              ...             ...             ...             ...   \n",
       "496       -0.278197       -0.743100        1.197358       -0.444928   \n",
       "497       -0.627009       -2.445888       -1.020925       -1.907284   \n",
       "498        0.007698        0.677275        0.290452        0.999529   \n",
       "499       -0.913799        0.201230        1.987247        0.616391   \n",
       "500       -0.024012       -1.819605       -1.939444       -1.910300   \n",
       "\n",
       "     BlendProperty9  BlendProperty10  \n",
       "ID                                    \n",
       "1         -0.336821         0.347265  \n",
       "2         -0.933696         0.030162  \n",
       "3          0.784179         2.252076  \n",
       "4          0.877961        -0.963787  \n",
       "5         -0.505778         1.060656  \n",
       "..              ...              ...  \n",
       "496       -1.457120        -0.432238  \n",
       "497       -1.337142        -1.347159  \n",
       "498        0.230334         0.483903  \n",
       "499        0.171065         1.289822  \n",
       "500       -2.334517        -0.198695  \n",
       "\n",
       "[500 rows x 10 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tab_reg_pred = loaded_model.predict(test_dataset)\n",
    "# tab_reg_pred = pd.DataFrame(tab_reg_pred,columns=['BlendProperty1', 'BlendProperty2', 'BlendProperty3', 'BlendProperty4',\n",
    "#        'BlendProperty5', 'BlendProperty6', 'BlendProperty7', 'BlendProperty8',\n",
    "#        'BlendProperty9', 'BlendProperty10'],index=test_dataset.index)\n",
    "# tab_reg_pred.to_csv('_output_tabpfreg.csv')\n",
    "# tab_reg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [1872, 526, 173, 720, 414, 237, 1472, 1335, 1063, 23, 1766, 63, 289, 188, 701, 1814, 1137, 354, 416, 1245, 930, 196, 579, 1134, 1813, 1934, 433, 100, 1654, 394, 1938, 220, 1675, 1497, 1784, 344, 1027, 888, 1350, 552, 743, 1541, 538, 906, 1394, 115, 829, 1937, 808, 1310, 1004, 305, 1100, 479, 1423, 1075, 570, 618, 1897, 1265, 78, 1911, 32, 1537, 1033, 1562, 351, 163, 203, 1053, 1364, 1966, 495, 1624, 1965, 1962, 610, 432, 1491, 218, 1930, 1465, 630, 1381, 1301, 59, 298, 1710, 73, 162, 1274, 1593, 1433, 1612, 591, 316, 45, 1719, 1831, 427, ...]\n",
       "\n",
       "[1800 rows x 0 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y#.iloc[:,:1-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tabpfn import TabPFNClassifier, TabPFNRegressor\n",
    "# import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training the model \n",
    "# for _ in range(1,11):\n",
    "#     f'tab_reg_{_}0'  = TabPFNRegressor(device=\"auto\",random_state=42,n_jobs=12)\n",
    "#     (f'tab_reg_{_}0').fit(np.hstack([train_X, train_y.iloc[:,:_-1]), trian_y[f'BlendProperty{_}'])\n",
    "#     (f'pred_{_}0') = (f'tab_reg + {_}0').predict(train_X)\n",
    "#     f'train_y_diff_{_}1' = train_y[f'BlendProperty{_}'] - (pred+ f'_{_}0')\n",
    "#     f'tab_reg_{_}1'  = TabPFNRegressor(device=\"auto\",random_state=42,n_jobs=12)\n",
    "#     f'tab_reg_{_}1'.fit(np.hstack([train_X, train_y.iloc[:,:_-1]), (train_y_diff + f'_{_}1'))\n",
    "#     joblib.dump((f'tab_reg_{_}0'), f\"tab_reg_{_}0.pkl\")\n",
    "#     joblib.dump((f'tab_reg_{_}1'), f\"tab_reg_{_}1.pkl\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc1'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Loading and making the prediction from the model\n",
    "# prediction  = []\n",
    "# for _ in range(1,11):\n",
    "#     f'tab_reg_{_}0' = joblib.load((f'tab_reg_{_}0'), f\"tab_reg_{_}0.pkl\")\n",
    "#     f'tab_reg_{_}1' =  joblib.load((f'tab_reg_{_}1'), f\"tab_reg_{_}1.pkl\") \n",
    "#     prediction.append((f'tab_reg_{_}0').predict(np.hstack([train_X, prediction[:,:_-1])))\n",
    "#     prediction[:,_-1] += (f'tab_reg_{_}1').predict(np.hstack([train_X, prediction[:,:_-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tab_reg_pred = prediction # loaded_model.predict(val_X)\n",
    "# print(\"MSE: \", mean_squared_error(val_y, tab_reg_pred))\n",
    "# print(\"MAE: \", mean_absolute_error(val_y, tab_reg_pred))\n",
    "# print(\"R2 : \", r2_score(val_y, tab_reg_pred))\n",
    "# print(\"MAPE:\", mean_absolute_percentage_error(val_y, tab_reg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNRegressor\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Containers for models\n",
    "models0 = {}\n",
    "models1 = {}\n",
    "models2 = {}\n",
    "models3 = {}\n",
    "\n",
    "# TRAINING\n",
    "for k in range(1, 11):\n",
    "    # 1) Build X_k = [train_X, train_y columns 1..k-1]\n",
    "    if k == 1:\n",
    "        Xk = train_X.values\n",
    "    else:\n",
    "        Xk = np.hstack([train_X.values, train_y.iloc[:, :k-1].values])\n",
    "    yk = train_y[f'BlendProperty{k}'].values\n",
    "\n",
    "    # 2) First pass model (stage 0)\n",
    "    m0 = TabPFNRegressor(device=\"auto\", random_state=42, n_jobs=12)\n",
    "    m0.fit(Xk, yk)\n",
    "    pred0 = m0.predict(Xk)\n",
    "\n",
    "    # 3) Second pass model on residuals (stage 1)\n",
    "    resid1 = yk - pred0\n",
    "    m1 = TabPFNRegressor(device=\"auto\", random_state=42, n_jobs=12)\n",
    "    m1.fit(Xk, resid1)\n",
    "    pred1 = m1.predict(Xk)\n",
    "\n",
    "    # 4) Third pass residual-of-residual (stage 2)\n",
    "    resid2 = yk - (pred0 + pred1)\n",
    "    m2 = TabPFNRegressor(device=\"auto\", random_state=42, n_jobs=12)\n",
    "    m2.fit(Xk, resid2)\n",
    "    pred2 = m2.predict(Xk)\n",
    "\n",
    "    # 5) Fourth pass residual-of-residual-of-residual (stage 3)\n",
    "    resid3 = yk - (pred0 + pred1 + pred2)\n",
    "    m3 = TabPFNRegressor(device=\"auto\", random_state=42, n_jobs=12)\n",
    "    m3.fit(Xk, resid3)\n",
    "\n",
    "    # 6) Store models and save\n",
    "    models0[k] = m0\n",
    "    models1[k] = m1\n",
    "    models2[k] = m2\n",
    "    models3[k] = m3\n",
    "    joblib.dump(m0, f\"tab_reg_{k}0.pkl\")\n",
    "    joblib.dump(m1, f\"tab_reg_{k}1.pkl\")\n",
    "    joblib.dump(m2, f\"tab_reg_{k}2.pkl\")\n",
    "    joblib.dump(m3, f\"tab_reg_{k}3.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION / EVALUATION\n",
    "eval_preds = np.zeros((val_X.shape[0], 10))\n",
    "\n",
    "for k in range(1, 11):\n",
    "    # Build features for val\n",
    "    if k == 1:\n",
    "        Xk_val = val_X.values\n",
    "    else:\n",
    "        Xk_val = np.hstack([val_X.values, eval_preds[:, :k-1]])\n",
    "\n",
    "    # Load models\n",
    "    m0 = joblib.load(f\"tab_reg_{k}0.pkl\")\n",
    "    m1 = joblib.load(f\"tab_reg_{k}1.pkl\")\n",
    "    m2 = joblib.load(f\"tab_reg_{k}2.pkl\")\n",
    "    m3 = joblib.load(f\"tab_reg_{k}3.pkl\")\n",
    "\n",
    "    # Make predictions and sum stages\n",
    "    p0 = m0.predict(Xk_val)\n",
    "    p1 = m1.predict(Xk_val)\n",
    "    p2 = m2.predict(Xk_val)\n",
    "    p3 = m3.predict(Xk_val)\n",
    "\n",
    "    eval_preds[:, k-1] = p0 + p1 + p2 + p3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009466852415944728\n",
      "MAE: 0.05503752282344956\n",
      "R2 : 0.406522287771252\n",
      "MAPE: 0.19935973660430076\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics\n",
    "print(\"MSE:\", mean_squared_error(val_y.values, eval_preds))\n",
    "print(\"MAE:\", mean_absolute_error(val_y.values, eval_preds))\n",
    "print(\"R2 :\", r2_score(val_y.values, eval_preds))\n",
    "print(\"MAPE:\", mean_absolute_percentage_error(val_y.values, eval_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION / EVALUATION\n",
    "eval_preds = np.zeros((test_dataset.shape[0], 10))\n",
    "\n",
    "for k in range(1, 11):\n",
    "    # Build features for val\n",
    "    if k == 1:\n",
    "        Xk_val = test_dataset.values\n",
    "    else:\n",
    "        Xk_val = np.hstack([test_dataset.values, eval_preds[:, :k-1]])\n",
    "\n",
    "    # Load models\n",
    "    m0 = joblib.load(f\"tab_reg_{k}0.pkl\")\n",
    "    m1 = joblib.load(f\"tab_reg_{k}1.pkl\")\n",
    "    m2 = joblib.load(f\"tab_reg_{k}2.pkl\")\n",
    "    m3 = joblib.load(f\"tab_reg_{k}3.pkl\")\n",
    "\n",
    "    # Make predictions and sum stages\n",
    "    p0 = m0.predict(Xk_val)\n",
    "    p1 = m1.predict(Xk_val)\n",
    "    p2 = m2.predict(Xk_val)\n",
    "    p3 = m3.predict(Xk_val)\n",
    "\n",
    "    eval_preds[:, k-1] = p0 + p1 + p2 + p3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlendProperty1</th>\n",
       "      <th>BlendProperty2</th>\n",
       "      <th>BlendProperty3</th>\n",
       "      <th>BlendProperty4</th>\n",
       "      <th>BlendProperty5</th>\n",
       "      <th>BlendProperty6</th>\n",
       "      <th>BlendProperty7</th>\n",
       "      <th>BlendProperty8</th>\n",
       "      <th>BlendProperty9</th>\n",
       "      <th>BlendProperty10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.148845</td>\n",
       "      <td>0.262678</td>\n",
       "      <td>0.703906</td>\n",
       "      <td>0.640048</td>\n",
       "      <td>0.350738</td>\n",
       "      <td>0.720537</td>\n",
       "      <td>0.680719</td>\n",
       "      <td>0.356276</td>\n",
       "      <td>-0.354980</td>\n",
       "      <td>0.337484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.795538</td>\n",
       "      <td>-0.598136</td>\n",
       "      <td>-1.193159</td>\n",
       "      <td>0.035167</td>\n",
       "      <td>-0.728268</td>\n",
       "      <td>-0.124294</td>\n",
       "      <td>-1.181531</td>\n",
       "      <td>-1.072566</td>\n",
       "      <td>-0.925527</td>\n",
       "      <td>0.014585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.765951</td>\n",
       "      <td>1.128263</td>\n",
       "      <td>1.072179</td>\n",
       "      <td>1.075381</td>\n",
       "      <td>2.544187</td>\n",
       "      <td>1.875419</td>\n",
       "      <td>1.043127</td>\n",
       "      <td>2.037348</td>\n",
       "      <td>0.756956</td>\n",
       "      <td>2.227070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.459227</td>\n",
       "      <td>0.305500</td>\n",
       "      <td>0.881599</td>\n",
       "      <td>-0.719728</td>\n",
       "      <td>1.905452</td>\n",
       "      <td>-0.448641</td>\n",
       "      <td>0.855586</td>\n",
       "      <td>1.696070</td>\n",
       "      <td>0.747031</td>\n",
       "      <td>-0.965298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.142876</td>\n",
       "      <td>-1.217153</td>\n",
       "      <td>1.107155</td>\n",
       "      <td>0.443758</td>\n",
       "      <td>2.397340</td>\n",
       "      <td>0.248083</td>\n",
       "      <td>1.076462</td>\n",
       "      <td>-0.163518</td>\n",
       "      <td>-0.466549</td>\n",
       "      <td>1.048567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.179043</td>\n",
       "      <td>-0.871055</td>\n",
       "      <td>1.207405</td>\n",
       "      <td>-0.291628</td>\n",
       "      <td>-0.276070</td>\n",
       "      <td>-0.733403</td>\n",
       "      <td>1.174684</td>\n",
       "      <td>-0.490458</td>\n",
       "      <td>-1.485863</td>\n",
       "      <td>-0.481735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-2.174039</td>\n",
       "      <td>-1.324562</td>\n",
       "      <td>-1.056241</td>\n",
       "      <td>-2.355623</td>\n",
       "      <td>-0.626858</td>\n",
       "      <td>-2.437788</td>\n",
       "      <td>-1.045869</td>\n",
       "      <td>-1.863388</td>\n",
       "      <td>-1.317421</td>\n",
       "      <td>-1.315383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1.990788</td>\n",
       "      <td>2.211923</td>\n",
       "      <td>0.337941</td>\n",
       "      <td>1.182781</td>\n",
       "      <td>0.006488</td>\n",
       "      <td>0.679122</td>\n",
       "      <td>0.322285</td>\n",
       "      <td>0.995825</td>\n",
       "      <td>0.183938</td>\n",
       "      <td>0.470461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-0.116684</td>\n",
       "      <td>0.817733</td>\n",
       "      <td>1.642594</td>\n",
       "      <td>-1.358319</td>\n",
       "      <td>-0.912031</td>\n",
       "      <td>0.198235</td>\n",
       "      <td>1.813064</td>\n",
       "      <td>0.514926</td>\n",
       "      <td>0.204476</td>\n",
       "      <td>1.297232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-1.025164</td>\n",
       "      <td>-1.928398</td>\n",
       "      <td>-1.965273</td>\n",
       "      <td>-1.634654</td>\n",
       "      <td>-0.024335</td>\n",
       "      <td>-1.809935</td>\n",
       "      <td>-1.938664</td>\n",
       "      <td>-1.893406</td>\n",
       "      <td>-2.338745</td>\n",
       "      <td>-0.216760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BlendProperty1  BlendProperty2  BlendProperty3  BlendProperty4  \\\n",
       "ID                                                                    \n",
       "1          0.148845        0.262678        0.703906        0.640048   \n",
       "2         -0.795538       -0.598136       -1.193159        0.035167   \n",
       "3          1.765951        1.128263        1.072179        1.075381   \n",
       "4         -0.459227        0.305500        0.881599       -0.719728   \n",
       "5          0.142876       -1.217153        1.107155        0.443758   \n",
       "..              ...             ...             ...             ...   \n",
       "496        0.179043       -0.871055        1.207405       -0.291628   \n",
       "497       -2.174039       -1.324562       -1.056241       -2.355623   \n",
       "498        1.990788        2.211923        0.337941        1.182781   \n",
       "499       -0.116684        0.817733        1.642594       -1.358319   \n",
       "500       -1.025164       -1.928398       -1.965273       -1.634654   \n",
       "\n",
       "     BlendProperty5  BlendProperty6  BlendProperty7  BlendProperty8  \\\n",
       "ID                                                                    \n",
       "1          0.350738        0.720537        0.680719        0.356276   \n",
       "2         -0.728268       -0.124294       -1.181531       -1.072566   \n",
       "3          2.544187        1.875419        1.043127        2.037348   \n",
       "4          1.905452       -0.448641        0.855586        1.696070   \n",
       "5          2.397340        0.248083        1.076462       -0.163518   \n",
       "..              ...             ...             ...             ...   \n",
       "496       -0.276070       -0.733403        1.174684       -0.490458   \n",
       "497       -0.626858       -2.437788       -1.045869       -1.863388   \n",
       "498        0.006488        0.679122        0.322285        0.995825   \n",
       "499       -0.912031        0.198235        1.813064        0.514926   \n",
       "500       -0.024335       -1.809935       -1.938664       -1.893406   \n",
       "\n",
       "     BlendProperty9  BlendProperty10  \n",
       "ID                                    \n",
       "1         -0.354980         0.337484  \n",
       "2         -0.925527         0.014585  \n",
       "3          0.756956         2.227070  \n",
       "4          0.747031        -0.965298  \n",
       "5         -0.466549         1.048567  \n",
       "..              ...              ...  \n",
       "496       -1.485863        -0.481735  \n",
       "497       -1.317421        -1.315383  \n",
       "498        0.183938         0.470461  \n",
       "499        0.204476         1.297232  \n",
       "500       -2.338745        -0.216760  \n",
       "\n",
       "[500 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_tabpfm = eval_preds\n",
    "test_pred_tabpfm = pd.DataFrame(test_pred_tabpfm,columns=['BlendProperty1', 'BlendProperty2', 'BlendProperty3', 'BlendProperty4',\n",
    "       'BlendProperty5', 'BlendProperty6', 'BlendProperty7', 'BlendProperty8',\n",
    "       'BlendProperty9', 'BlendProperty10'],index=test_dataset.index)\n",
    "test_pred_tabpfm.to_csv('combine_output_test_pred_tabpfm_check.csv')\n",
    "test_pred_tabpfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_reg = MultiOutputRegressor(AdaBoostRegressor(estimator=TabPFNRegressor(n_estimators=8,device='cuda',random_state=42,n_jobs=-1),n_estimators=5,learning_rate=0.01,random_state=42,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_reg.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(ada_reg,'ada_boost_multioutput_tabpfn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# ada_reg = joblib.load('ada_boost_multioutput_tabpfn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_reg_pred = ada_reg.predict(val_X)\n",
    "print(\"MSE: \", mean_squared_error(val_y, tab_reg_pred))\n",
    "print(\"MAE: \", mean_absolute_error(val_y, tab_reg_pred))\n",
    "print(\"R2 : \", r2_score(val_y, tab_reg_pred))\n",
    "print(\"MAPE:\", mean_absolute_percentage_error(val_y, tab_reg_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tabpfms =  loaded_model.predict(test_dataset) + multioutput_tab_reg_0.predict(test_dataset) + multioutput_tab_reg_1.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlendProperty1</th>\n",
       "      <th>BlendProperty2</th>\n",
       "      <th>BlendProperty3</th>\n",
       "      <th>BlendProperty4</th>\n",
       "      <th>BlendProperty5</th>\n",
       "      <th>BlendProperty6</th>\n",
       "      <th>BlendProperty7</th>\n",
       "      <th>BlendProperty8</th>\n",
       "      <th>BlendProperty9</th>\n",
       "      <th>BlendProperty10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144660</td>\n",
       "      <td>0.245549</td>\n",
       "      <td>0.712867</td>\n",
       "      <td>0.610593</td>\n",
       "      <td>0.350618</td>\n",
       "      <td>0.707636</td>\n",
       "      <td>0.676811</td>\n",
       "      <td>0.359906</td>\n",
       "      <td>-0.337583</td>\n",
       "      <td>0.336408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.790911</td>\n",
       "      <td>-0.595550</td>\n",
       "      <td>-1.194027</td>\n",
       "      <td>0.064809</td>\n",
       "      <td>-0.727866</td>\n",
       "      <td>-0.113469</td>\n",
       "      <td>-1.188349</td>\n",
       "      <td>-1.057020</td>\n",
       "      <td>-0.874985</td>\n",
       "      <td>0.017551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.763701</td>\n",
       "      <td>1.133104</td>\n",
       "      <td>1.073073</td>\n",
       "      <td>1.062013</td>\n",
       "      <td>2.544158</td>\n",
       "      <td>1.872890</td>\n",
       "      <td>1.043529</td>\n",
       "      <td>2.012657</td>\n",
       "      <td>0.794215</td>\n",
       "      <td>2.238994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.455381</td>\n",
       "      <td>0.310517</td>\n",
       "      <td>0.897070</td>\n",
       "      <td>-0.719686</td>\n",
       "      <td>1.894199</td>\n",
       "      <td>-0.453937</td>\n",
       "      <td>0.825443</td>\n",
       "      <td>1.808139</td>\n",
       "      <td>0.871755</td>\n",
       "      <td>-0.975509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.152203</td>\n",
       "      <td>-1.205750</td>\n",
       "      <td>1.118310</td>\n",
       "      <td>0.454448</td>\n",
       "      <td>2.403900</td>\n",
       "      <td>0.265163</td>\n",
       "      <td>1.087767</td>\n",
       "      <td>-0.122754</td>\n",
       "      <td>-0.523214</td>\n",
       "      <td>1.049241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.179932</td>\n",
       "      <td>-0.858364</td>\n",
       "      <td>1.214646</td>\n",
       "      <td>-0.287842</td>\n",
       "      <td>-0.276840</td>\n",
       "      <td>-0.737055</td>\n",
       "      <td>1.177578</td>\n",
       "      <td>-0.484711</td>\n",
       "      <td>-1.451500</td>\n",
       "      <td>-0.448714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-2.173048</td>\n",
       "      <td>-1.341439</td>\n",
       "      <td>-1.045870</td>\n",
       "      <td>-2.379928</td>\n",
       "      <td>-0.626680</td>\n",
       "      <td>-2.451068</td>\n",
       "      <td>-1.044825</td>\n",
       "      <td>-1.910323</td>\n",
       "      <td>-1.333339</td>\n",
       "      <td>-1.343474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1.990859</td>\n",
       "      <td>2.201061</td>\n",
       "      <td>0.304565</td>\n",
       "      <td>1.170098</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.672645</td>\n",
       "      <td>0.294335</td>\n",
       "      <td>1.017929</td>\n",
       "      <td>0.249123</td>\n",
       "      <td>0.483797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-0.122276</td>\n",
       "      <td>0.810098</td>\n",
       "      <td>1.647455</td>\n",
       "      <td>-1.394247</td>\n",
       "      <td>-0.912829</td>\n",
       "      <td>0.189658</td>\n",
       "      <td>1.957715</td>\n",
       "      <td>0.565628</td>\n",
       "      <td>0.193554</td>\n",
       "      <td>1.285163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-1.023673</td>\n",
       "      <td>-1.924242</td>\n",
       "      <td>-1.956342</td>\n",
       "      <td>-1.648219</td>\n",
       "      <td>-0.024504</td>\n",
       "      <td>-1.823440</td>\n",
       "      <td>-1.933756</td>\n",
       "      <td>-1.922025</td>\n",
       "      <td>-2.308737</td>\n",
       "      <td>-0.208171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BlendProperty1  BlendProperty2  BlendProperty3  BlendProperty4  \\\n",
       "ID                                                                    \n",
       "1          0.144660        0.245549        0.712867        0.610593   \n",
       "2         -0.790911       -0.595550       -1.194027        0.064809   \n",
       "3          1.763701        1.133104        1.073073        1.062013   \n",
       "4         -0.455381        0.310517        0.897070       -0.719686   \n",
       "5          0.152203       -1.205750        1.118310        0.454448   \n",
       "..              ...             ...             ...             ...   \n",
       "496        0.179932       -0.858364        1.214646       -0.287842   \n",
       "497       -2.173048       -1.341439       -1.045870       -2.379928   \n",
       "498        1.990859        2.201061        0.304565        1.170098   \n",
       "499       -0.122276        0.810098        1.647455       -1.394247   \n",
       "500       -1.023673       -1.924242       -1.956342       -1.648219   \n",
       "\n",
       "     BlendProperty5  BlendProperty6  BlendProperty7  BlendProperty8  \\\n",
       "ID                                                                    \n",
       "1          0.350618        0.707636        0.676811        0.359906   \n",
       "2         -0.727866       -0.113469       -1.188349       -1.057020   \n",
       "3          2.544158        1.872890        1.043529        2.012657   \n",
       "4          1.894199       -0.453937        0.825443        1.808139   \n",
       "5          2.403900        0.265163        1.087767       -0.122754   \n",
       "..              ...             ...             ...             ...   \n",
       "496       -0.276840       -0.737055        1.177578       -0.484711   \n",
       "497       -0.626680       -2.451068       -1.044825       -1.910323   \n",
       "498        0.006623        0.672645        0.294335        1.017929   \n",
       "499       -0.912829        0.189658        1.957715        0.565628   \n",
       "500       -0.024504       -1.823440       -1.933756       -1.922025   \n",
       "\n",
       "     BlendProperty9  BlendProperty10  \n",
       "ID                                    \n",
       "1         -0.337583         0.336408  \n",
       "2         -0.874985         0.017551  \n",
       "3          0.794215         2.238994  \n",
       "4          0.871755        -0.975509  \n",
       "5         -0.523214         1.049241  \n",
       "..              ...              ...  \n",
       "496       -1.451500        -0.448714  \n",
       "497       -1.333339        -1.343474  \n",
       "498        0.249123         0.483797  \n",
       "499        0.193554         1.285163  \n",
       "500       -2.308737        -0.208171  \n",
       "\n",
       "[500 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_tabpfm = pred_tabpfms\n",
    "test_pred_tabpfm = pd.DataFrame(test_pred_tabpfm,columns=['BlendProperty1', 'BlendProperty2', 'BlendProperty3', 'BlendProperty4',\n",
    "       'BlendProperty5', 'BlendProperty6', 'BlendProperty7', 'BlendProperty8',\n",
    "       'BlendProperty9', 'BlendProperty10'],index=test_dataset.index)\n",
    "test_pred_tabpfm.to_csv('combine_output_test_pred_tabpfm.csv')\n",
    "test_pred_tabpfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7811108,
     "sourceId": 12387522,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
